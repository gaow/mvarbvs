#!/usr/bin/env sos-runner
#fileformat=SOS1.0

# Various calls to commands to accomplish some workflow
# When some workflow gets complicated they will be separated into dedicated files

parameter: project_name = 'GTEx'

[genotype_stats_1]
# making genotype summary statistics via vcftools
parameter: workdir = None
depends: executable("vcftools")
input: pattern = "{name}.vcf.gz"
output: expand_pattern("${CONFIG['wd']}/${name!b}.imiss"), expand_pattern("${CONFIG['wd']}/${name!b}.lmiss")
task: workdir = workdir
run: 
  vcftools --gzvcf ${input} --out ${output[0]!n} --missing-indv
  vcftools --gzvcf ${input} --out ${output[1]!n} --missing-site

[genotype_stats_2]
# making genotype summary statistics plot
parameter: workdir = None
depends: Py_Module("seaborn")
input: group_by = 1, pattern = "{name}.{ext}"
output: expand_pattern("{_name}.{_ext}.pdf")
task: workdir = workdir
python:
import matplotlib.pyplot as plt, seaborn as sns, pandas as pd
fig, axs = plt.subplots(ncols=2)
data = pd.read_csv(${_input!r}, sep = '\t')
sns.distplot(data["F_MISS"], ax = axs[0], kde = False)
sns.violinplot(data["F_MISS"], ax = axs[1])
axs[0].set_title(${_input!br}.split('.')[-1])
fig.savefig(${_output!r})

[rnaseq_1]
# Quantile normalization of RNA-seq data
# 1. expression values are quantile normalized to the average empirical distribution observed across samples
# 2. for each gene, expression values are inverse quantile normalized to a standard normal distribution across samples
# genes are selected based on expression thresholds of >0.1 RPKM in >10 samples and >5 reads in >10 samples
# input are rpkm file (for normalization), count file (for QC) and vcf file (for removing samples that do not have genotypes)
parameter: rpkm_cutoff = 0.1
parameter: read_cutoff = 5
parameter: sample_cutoff = 10
parameter: script = os.path.abspath("../src/normalize_expression.py")
parameter: workdir = None
output: "${workdir}/${input[0]!nnb}.qnorm.std.flat.h5", "${workdir}/${input[0]!nnb}.qnorm.flat.h5", "${workdir}/${input[0]!nnb}.qnorm.std.h5", "${workdir}/${input[0]!nnb}.qnorm.h5"
task: workdir = workdir
run:
  python ${script} ${input[0]} ${input[1]} ${input[2]} ${input[3]} ${input[0]!nnb} --expression_threshold ${rpkm_cutoff} --count_threshold ${read_cutoff} --min_samples ${sample_cutoff}

[rnaseq_2]
# PEER analysis
# There are a number of configuable parameters in this script
# Using default values for now. Can be changed here or not depending on the analyst
depends: R_library('rhdf5'), R_library('peer')
parameter: tissues = get_output("h5ls ${input[2]} | awk '{print $1}'").strip().split('\n')
parameter: workdir = None
input: for_each = ['tissues']
output: "${workdir}/${_tissues}_PEER_covariates.txt", "${workdir}/${_tissues}_PEER_alpha.txt", "${workdir}/${_tissues}_PEER_residuals.txt"
task: workdir = workdir, walltime = "20:00:00", cores = 1, mem = "4G"
R:

expr.h5 = ${input[2]!r}
prefix = ${_tissues!r}
alphaprior_a=0.001
alphaprior_b=0.01
epsprior_a=0.1
epsprior_b=10
max_iter=1000

library(peer, quietly=TRUE)  # https://github.com/PMBio/peer
library(rhdf5, quietly=TRUE)

WriteTable <- function(data, filename, index.name) {
	datafile <- file(filename, open = "wt")
	on.exit(close(datafile))
	header <- c(index.name, colnames(data))
	writeLines(paste0(header, collapse="\t"), con=datafile, sep="\n")
	write.table(data, datafile, sep="\t", col.names=FALSE, quote=FALSE)
}

loadTable <- function(filename, group, auto_transpose = FALSE) {
  obj <- h5read(filename, group)
  dat <- obj$block0_values
  rownames(dat) <- obj$axis0
  colnames(dat) <- obj$axis1
  if (ncol(dat) > nrow(dat) && auto_transpose) dat <- t(dat)
  return(dat)
}

getNumPeer <- function(ss) {
  if (ss<150) return (min(15, ceiling(ss / 5)))
  else if (ss >=150 && ss < 250) return(30)
  else return(35)
}

cat("PEER: loading expression data ... ")
# rows are number of samples. columns are number of genes
M <- as.matrix(loadTable(expr.h5, "/${_tissues}"))
n = getNumPeer(nrow(M))
cat("done.\n")

# run PEER
cat(paste0("PEER: estimating hidden confounders (", n, " for tissue ", prefix , ")\n"))
model <- PEER()
invisible(PEER_setNk(model, n))
invisible(PEER_setPhenoMean(model, M))
invisible(PEER_setPriorAlpha(model, alphaprior_a, alphaprior_b))
invisible(PEER_setPriorEps(model,epsprior_a, epsprior_b))
invisible(PEER_setNmax_iterations(model, max_iter))
# if(!is.null(covs)) {
#   invisible(PEER_setCovariates(model, covs))
# }
time <- system.time(PEER_update(model))

X <- PEER_getX(model)  # samples x PEER factors
A <- PEER_getAlpha(model)  # PEER factors x 1
R <- t(PEER_getResiduals(model))  # genes x samples

# add relevant row/column names
c <- paste0("InferredCov",1:ncol(X))
rownames(X) <- rownames(M)
colnames(X) <- c
rownames(A) <- c
colnames(A) <- "Alpha"
A <- as.data.frame(A)
A$Relevance <- 1.0 / A$Alpha
rownames(R) <- colnames(M)
colnames(R) <- rownames(M)

# write results
cat("PEER: writing results ... ")
WriteTable(t(X), paste0(prefix, "_PEER_covariates.txt"), "ID")  # format(X, digits=6)
WriteTable(A, paste0(prefix, "_PEER_alpha.txt"), "ID")
WriteTable(R, paste0(prefix, "_PEER_residuals.txt"), "ID")
cat("done.\n")

[LD_pruning_1]
# Mark independent variants
parameter: workdir = None
parameter: pairwise_ld_param = '50 5 0.2'
parameter: maf = 0.1
depends: executable('plink')
input: pattern = '{name}.{ext}'
output: expand_pattern('{name}.prune.in')
task: workdir = workdir 
run:
  plink --bfile ${input!n} \
        --allow-no-sex \
        --maf ${maf} \
        --indep-pairwise ${pairwise_ld_param} \
        --out ${output!nn}
        
[LD_pruning_2]
# Select independent common variants
parameter: workdir = None
depends: executable('plink')
input: pattern = '{name}.prune.in'
output: expand_pattern('{name}.prune.bed')
task: workdir = workdir 
run:
  plink --bfile ${input!nn} \
        --extract ${input} \
        --no-sex --no-pheno --no-parents \
        --make-bed \
        --out ${output!n}

[global_ancestry_1]
# global ancestry analysis via KING
# And fix family ID (replace by ancestry coding)
parameter: phenotype = "${CONFIG['phenotype']!a}"
parameter: workdir = None
depends: executable('king'), phenotype
input: pattern = "{name}.{ext}"
output: expand_pattern('{name}.pc.ped')
task: workdir = workdir
run:
  # king -b ${input!n}.bed --pca 20 --prefix ${input!n}.
  # Would be much faster if I use MDS
  # One should use PCA to be more comparable to GTEx official results, though
  king -b ${input!n}.bed --mds --prefix ${input!n}.

python:
import pandas as pd
reference = pd.read_csv(${phenotype!r}, dtype = str, usecols = (0,4), sep = '\t')
reference['RACE'] = 'POP' + reference['RACE'].astype(str)
fam = pd.read_csv(${output!r}, header = None, sep = ' ',
                  names = ['fid', 'sid', 'pid', 'mid', 'sex', 'phen'] + ['PC{}'.format(x+1) for x in range(20)])
dat = pd.merge(reference, fam, left_on = 'SUBJID', right_on = "sid")
dat.drop(['SUBJID', 'fid'], axis=1, inplace = True)
dat.to_csv(${output!r}, sep = ' ', header = False, index = False)

[global_ancestry_2]
# scatter plot for global ancestry analysis result
# R plotly implementation
parameter: workdir = None
depends: R_library("plotly")
input: pattern = "{name}.ped" 
output: expand_pattern('{name}.html')
task: workdir = workdir 
R: 
   library(plotly)
   dat <- read.table(${input!r}, sep = ' ')
   for (i in 1:(ncol(dat) - 6 - 1)) {
       title <- paste(${input!bnr}, "PC", i, "vs", "PC", i + 1, sep = "_")
       p <- plot_ly(dat, x = dat[, 6 + i], y = dat[, 7 + i], text = dat[,2], color = dat[,1],
                    mode = "markers", type = 'scatter', visible = 'legendonly') %>% layout(title = title)
       htmlwidgets::saveWidget(as.widget(p), paste0(title, ".html"))
   }
run:
   foo () {
     echo '<html><body>'
     sed 's/^.*/<a href="&">&<\/a><br\/>/'
     echo '</body></html>'
   }
   mkdir -p ${input!n}; mv ${input!bn}*.html ${input!n}
   ls ${input!n}/*.html | foo > ${output}

[ensembl_annotation]
# Annotate gene to chromosomal positions
# Input is GTEx expression file with first column the ENSG IDs
depends: R_library("biomaRt")
output: "${input!n}.annotation"
task: workdir = workdir
R:
system("zcat ${input} | cut -f 1 | tail -n+4 | cut -f 1 -d '.' > ${input!n}.gene_id")
values = unlist(read.table("${input!n}.gene_id", stringsAsFactors=FALSE)) 
ensembl = biomaRt::useMart("ensembl", dataset="hsapiens_gene_ensembl", host="www.ensembl.org")
res = biomaRt::getBM(attributes = c("chromosome_name", "start_position", "end_position", "ensembl_gene_id", "hgnc_symbol"), filters = c("ensembl_gene_id"), values = values,  mart = ensembl)
write.table(res, file = ${output!r}, row.names=FALSE, na= "<NA>", col.names = FALSE)

run:
  cat ${output} | sed -e 's/"//g' | sort -g -o ${output}
  rm -f ${input!n}.gene_id

[genotype_LD_1]
# Permute X & Get LD structure
parameter: workdir = None
parameter: src = None
parameter: genotype_data = None
parameter: permute_genotype = "False"
input: genotype_data, group_by = 1
output: "${_input!an}.ld.h5" if permute_genotype == 'False' else "${_input!an}.permuted.ld.h5"
task: workdir = workdir
python:
  import os, sys
  sys.path.append(${src!ar})
  from SimUtils import PhenotypeSimulator, BetaDist
  ms = PhenotypeSimulator(${_input!ar})
  tables = ms.get_genes()
  if ${permute_genotype}:
     ms.permute_X(tables, save_to = '${_output!nn}.h5')
  ld = ms.get_ld(tables, save_to = ${_output!r})
  for table in tables:
      ms.ld_heatmap(ld[table].iloc[:1000,:1000], '{}.ld.png'.format(os.path.basename(table) + ('.permuted' if ${permute_genotype} else '')))

[simulation_1]
# Generate simulated data
parameter: workdir = None
parameter: src = None
parameter: pi0 = None 
parameter: shape = None
parameter: n_rep = None
parameter: replicate = [x + 1 for x in range(n_rep)]
parameter: genotype_data = None
parameter: permuted_genotype = "False"
input: genotype_data if permuted_genotype == 'False' else [x.replace(".h5", ".permuted.h5") for x in genotype_data], group_by = 1, for_each = ['pi0', 'shape', 'replicate']
output: "${workdir}/${_input!bn}." + "${_pi0}_${_shape}_${_replicate}".replace('.', 'p') + '.expr.h5'
task: workdir = workdir
python:
  import sys, os, json, pandas as pd
  sys.path.append(${src!ar})
  from SimUtils import PhenotypeSimulator, BetaDist
  ms = PhenotypeSimulator(${_input!ar})
  tables = ms.get_genes()
  ld = ms.load_ld(tables, "${_input!an}.ld.h5")
  if os.path.isfile(${_output!r}):
     os.remove(${_output!r})
  param = BetaDist()  
  param.set_pi0(${_pi0})
  param.set_${_shape}()
  print(param)
  for table in tables:
    ms.set_id(os.path.basename(table))
    nbeta = ld[table].shape[0]
    beta = ms.generate_betamix(nbeta=nbeta,pi0=param.pi0, pis=param.pis, mus = param.mus, sigmas=param.sigmas)
    if not ${permuted_genotype}:
       strong_snps_idx = ms.select_convoluted_snps(ld[table])
       beta = ms.swap_beta(beta, strong_snps_idx)
    X = ms.get_X(table=table)
    y = ms.generate_y(beta=beta,sigma=1, X=X, force = True)
  pd.concat(ms.phenotype.values()).to_hdf(${_output!r}, '/simulated', mode = 'a', complevel = 9, complib = 'zlib')
  meta = {'pi': param.pis, 'pi0': param.pi0, 'sigma': param.sigmas, 'mu': param.mus, 'beta': ms.beta, 'name': ${_shape!r}}
  with open("${_output!n}.json", 'w') as fp:
    json.dump(meta, fp)

[simulation_2]
# Analyze data
parameter: genotype_data = None
parameter: workdir = None
input: group_by = 1
output: "${_input!n}.analyzed.rds"
task: workdir = workdir
R:
  library(rhdf5)
  source("src/Utils.R")
  genotype_file = "${genotype_data[0]!ad}/${_input!bnnn}.h5"
  expr_file = ${_input!r}
  expr_table = '/simulated'
  tables = get_h5_groups(genotype_file)
  res = list()
  for (table in tables) {
      dat = load_data(genotype_file, expr_file, table, expr_table)
      X = as.matrix(dat$X)
      storage.mode(X) <- "double"
      y = as.vector(dat$y)
      # Univariate analysis
      res0 = univariate_lm(X,y)
      mixsd = ashr:::autoselect.mixsd(res0, sqrt(2), 0, c(-Inf,Inf), "normal")
      res1 = varbvs::varbvsmix(X, NULL, y, sa = c(0, mixsd^2))
      res1$pip = res1$alpha %*% c(res1$w)
      res1$beta = rowSums(res1$alpha * res1$mu)
      res1$y = X %*% res1$beta + res1$mu.cov[1]
      meta = rjson::fromJSON(file = "${_input!n}.json")
      meta$y = y
      meta$beta = meta$beta[[basename(table)]]
      res2 = ashr::ash(res0$x, res0$s)
      res[[basename(table)]] = list(uni=res0,mr.ash=res1,ash=res2,meta=meta)
  }
  saveRDS(res, file = ${_output!r})

[simulation_3]
# Make plots
input: group_by = 1
output: "${_input!n}.pdf"
task: workdir = workdir
R:
  dat = readRDS(${_input!r})
  pdf(${_output!r})
  for (table in names(dat)) {
      res = dat[[table]]
      # Fitted mixture porportions
      par(mfrow = c(1,3), oma=c(0,0,2,0))
      barplot(c(res$meta$pi0, res$meta$pi * (1 - res$meta$pi0)), col=rgb(0.2,0.4,0.6,0.6), horiz=T, las=1, main = 'truth')
      barplot(res$mr.ash$w, col=rgb(0.2,0.4,0.6,0.6), horiz=T, las=1, main = 'mr-ash, fitted g')
      barplot(ashr::get_fitted_g(res$ash)$pi, col=rgb(0.2,0.4,0.6,0.6), horiz=T, las=1, main = 'ash, fitted g')
      title(paste0(table, " ", ifelse(grepl('permuted', ${_input!r}), "permuted", "original"), " genotype, ", round(res$meta$pi0,4), " pi0 + ", res$meta$name, " mixture"), outer=TRUE)
      # Compare fit
      par(mfrow = c(3,2), mar = c(2,1,2,1))
      plot(res$meta$beta, pch=20, bg="white", col=rgb(0.3,0.6,0.9,0.9), ylab = "betahat", main = 'truth, betahat')
      plot(res$mr.ash$beta, pch=20, bg="white", col=rgb(0.3,0.6,0.9,0.9), ylab = "betahat", main = 'mr-ash, betahat')
      legend("topleft", paste0("sigma = ", round(res$mr.ash$sigma,2)), bty="n") 
      plot(ashr::get_pm(res$ash), pch=20, bg="white", col=rgb(0.3,0.6,0.9,0.9), ylab = "betahat", main = 'ash, betahat')
      plot(res$uni$x, pch=20, bg="white", col=rgb(0.3,0.6,0.9,0.9), ylab = "betahat", main = 'univariate, betahat')
      plot(res$meta$beta, res$mr.ash$beta, pch=20, bg="white", col=rgb(0.3,0.3,0.9,0.9), ylab = "mr.ash", xlab = "truth", main = 'truth vs mr.ash, betahat')
      abline(0,1, col="whitesmoke")
      plot(ashr::get_pm(res$ash), res$mr.ash$beta, pch=20, bg="white", col=rgb(0.3,0.3,0.9,0.9), ylab = "mr.ash", xlab = "ash", main = 'ash vs mr.ash, betahat')
      abline(0,1, col="whitesmoke")
  }