#!/usr/bin/env sos-runner
#fileformat=SOS1.0

# Various calls to commands to accomplish some workflow
# When some workflow gets complicated they will be separated into dedicated files


parameter: project_name = "GTEx7"

[genotype_stats_1]
# making genotype summary statistics via vcftools
parameter: workdir = None
depends: executable("vcftools")
input: pattern = "{name}.vcf.gz"
output: expand_pattern("${CONFIG['wd']}/${name!b}.imiss"), expand_pattern("${CONFIG['wd']}/${name!b}.lmiss")
task: workdir = workdir
run: 
  vcftools --gzvcf ${input} --out ${output[0]!n} --missing-indv
  vcftools --gzvcf ${input} --out ${output[1]!n} --missing-site

[genotype_stats_2]
# making genotype summary statistics plot
parameter: workdir = None
depends: Py_Module("seaborn")
input: group_by = 1, pattern = "{name}.{ext}"
output: expand_pattern("{_name}.{_ext}.pdf")
task: workdir = workdir
python:
import matplotlib.pyplot as plt, seaborn as sns, pandas as pd
fig, axs = plt.subplots(ncols=2)
data = pd.read_csv(${_input!r}, sep = '\t')
sns.distplot(data["F_MISS"], ax = axs[0], kde = False)
sns.violinplot(data["F_MISS"], ax = axs[1])
axs[0].set_title(${_input!br}.split('.')[-1])
fig.savefig(${_output!r})

[rnaseq_1]
# Quantile normalization of RNA-seq data
# 1. expression values are quantile normalized to the average empirical distribution observed across samples
# 2. for each gene, expression values are inverse quantile normalized to a standard normal distribution across samples
# genes are selected based on expression thresholds of >0.1 RPKM in >10 samples and >5 reads in >10 samples
# input are rpkm file (for normalization), count file (for QC) and vcf file (for removing samples that do not have genotypes)
parameter: rpkm_cutoff = 0.1
parameter: read_cutoff = 5
parameter: sample_cutoff = 10
parameter: script = os.path.abspath("../src/normalize_expression.py")
parameter: workdir = None
output: "${workdir}/${input[0]!nnb}.qnorm.std.flat.h5", "${workdir}/${input[0]!nnb}.qnorm.flat.h5", "${workdir}/${input[0]!nnb}.qnorm.std.h5", "${workdir}/${input[0]!nnb}.qnorm.h5"
task: workdir = workdir
run:
  python ${script} ${input[0]} ${input[1]} ${input[2]} ${input[3]} ${input[0]!nnb} --expression_threshold ${rpkm_cutoff} --count_threshold ${read_cutoff} --min_samples ${sample_cutoff}

[rnaseq_2]
# PEER analysis
# There are a number of configuable parameters in this script
# Using default values for now. Can be changed here or not depending on the analyst
depends: R_library('rhdf5'), R_library('peer')
parameter: tissues = get_output("h5ls ${input[3]} | awk '{print $1}'").strip().split('\n')
input: for_each = ['tissues']
output: "${_tissues}_PEER_covariates.txt", "${_tissues}_PEER_alpha.txt", "${_tissues}_PEER_residuals.txt"
task: workdir = workdir, walltime = "20:00:00", cores = 1, mem = "4G"
R:

expr.h5 = ${input[3]!r}
prefix = ${_tissues!r}
alphaprior_a=0.001
alphaprior_b=0.01
epsprior_a=0.1
epsprior_b=10
max_iter=1000

library(peer, quietly=TRUE)  # https://github.com/PMBio/peer
library(rhdf5, quietly=TRUE)

WriteTable <- function(data, filename, index.name) {
	datafile <- file(filename, open = "wt")
	on.exit(close(datafile))
	header <- c(index.name, colnames(data))
	writeLines(paste0(header, collapse="\t"), con=datafile, sep="\n")
	write.table(data, datafile, sep="\t", col.names=FALSE, quote=FALSE)
}

loadTable <- function(filename, group, auto_transpose = FALSE) {
  obj <- h5read(filename, group)
  dat <- obj$block0_values
  rownames(dat) <- obj$axis0
  colnames(dat) <- obj$axis1
  if (ncol(dat) > nrow(dat) && auto_transpose) dat <- t(dat)
  return(dat)
}

getNumPeer <- function(ss) {
  if (ss<150) return (15)
  else if (ss >=150 && ss < 250) return(30)
  else return(35)
}

cat("PEER: loading expression data ... ")
# rows are number of samples. columns are number of genes
M <- as.matrix(loadTable(expr.h5, "/${_tissues}"))
n = getNumPeer(nrow(M))
cat("done.\n")

# run PEER
cat(paste0("PEER: estimating hidden confounders (", n, " for tissue ", prefix , ")\n"))
model <- PEER()
invisible(PEER_setNk(model, n))
invisible(PEER_setPhenoMean(model, M))
invisible(PEER_setPriorAlpha(model, alphaprior_a, alphaprior_b))
invisible(PEER_setPriorEps(model,epsprior_a, epsprior_b))
invisible(PEER_setNmax_iterations(model, max_iter))
# if(!is.null(covs)) {
#   invisible(PEER_setCovariates(model, covs))
# }
time <- system.time(PEER_update(model))

X <- PEER_getX(model)  # samples x PEER factors
A <- PEER_getAlpha(model)  # PEER factors x 1
R <- t(PEER_getResiduals(model))  # genes x samples

# add relevant row/column names
c <- paste0("InferredCov",1:ncol(X))
rownames(X) <- rownames(M)
colnames(X) <- c
rownames(A) <- c
colnames(A) <- "Alpha"
A <- as.data.frame(A)
A$Relevance <- 1.0 / A$Alpha
rownames(R) <- colnames(M)
colnames(R) <- rownames(M)

# write results
cat("PEER: writing results ... ")
WriteTable(t(X), paste0(prefix, "_PEER_covariates.txt"), "ID")  # format(X, digits=6)
WriteTable(A, paste0(prefix, "_PEER_alpha.txt"), "ID")
WriteTable(R, paste0(prefix, "_PEER_residuals.txt"), "ID")
cat("done.\n")

[umich_to_plink_1]
# UMich imputed VCF to plink format
parameter: filter = 1
input: group_by = 'single'
output: "${_input!n}.bed"
task:
run:
  if [[ ${filter} ]]; then
     zcat ${_input} | awk 'if ($7 == "PASS") {print $2}' > ${_input!nn}.exclude_id
     plink --vcf ${_input} --out ${_output!n} --exclude ${_input!nn}.exclude_id
     rm -f ${_input!nn}.exclude_id
  else
     plink --vcf ${_input} --out ${_output!n}
  fi

[umich_to_plink_2]
# Merge all files
output: "${project_name}" 

[fastqtl_1]
# FastQTL pipeline