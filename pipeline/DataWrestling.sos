#!/usr/bin/env sos-runner
# vim: set filetype=python: set expandtab : ts=4:
#fileformat=SOS1.0

# This script provides routines for file conversions and data transformations

[variants_filter_1]
# Exclude imputed variants
parameter: include = None
output: "${input!n}.genotyped.bed"
task: workdir = workdir
python:
import pandas as pd
imputed = pd.read_csv("${input!n}.bim", dtype = str, usecols = (0,1,3), header = None, sep = '\t')
genotyped = pd.read_csv("${include!n}.bim", dtype = str, usecols = (0,1,3), header = None, sep = '\t')
imputed[0] = imputed[0] + '_' + imputed[3]
imputed.drop([3], axis = 1, inplace = True)
genotyped[0] = genotyped[0] + '_' + genotyped[3]
genotyped.drop([1,3], axis = 1, inplace = True)
res = pd.merge(imputed, genotyped, how='inner', on=[0,0])
res[1].to_csv("${input!n}.extract_id", header = False, index = False)

run:
  plink --bfile ${input!n} --out ${output!n} --extract ${input!n}.extract_id --make-bed
  rm -f ${input!n}.extract_id

[variants_filter_2]
# Filter by MAF, HWE etc
parameter: maf = 0.01
parameter: mac = 10
output: "${input!n}.filtered.bed"
task: workdir = workdir
run:
  plink --bfile ${input!n} --maf ${maf} --mac ${mac} --make-bed --out ${output!n}

[plink_to_hdf5_batch]
# Convert plink genotype to HDF5 in batches of genes
# Only autosomal genes are considered
# cis: ${cis} up/downstream from TSS of each gene
depends: Py_Module("pandas-plink")
parameter: ann = None
parameter: workdir = None
parameter: cis = 1000000
parameter: resume = 1
output: "${input!n}.cis.h5"
# task: workdir = workdir
python:
import os
import pandas as pd, numpy as np
from pandas_plink import read_plink

keys = []
if os.path.isfile(${output!r}):
   if ${resume} == 1:
      print("loading existing database ${output!b}")
      keys = pd.HDFStore(${output!r}).keys()
      print("{} existing genes will be skipped".format(len(keys)))
   else:
      os.remove(${output!r})

(bim, fam, bed) = read_plink(${input!nr})
ann = [x.strip().split() for x in open(${ann!ar}).readlines()]
n = len(ann)
empty_genes = []
for i, line in enumerate(ann):
    if(i % 100 == 0):
        print('[percent completed] %.2f' % ((float(i)/n)*100))
    if line[0] not in list(map(str, [x+1 for x in range(22)])):
        continue
    if '/chr{}/{}'.format(line[0], line[3]) in keys:
        continue
    snps = bim.query("chrom == '{}' and (pos >= {} and pos <= {})".\
                            format(line[0], int(line[1]) - ${cis}, int(line[1]) + ${cis}))
    if (snps.empty):
        empty_genes.append(line[3])
        continue
    X = pd.DataFrame(2 - bed[snps.i,:].compute(), 
                     index = [':'.join((x.split('_', 1)[0], y,z)) for x, y, z in zip(snps.snp, snps.a1, snps.a0)], 
                     columns = fam.iid, dtype = np.uint8)
    X.to_hdf(${output!r}, 'chr{}/{}'.format(line[0], line[3]), mode = 'a', complevel = 9, complib = 'zlib')
with open("${output!n}.empty_genes", 'w') as f:
     f.write('\n'.join(empty_genes))

[recode_platform: shared = {'platform_info': 'output'}]
# Covariate "platform" needs to be recoded
parameter: attr_file = None
input: attr_file
output: "${input}.platform_info"
python:
import pandas as pd
samples = pd.read_csv(${input!r}, dtype=str, delimiter='\t', header=0)
res = [('SUBJID', 'GENO_PLATFORM')]
platform = []
for row in samples[['SAMPID', 'SMGEBTCHT', 'SMAFRZE']].values:
    if row[2] == 'WGS':
       row[0] = '-'.join(row[0].split('-')[:2])
       if not row[1] in platform:
          platform.append(row[1])
       res.append((row[0], str(platform.index(row[1]))))
with open(${output!r}, "w") as f:
    f.write('\n'.join([','.join(x) for x in res]))

[covariates_to_HDF5]
parameter: peer_factors = None
parameter: pc_file = None
parameter: covar_file = None
parameter: output_file = None
input: peer_factors, pc_file, covar_file, platform_info
output: output_file
python:
import os
import pandas as pd
if os.path.isfile(${output!ar}):
   os.remove(${output!ar})
pc = pd.read_csv(${pc_file!r}, header = None, sep = ' ', index_col = 1,
     names = ['fid','pid','mid','sex','phen'] + ["PC{}".format(i+1) for i in range(20)])[["PC1", "PC2", "PC3"]]
platform = pd.read_csv(${platform_info!r}, header = 0, sep = ',', index_col = 0)
covar = pd.read_csv(${covar_file!r}, header = 0, sep = '\t', index_col = 0)['SEX'].to_frame()
dat = covar.merge(platform, left_index = True, right_index = True)
dat = dat.merge(pc, left_index = True, right_index = True)
# Add PEER
for item in [${peer_factors!ar,}]:
    peer = pd.read_csv(item, header = 0, sep = '\t', index_col = 0).transpose()
    samples = {}
    for x in peer.index:
        samples[x] = dat.loc['-'.join(x.split('-')[:2])].tolist()
    samples = pd.DataFrame(samples).transpose()
    samples.columns = dat.columns
    samples = samples.merge(peer, left_index = True, right_index = True)
    samples.to_hdf(${output!ar}, '/{}'.format(os.path.basename(item[:-20])), mode = 'a', complevel = 9, complib = 'zlib')

[subset_HDF5_data]
# Given gene list, extract SNP and expression data from formatted database
parameter: ann_file = None
parameter: geno_file = None
parameter: expr_file = None
parameter: toy_file = None
parameter: gene_list = None
input: "${geno_file!a}", "${expr_file!a}"
output: "${toy_file!a}.genotype.h5", "${toy_file!a}.expr.h5"

python:
import pandas as pd
import os
# load gene annotation
ann = pd.read_csv(${ann_file!ar}, header = None, names = ['chr', 'gene'], sep = ' ', usecols = (0,3))
ann = {g:c for g, c in zip(ann['gene'], ann['chr'])}
# load gene list
genes = pd.read_csv(${gene_list!ar}, header = None)[0]
# purge existing toy
gfile = ${output[0]!r}
efile = ${output[1]!r}
if os.path.isfile(gfile):
   os.remove(gfile)
if os.path.isfile(efile):
   os.remove(efile)
# build toy
for g in genes:
    g = g.split('.')[0]
    if g not in ann:
       print("Gene {} not found".format(g))
       continue
    chrom = ann[g]
    geno = pd.read_hdf(${input[0]!r}, 'chr{}/{}'.format(chrom, g))
    geno.to_hdf(gfile, 'chr{}/{}'.format(chrom, g), mode = 'a', complevel = 9, complib = 'zlib')

for key in pd.HDFStore(${input[1]!r}).keys():
    expr = pd.read_hdf(${input[1]!r}, key).loc[genes]
    expr.to_hdf(efile, key, mode = 'a', complevel = 9, complib = 'zlib')
