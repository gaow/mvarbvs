{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Meetings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180913 meeting \n",
    "\n",
    "With Matthew.\n",
    "\n",
    "### Updates on `susieR`\n",
    "\n",
    "- worked with Kaiqian trying to finalize the sparse branch\n",
    "    - She'll come in herself in a separate meeting\n",
    "- do not want to make additional changes (discussed interface change) until Kaiqian's branch is merged\n",
    "    - no need to deal with merge conflicts like pro when we do not have to do it!\n",
    "\n",
    "### Updates since last manuscript meeting\n",
    "\n",
    "Gao\n",
    "\n",
    "- Appendix VB section mostly completed\n",
    "- Looked at single case examples\n",
    "\n",
    "Matthew\n",
    "\n",
    "- Went over the numerical comparison section with changes and suggestions\n",
    "\n",
    "### Todo now (by the end of this week)\n",
    "\n",
    "Gao\n",
    "\n",
    "- Go over again results section finalizing case examples from sQTL analysis\n",
    "- Adopt Matthew's suggestion re-organizing figures for the numerical comparison section\n",
    "\n",
    "\n",
    "Matthew\n",
    "\n",
    "- Another round at the Methods section & Appendix -- can leave some details for Gao to derive & fill up\n",
    "    - mostly a matter of style, or best practice guideline: what to show and what to hide, how generic we formulate things\n",
    "\n",
    "### Todo after above (before our meeting next week)\n",
    "\n",
    "Gao (also this weekend)\n",
    "\n",
    "- Draft a short discussion section as agreed\n",
    "- Fill up remaining details from Methods and Appendix that Matthew pointed out\n",
    "\n",
    "\n",
    "Matthew (hopefully next week)\n",
    "\n",
    "- A look at the results section\n",
    "- A look at the discussion section\n",
    "\n",
    "### Todo Wed Sept 19\n",
    "\n",
    "Hopefully we can discuss and write (together?)\n",
    "\n",
    "- The introduction section\n",
    "- The trend filtering application possibly as a small applications section.\n",
    "\n",
    "### Todo Fri Sept 21\n",
    "\n",
    "Hopefully we have some drafts of above to discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180910 Manuscript discussion\n",
    "\n",
    "### Methods\n",
    "\n",
    "- why use $1/\\tau$ to parameterize?\n",
    "- Should we output BF from SuSiE? We have `coef()` for coefficients. Need something for association testing?\n",
    "\n",
    "### Other stuff\n",
    "\n",
    "1. Data application\n",
    "    - Focusing on some case example -- but I want proven examples not just overlapping with motif stuff\n",
    "2. When should we introduce other methods: intro, motivating example, or numerical comparison? In particular when do we introduce DAP-G's signal cluster.\n",
    "3. Which section should we focus on finalizing next. More generally with what sequence should we start finalizing.\n",
    "    - I suggest Matthew focus on revising / re-writing Methods and Numerical examples\n",
    "    - Gao focus on adding case examples to Applications\n",
    "    - Gao will make updated draft to intro and discussion parts after discussing with Matthew today. \n",
    "4. Timeline: need to wrap up some errands Tue and Wed. Will finish up everything else by Monday next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180831 Updates\n",
    "\n",
    "### Questions\n",
    "\n",
    "- why use $1/\\tau$ to parameterize?\n",
    "- (2.6) $n$ because $X'X=n$?\n",
    "- Possible limitations: violation to additive? eg. joint \"interaction\" effect.\n",
    "- Should we output BF from SuSiE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180817 Updates\n",
    "\n",
    "1. The [CAVIAR inconsistency](https://gaow.github.io/mvarbvs/analysis/20180709_SplicingQTL_Detailed.html#SuSiE-with-L-=-5-but-estimated-prior-variance-125) issue is \"fixed\" by `estimate_prior_variance`\n",
    "2. But `estimate_prior_variance` [seems to have less power](https://github.com/stephenslab/susie-paper/blob/13d4332d5b122ba8138194ff5f6c9399ab8eb3c4/numerical_results/index.ipynb) in our numerical study, compared to [fixing it to 0.1](https://github.com/stephenslab/susie-paper/blob/280347deae3c267cef3fa39637b910a3a3735b7f/numerical_results/index.ipynb).\n",
    "3. And both above using susieR version 0.2 are less powerful compared to [using version 0.1](https://stephenslab.github.io/susie-paper/numerical_results/index.html).\n",
    "    - [diff between 0.1 and 0.2](https://github.com/stephenslab/susieR/blob/master/R/susie.R#L137)\n",
    "4. [Enrichment analysis updated](https://gaow.github.io/mvarbvs/analysis/20180712_Enrichment_Workflow.html#Unmatched-enrichment-analysis-19) and discussed with Yang.\n",
    "    - The result section of the manuscript has been updated\n",
    "5. [A website](https://stephenslab.github.io/susie-paper) was created for the manuscript. Every single analysis performed in the manuscript can be reproduced using information from this site.\n",
    "\n",
    "Next move:\n",
    "\n",
    "1. Which version of SuSiE to use? (see 1-3 above)\n",
    "    - possibly need to rerun splicing QTL analysis (should be very quick)\n",
    "1. Additional analysis for the manscript? \n",
    "2. Write it up now. Timeline on both our sides?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180711\n",
    "\n",
    "In person discussion with Matthew mostly on real data application results\n",
    "\n",
    "### Aganda\n",
    "\n",
    "1. Data section outline see overleaf\n",
    "2. [Some questions](https://gaow.github.io/mvarbvs/writeup/To_Explore.html) before interpreting the results\n",
    "    - should we start to interpret now, or to solve the prior and other issues first?\n",
    "3. The [bad case](https://gaow.github.io/mvarbvs/analysis/20180709_SplicingQTL_Detailed.html) and the [good case](https://gaow.github.io/mvarbvs/analysis/20180711_A_Hard_Case.html) -- do we discuss?\n",
    "4. Real data results -- figures for finemapping, and some [enrichment results](https://gaow.github.io/mvarbvs/analysis/20180712_Enrichment_Workflow.html).\n",
    "\n",
    "### Recap 3 issues on slack\n",
    "\n",
    "1. How to specify prior -- there is a difference in real data analysis, though not so much in simulation studies, because I do not have very large PVE simulated anyways.\n",
    "2. How to specify L -- as demonstrated in one of my other notebook with CAVIAR, it is perhaps not safe to set a large L\n",
    "3. Issue 21, same signal captured by 2 CS.\n",
    "\n",
    "### TODO for manuscript\n",
    "\n",
    "1. [after DSC rerun] [not urgent] Figure 2: find a new way to plot such that the PRC is nicer. Possibly [the grenander estimator](https://www.rdocumentation.org/packages/modeest/versions/2.1/topics/grenander).\n",
    "2. [after DSC rerun] Make Figure 3 shorter and use same bin-width\n",
    "3. [July 17] Figure 4 goes to supplemental material\n",
    "4. [after DSC rerun] Table 1 make a plot of it. Bar plot of 4 panels. The table itself goes to supplemental\n",
    "5. [July 18] Version number FINEMAP (1.1), CAVIAR and DAP-G\n",
    "6. [July 19] Rewrite complexity analysis. Only do it for susie. Do not review that for other methods.\n",
    "    - susie is either NLP or LP^2\n",
    "7. [July 20] Explain in the text DAP intervals -- tries to acheive the same thing as we do, but not as natural\n",
    "8. [July 21] Review how other paper define CS? eg, Maller 2012?\n",
    "9. [July 22 - 24] Add result for splicing analysis first draft\n",
    "10. [July 25 - 29] Add the motivating example first draft\n",
    "\n",
    "### Rerun DSC\n",
    "\n",
    "- [July 18] Because of susieR version 0.2 update! But I think this is also a good chance for me to start `susie-paper` website to process DSC results and show people how each figure / table is reproduced.\n",
    "- Add an option to use susieR estimate prior variance!\n",
    "- Put together the susie-paper website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180702\n",
    "\n",
    "In person discussion with Matthew on manuscript and next steps\n",
    "\n",
    "### Timeline\n",
    "\n",
    "July 2 - July 12\n",
    "\n",
    "- Data results on molecular QTL. See outline in the overleaf manuscript draft\n",
    "- Meeting with Matthew on July 12 to discuss data results, if completed to some digree ...\n",
    "\n",
    "July 13 - July 25\n",
    "\n",
    "- Start working on multivariate again. \n",
    "- Finish up ELBO derivation following from FLASH (or better, susie?)\n",
    "    - Current version ELBO is based on FLASH paper but does not always increase ...\n",
    "- Fix a couple of bugs in M&M code\n",
    "- Make it based on summary statistics only.\n",
    "- Start a new overleaf document to put in these methods details\n",
    "\n",
    "July 25 - Aug 7\n",
    "\n",
    "- Implement a DSC for multivariate simulation and analysis, comparing M&M with susie\n",
    "\n",
    "Aug 7 - Aug 17\n",
    "\n",
    "- Another round of edits to both susie and M&M paper\n",
    "\n",
    "Aug 17 \n",
    "\n",
    "- Meeting with Matthew to discuss susie timeline and finish up susie paper\n",
    "- Meeting with Matthew to discuss M&M application\n",
    "    - I'd like to also throw in enrichment based priors\n",
    "    - Not tissue specific annotations yet, but very simple and well established ones, eg physical position, footprint\n",
    "    - Maybe look at Yang's data again in addition to GTEx data\n",
    "    \n",
    "Hope to finish up susie paper Sept 15, and the first draft of M&M paper with applications by the end of 2018. That is, we'll have 3 months on multivariate data analysis part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180618\n",
    "\n",
    "Slack discussion with Matthew on manuscript outline.\n",
    "\n",
    "### RE \"default susie\"\n",
    "\n",
    "- Default `estimate_residual_variance` set to `TRUE`.\n",
    "- By default we scale and center X so that prior becomes PVE.\n",
    "- Choice of Prior: \n",
    "    - Option 1: we show in our numerical studies prior = 0.1 for all scenarios. We show in supplemental that results do not change that much with other values.\n",
    "    - Option 2: as discussed [in this ticket](https://github.com/stephenslab/susieR/issues/10) we can potentially estimate it.\n",
    "\n",
    "### Result section\n",
    "\n",
    "*Note: all figures will be updated to reflect a fix in my simulation code, and to incorporate twice more replicates in the new simulation run*\n",
    "\n",
    "1. Show Bayesian CS followed by a \"purity\" filter is good enough in the context of genetic fine-mapping. \n",
    "    - For given scenario the [purity vs size plot](https://gaow.github.io/mvarbvs/analysis/20180515_SusieR_Benchmark.html#2-signals-+-20%-PVE-+-est_residual=FALSE)\n",
    "    - For 95% CS across pooled scenarios a histogram of purity (**to be plotted**) and the [capture rate as purity threshold changes](https://gaow.github.io/mvarbvs/details/20180515_SuSiE_Benchmark.html#How-do-we-define-mappable-CS)\n",
    "    - For different coverage of CS, show that [false discover proportion is under control](https://gaow.github.io/mvarbvs/analysis/20180606_Coverage_Check.html) -- **this table is to be re-generated using the new `get_susie_CS` function rather than external Python script**. This is to ensure others can reproduce exactly what we offer for the manuscript.\n",
    "\n",
    "2. Show SNP level PIP and ROC\n",
    "    - Consistency of PIP with [other methods](https://gaow.github.io/mvarbvs/analysis/20180527_PIP_Comparison.html#susie-est_var-vs-CAVIAR-154) including susie, caviar, DAP and FINEMAP (**Need to add in FINEMAP V1.1 results**)\n",
    "    - [Calibrated PIP](https://gaow.github.io/mvarbvs/analysis/20180605_PIP_Calibrated.html) in comparison with the truth, also showing DAP, CAVIAR and FINEMAP results with the truth (**Need to add in FINEMAP V1.1 results**).\n",
    "    - [ROC](https://gaow.github.io/mvarbvs/analysis/20180606_ROC.html) in comparison with DAP, CAVIAR and FINEMAP (**Need to add in FINEMAP V1.1 results**; **also make Y-axis start at zero**).\n",
    "    \n",
    "3. Comparison of susie CS with DAP cluster\n",
    "    - For [simpler cases](https://gaow.github.io/mvarbvs/analysis/20180528_Power_Comparison.html#susie-est_var-vs-DAP)\n",
    "    - For [harder case](https://gaow.github.io/mvarbvs/analysis/20180615_Power_DAP.html#Power-comparison,-susie-VS-DAP,-for-~8K-region)\n",
    "    \n",
    "4. Compare speed of `susieR` vs `dap-g`\n",
    "    - **Need to pull and average from DSC results**\n",
    "    - For susieR: we do use ELBO to check for convergence -- should I use line-profiler to get an idea how long the ELBO takes and give an estimate of using $\\alpha$ convergence instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180607\n",
    "\n",
    "Meeting with Matthew. \n",
    "\n",
    "### Aganda\n",
    "\n",
    "- Look together sets comparison between DAP and Susie in \"Power\" and FDP.\n",
    "- Discuss data applications.\n",
    "- Discuss additional simulation.\n",
    "\n",
    "### TODO\n",
    "\n",
    "- [] Double-check DAP's reported LD agree with what I compute, for the 1 causal case in particular\n",
    "- [X] Re-plot PIP-based ROC focusing on PIP thresholds of interest (zoom-in on X-axis)\n",
    "- [X] Use Median sample size for the power table\n",
    "- [X] Create simulation using ~7K variants with 10 causal, show susie method scales but DAP's heuristics may have issues\n",
    "- [X] Bring back FINEMAP version < May 9, 2018 to the DSC -- the goal is to reassure that DAP indeed outperforms CAVIAR and FINEMAP\n",
    "  - make plots of susie vs FINEMAP and DAP vs FINEMAP\n",
    "- [X] Rerun all DSC -- fix that \"dollar bet\" mistake on `random.normal(mean, sd)` issue ...\n",
    "- [] Take that single example from CAVIAR paper (or other single examples) just quickly checkout if anything interesting shows up\n",
    "- [X] Talk to Kevin on his molecular QTL data. We decide to do data application outside GTEx eQTL for various reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180529\n",
    "\n",
    "Meeting with Matthew.\n",
    "\n",
    "### Aganda\n",
    "\n",
    "- Project status: simulation studies mostly done. Starting to analyzing data.\n",
    "- Mostly done -- get some more CAVIAR results, double-check DAP. Maybe get an old version of FINEMAP to work? Or just ignore it and move on?\n",
    "\n",
    "### Questions\n",
    "\n",
    "- Show why the VB removes those in LD by putting them in one CS. But not eleminating signals -- need some proof, or at least some quantification\n",
    "    - Input: LD. (maybe also say why 0.2 is good enough?)\n",
    "    - Output: weights in set 1, weights in set 2.\n",
    "    - When can two truely independent and significant signals go into one set?\n",
    "- [This case](http://shiny.stephenslab.uchicago.edu/gaow/susie_html_20180516/liter_data_4_summarize_ld_1_simple_lm_13_fit_susie_6_plot_susie_1.seg.1.png): it is just what it is?\n",
    "- Goal of project: finemapping, heritability estimate, prediction. What if people are interested in the others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20180417\n",
    "\n",
    "Meeting with Matthew\n",
    "\n",
    "### Aganda\n",
    "\n",
    "- [M&M results](https://gaow.github.io/mvarbvs/analysis/20180415_MNMASH_FMO2.html), compared with [univeraite methods](https://gaow.github.io/mvarbvs/analysis/20180416_SingleCondition_FMO2.html).\n",
    "- [Output of M&M](https://gaow.github.io/mvarbvs/analysis/20180416_mnm_model.html): quantites of interest. Check if they are right.\n",
    "- [Initialization with mash](https://gaow.github.io/mvarbvs/analysis/20180416_mnm_model.html): use of point mass.\n",
    "- [ELBO computation](https://gaow.github.io/mvarbvs/writeup/14b5a0ba68cc2757033109c267a409fcef2ac7c2.html#Derivation-of-ELBO-15) difficuty: low rank mash prior matrices.\n",
    "- MASH paper revision\n",
    "\n",
    "### Need to fix\n",
    "\n",
    "- Computation of lfsr. Currently I'm conceptually wrong. The lfsr we report for the new model should be per value per set of SNPs (per condition). \"Set of SNPs\" is reflected by the $L$ effects in our model. When there is only one SNP in the set of SNPs the lfsr natually becomes lfsr for this SNP\n",
    "- We can compute lfdr for our own information but should not report\n",
    "\n",
    "### To catch up in writing\n",
    "\n",
    "- How lfsr are computed and interpreted\n",
    "- How and why are the 3 quantities of interest defined (maybe use a separate notebook to explain the motivations)\n",
    "- New method to computer ELBO\n",
    "\n",
    "### What to report from M&M?\n",
    "\n",
    "To convey the core idea of our new fine-mapping approach we'd like to report these quantities:\n",
    "\n",
    "1. SNP level: Identify for each of the $L$ effects 95% HPD interval, report its size (number of SNPs in the set), purity (smallest pair-wise LD means higher purity) and lfsr (or, minimum lfsr). There should be high correlation between small size, high purity and low lfsr. We can visualize this, and determine a threshold of $L_0$ to report.\n",
    "\n",
    "2. Finemapping results: Once we have determined $L_0$ above, we can imaging having a browser of these sets where we report for SNPs posterior probability of being an eQTL by plotting those HPD identified above. The posterior probability is just posterior of $\\alpha$. In normal cases these sets should not overlap.\n",
    "\n",
    "3. Effect estimate: For tissue level summary, we can click on each of the sets plotted and display a metaplot for averaged effect size and standard error bars.\n",
    "\n",
    "### Next steps\n",
    "\n",
    "- Get ELBO work -- deal with low rank matrix computations in the prior and KL part.\n",
    "- Make M&M report as discussed above.\n",
    "- More comparisons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20171210\n",
    "Meeting with Matthew\n",
    "\n",
    "### Agenda\n",
    "\n",
    "GTEx related\n",
    "- New genotype uploaded along with updated results (including eQTL results); will be ready mid-week\n",
    "  - MASH results: to wait for Zarlab or to produce results as is.\n",
    "- [Summary of GTEx fine-mapping group meeting](https://github.com/stephenslab/gtex-eqtls/blob/master/writeup/Meetings.ipynb)\n",
    "  - Relevance to new-vb (or Susie)\n",
    "  - Relevance to DSC (results exploration)\n",
    "  \n",
    "M&M related:\n",
    "- [Algorithm](https://www.overleaf.com/12276327wvnnmbmpwzbw#/46670603/)\n",
    "  - [Derive ELBO](https://stephens999.github.io/misc/newVB.ss.html)\n",
    "- [Simulation plan](https://notebooks.azure.com/n/3F9GLgPZuZY/notebooks/20171210_Simulation_Multivariate.ipynb#Multivariate-simulation): scenarios and scores\n",
    "  - Scenarios\n",
    "    - Is the current theme good enough to include all special cases?\n",
    "    - What other simulations will be needed?\n",
    "  - Scores\n",
    "    - Check CI\n",
    "    - Check lfsr\n",
    "- Computation\n",
    "\n",
    "## 20171127\n",
    "\n",
    "Meeting with Matthew and Abhishek. Mostly we discussed big pictures of motivation and intuition of this proposed VB algorithm / parameterization based on the spike-slab model, and action lists for the next steps.\n",
    "\n",
    "We discussed comparison with MCMC based methods. One big selling point with the VB method is the novelty in defining and interpreting the term \"fine-mapping\". We believe our definition is more reasonable, and our method will natually lead to easily interpreable results. We envisage that by re-defining fine-mapping our way, we avoid situations that conventional methods may struggle with when doing fine-mapping the way they define it.\n",
    "\n",
    "We also discussed intuition behind the proposed parameterization and the VB algorithm that results in the particular structure of posterior distribution that we can exploit, i.e., posteriors at $L$ blocks. In this case, the model (parameterization of prior) was in fact motivated by the form of the algorithm deviced to result in the posterior structure. \n",
    "\n",
    "There are a few things in single-tissue application that we will consider next:\n",
    "\n",
    "1. Estimating (or fix?) hyper-parameters $\\sigma$, $\\sigma_b$\n",
    "2. Incorporate prior $\\pi_j$: estimate or plug-in?\n",
    "3. Work with summary statistics\n",
    "\n",
    "We believe these are good enough (even without 3) as first pass to figuring out the foundamentals of this approach, and readily apply to eQTL mapping. Other actions are needed to extand to other contexts (GWAS, variationQTL, etc) that we can worry about next.\n",
    "\n",
    "We have not discussed multivariate applications in this meeting. But we agree that multivariate application can be done in parallel with single tissue analysis, and we focus on harvesting low-hanging fruits in GTEx data as first pass. The proposed method can utilize existing MASH computations. I also have implemented a version (in Python) following Matthew's outline; hopefully I'll get it to work later this week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20171120\n",
    "\n",
    "Meeting with Matthew\n",
    "\n",
    "Discussions on [this derivation](https://stephens999.github.io/misc/newVB.ss.html)\n",
    "- Exactly one element is zero -- because sum of $\\pi$'s for $p$ SNPs is 1?\n",
    "- What to choose for $L$? \n",
    "- \"Similarly we can optimize F2 over q1 with q2 fixed the same way.\" -- for multiple SNP case, each time we fix all other $q$'s except for one? does the ordering of $L$ imply \"importance\"\n",
    "- function `single_snp` is not sparse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20171115\n",
    "\n",
    "Meeting with Matthew\n",
    "\n",
    "### mr-ash\n",
    "\n",
    "Showed results of analysis on 3 tissues. We have simulation and some real data results so far on mr-ash. But real data results has \"stability\" or \"inconsistency\" issues. \n",
    "\n",
    "We decide to move from mr-ash for now. Eventually it can be used (in comparison with other methods) as a tool for prediction. The real data example is precisely the reason why it is not good for fine-mapping (I think we wanted to do fine-mapping differently anyways by adding an additional MCMC step).\n",
    "\n",
    "### m&m model\n",
    "\n",
    "Comments on current model implementation\n",
    "* Change notation: $t$ to $p$, $V$ to $\\Sigma$, to match with MASH notation\n",
    "* Notation: $\\xi_j$ vs $\\hat{b}_j$. The latter is both more clear and confusing in its own way\n",
    "* We remove prior on $\\Lambda$. Just say it's MLE\n",
    "* Missing values: do not attempt to impute in the updates. Just ignore them in computing updates \n",
    "  * by properly setting elements in matrices & vectors to zeros\n",
    "* Numeric issue: use difference of log of multivariate normal densities, rather than ratio of densities.\n",
    "\n",
    "Tips on debugging current model\n",
    "* Use one tissue special case to debug, compare with mr-ash\n",
    "* Maybe give up this model (which is a multivariate version of mr-ash) and use the `finemap-vb` model instead as the basis\n",
    "  * Check out this [outline](https://stephens999.github.io/misc/newVB.html) and generalize to multivariate case\n",
    "  * Also checkout Abhishek's [this](https://aksarkar.github.io/nwas/finemap.html) and [that](https://aksarkar.github.io/nwas/prior.html#orgec6e69e).\n",
    "  \n",
    "### Next move\n",
    "\n",
    "I'm tempted to go over Matthew's newVB vignette, try to write up the basic model in a separate prototying Jupyter notebook and move my code for [the model I have](https://gaow.github.io/mvarbvs/prototype/20171103_MNMASH_Model.html) to this new framework. As discussed I'll keep track of and integrate to it progress on Abhishek and Peter's ends, and setup the GTEx data analysis infrastructure like we did for mash and mr-ash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 20171005 m&m fine mapping meeting\n",
    "\n",
    "With Peter (mostly) and Matthew (briefly). We discussed various stuff on current modeling steps 1 and 2, making sure we are on the same page. \n",
    "\n",
    "![](figures/IMG_20171005_1.jpg)\n",
    "\n",
    "We then discussed a simple MH sampling scheme. The key is, as suggested by Matthew and formalized by Peter, to sample 2 SNPs jointly at each move.\n",
    "\n",
    "![](figures/IMG_20171005_2.jpg)\n",
    "\n",
    "Gao will work out the algorithm details and a draft implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Project meeting 20170630\n",
    "With Matthew and Wei on simulation and some real data results. We mostly finished discussing [this notebook](../analysis/20170630_Simulation_Results.html). We've mostly focused on the situation when there is very dense true signal yet `mr-ash` cannot recover any of them.\n",
    "\n",
    "Some interesting discussions are:\n",
    "\n",
    "1. Why do we see ASH over-shrink the effect size? One intuition is that the $s$ we feed to ash are estimates from univariate regresiosn, which is different from the (proper) estimate of residual variance comparing the model with/without the corresponding SNP. It may be an over-estimate thus effectively over-shrink $\\hat{\\beta}$\n",
    "2. Relevant to 1: when using ASH estimates either as initialization values for `mr-ash`, or for prediction of response, we should scale it by a factor of $c$ such that $||Y-c\\hat{\\beta}||^2$ is minimized.\n",
    "3. To rule out any potential convergence issue, we should initialize at some \"good\" estimates, eg, from `ash` (scaled), and look at the variational lower bound to see if it improves. Another initialization would be result from ridge regression -- none of the effects will be zero.\n",
    "4. We can try to simulate from a simple model, the LMM, which has close form solution. We can see how well we fit. In fact this seemingly simple model can be a difficult problem to solve in given circumstances! Suppose we have $$Y=X\\beta+E$$ $$\\beta \\sim N(0, \\sigma_\\beta^2I)$$ then $$Y \\sim N(0, \\sigma_\\beta^2XX^T+\\sigma_e^2I)$$ When $XX^T$ is identity, estimates for $\\sigma_\\beta$ and $\\sigma_e$ are not identifiable. This may explain why `mr-ash` failed to recover any signal when there is no correlation between columns of $X$. \n",
    "\n",
    "Next steps:\n",
    "1. Simulate and fit under LMM model, also fit that simple simulation to `mr-ash`. Check out `BoltLMM` paper from Price Lab.\n",
    "2. Try make predictions with `mr-ash` and `ash` results and see how well it works\n",
    "3. Minor fix: include z-scores in diagnostic plots\n",
    "\n",
    "\n",
    "## Project meeting 20170615\n",
    "With Matthew on simulation results\n",
    "\n",
    "* Analyze with ASH and see what to exploit\n",
    "* Try simulation with very big \\sigma$ and observe the distribution of estimates\n",
    "\n",
    "Diagnostics:\n",
    "* Distribution of effects\n",
    "* Use averaged CDF: see ASH paper\n",
    "* Simulate scenarios where there is qualitative differences and see if mr-ash can capture that\n",
    "* Look at estimate of $\\sigma^2$\n",
    "\n",
    "Comparison with other methods:\n",
    "\n",
    "* Simulate 2 mixture normal and compare with GEMMA\n",
    "* Compare with rss-ash\n",
    "\n",
    "## Project meeting 20170518\n",
    "\n",
    "With Matthew on issues with GTEx V7 preprocessing.\n",
    "\n",
    "Questions:\n",
    "* Normalization: why qnorm? should I standardize it? should I do per-tissue qnorm then standardize them?\n",
    "* PEER: should I do per-tissue or altogether? If altogether should I add tissue as a covariate? \n",
    "   * Variable number of PEER with GTEx V6 -- what's the deal with V7 now?\n",
    "* Analysis: should I remove PEER + covariates first for each gene and then run mr-ash?\n",
    "* Any additional concerns with imputed genotypes?\n",
    "\n",
    "Feedback:\n",
    "* We do quantile normalization because it is the most robust. And our model assumes normal.\n",
    "  * potential issue with RPKM: if some genes are extremely highly expressed they will impact other genes's RPKM\n",
    "* No good answer to whether or not we adopt alternative stretagy. We should stick to one defensible strategy which easily is the [official GTEx guideline](https://gtexportal.org/home/documentationPage#staticTextAnalysisMethods).\n",
    "* We can use multiple regression to remove residue first. Potential issue is that we may over-correct but the gain in power is well worth the possible loss. Just make sure we keep P << N so that degree of freedom change is not that big. GTEx official procedure has some guideline on how many PEER to use.\n",
    "\n",
    "\n",
    "## Project meeting 20170502\n",
    "With Matthew and Wei. We discussed mostly the fine-mapping step of m&m, and some mr-ash related issues. First and foremost, we make it clear that focus of m&m should be constrained to eQTL fine mapping for now because it is an important problem that has not been answered in the multivariate framework we propose. \n",
    "\n",
    "Although we are interested in fine mapping eventually, it is perhaps too premature to make very concrete plan until we see the data analysis outcome from Step 2 the mash step (this comment was made in response to my initial request to finalize the fine mapping MCMC algorithm, and instead we brainstormed on what can be possibly done to perform fine mapping).\n",
    "\n",
    "### How to summarize fine mapping results?\n",
    "\n",
    "Sparse vs non-sparse result: \n",
    "\n",
    "* If we adopt a none sparse model it is not good idea to evaluate whether $\\beta=0$ -- we may want to look at correctness of the sign instead. \n",
    "* Result under a sparse model is potentially computationally easy. Example see Wen 2016 DAP paper. Or we can even look at one eQTL per gene model, or two eQTL per gene (thus a combination of ~2000 cis SNPs choose 2 pairs), at the fine-mapping step.\n",
    "\n",
    "What should be the output of fine mapping?\n",
    "* One version is to output each SNP's LD with the eQTL\n",
    "* We can also output the 95% CI for the LD estimate with eQTL and see if it covers complete LD\n",
    "  * But which one is the eQTL?\n",
    "* Or we can output the set of SNPs that we have 95% confidence that the set includes the eQTL (see Eskin)\n",
    "* We want to show that for given SNP, what is the nearest eQTL: what is the distance of this SNP to the nearest eQTL? what is the highest LD between this SNP and an eQTL?\n",
    "* Given MCMC result, how do we summarize it? \n",
    "  * What should we do if we want to use the results for data intergration? \n",
    "  * We may want a mode, not a flat PIP from MCMC\n",
    "  * We can take samples from posterior, then for each sample perform intergation analysis, and access the variance / sensitivity of results (how robust the conclusion is). And somehow combine the results. This is similar to the idea of multiple imputation.\n",
    "\n",
    "What can we learn directly from Step 2 the mash step?\n",
    "* If we go a bit further computing the lfsr and posterior mean of effects, we can get the \"mode\" candidate for eQTL, ie, we can then perform fine mapping around the mode. \n",
    "\n",
    "It is also perhaps too early to make any meaningful envision on what to do with finemapping, before looking into the data:\n",
    "* How uncertain are the results we'll end up getting? Maybe LD is not a big issue in many of the new eQTLs we identify, which by itself would be exciting results.\n",
    "\n",
    "### Where do we stop for mr-ash application\n",
    "We want to start the mr-ash paper by saying that there is great interest in introducing sparsity in regression, and recently there is a method called ash that introduces it in a \"smart\" way, and how it is relatively straightforward to use the ash idea in the context of regression.\n",
    "\n",
    "The strength of mr-ash is the computational efficiency (VEM) and the flexibility (ASH compared to spike-slab), but there are disadvantages (PIP is too concentrated, see Carbonatto 2012). \n",
    "\n",
    "In data application we can show how different the distribution of effect size of eQTL is, across genes. We can focus on a single tissue, fit separate mr-ash for each gene, and comment on interesting patterns that emerges; or we can use meta-analysis for multiple tissues on genes of interest, if there is not enough power from single tissue analysis.\n",
    "\n",
    "## Project meeting 20170417\n",
    "Meeting with Matthew. We went through the m&m procedure on overleaf, revisited issue 8 on github and talked about next steps on data analysis + simulations. The discussion has led to minor changes in the overleaf write up.\n",
    "\n",
    "Additionally we decide that the next step should be getting *Step 1* done, ie, mr-ash on GTEx data. We will start with analyzing GTEx V6 and verify with mash result, then move on to V7 data. *Step 1* would be an interesting application by itself as it is some form of univariate fine-mapping.\n",
    "\n",
    "\n",
    "## Project meeting 20170330\n",
    "Meeting with Matthew and Wei, to revive the project, by looking at what we have and what to be done. \n",
    "\n",
    "### Tentative agenda\n",
    "\n",
    "#### Connected work\n",
    "\n",
    "* varbvs\n",
    "* rss\n",
    "* ash\n",
    "* mash\n",
    "* mrash\n",
    "* BMASS\n",
    "\n",
    "### Questions\n",
    "\n",
    "* How can m&m ash generalize all theses work\n",
    "  * We have to think carefully what to incorperate in the generalized framework, and how to incorporate them\n",
    "  * In particular how can we combine mrash / rss + mash?\n",
    "* Do we start from summary statistics or full data?\n",
    "* Do we need MCMC in addition to VEM?\n",
    "\n",
    "Implementation-wise, shall we not write any code until we finalize on how the generalized framework is formulated? We should think \"modularly\" and we make contributions directly to other modules whenever possible, then build m&m ash with these modules.\n",
    "\n",
    "### What to do with `mrash` as a standalone work?\n",
    "If we start from full data then finalizing `mrash` is a natural first step. It is then just a discussion of whether to create a separate package or to make it part of varbvs.\n",
    "\n",
    "### Minutes\n",
    "The meeting has outlined the approach we take towards a modularized m&m. Most items on the agenda has been covered. See [this document](Modular_MNMASH.html) for details. \n",
    "\n",
    "## Project meeting 20161103\n",
    "Meeting with Matthew. We started from recap on the motivation of project, then discussed the M&M ASH model with practical considerations.\n",
    "\n",
    "### Motivation\n",
    "M&M ASH model is motivated by what we have noticed in the MASH project. We have observed effect of a SNP (eQTL) positive in one tissue yet negative in another tissue. This bothers us. We suspect this type of observation is most likely due to negative LD between two causal SNPs both having positive effect in two separate tissues yet if we make the one eQTL per gene assumption as made in MASH we will observe opposite effects. So if we assume SNPs are independent in association analysis we obtain $\\hat{\\beta}$ convoluted by LD of all SNPs. \n",
    "\n",
    "Let's consider univariate association analysis for a moment. Because of LD, $g(.)$, the distribution of $\\beta$ we estimate via univariate methods, would have long tails. In other words $g(.)$ is inflated by LD with other SNPs. Estimates of $g(.)$ from multiple regression with ASH prior via variantional EM (currently called MVASH) will not have this problem. However when we want to make inference on $\\beta$ the effect size, there will be identifiability issue with MVASH because VEM can reach local optima and the effect size it reports for the SNP identified may not be the SNP that in fact has an effect. The solution to this problem is to use MCMC for fine mapping on selected regions via VEM. A hybrid approach is to estimate hyper-parameters via VEM and use MCMC to sample the posterior.\n",
    "\n",
    "Now to solve the same issue in the context of multivariate regression, we propose the M&M ASH model, which applies multiple regression using ASH prior on multiple responses. David Gerard has derived a VEM procedure for the M&M model. Assumptions in David's derivations are: \n",
    "\n",
    "* The residual variance of genes (after regressing out eQTL effect) is structured low rank + diagonal\n",
    "* There will be missing data in the response matrix\n",
    "* The mixture proportion can be estimated per test, or be estimated jointly for all tests\n",
    "\n",
    "### M&M ASH with diagonal residual covariance structure\n",
    "\n",
    "Matthew suggests we make this model simpler and make sure it works. For starters we should ignore correlation among tissues. That is, we assume residual variance a diagonal matrix. Here are a few points why we should start with diagonal and why at least as a first pass we should not make non-diagonal assumption in M&M ASH:\n",
    "\n",
    "* We are not sure yet if correlated residual will cause a problem to our inference -- unless we can show it empirically: we should find real data examples when correlation between tissues are due to correlation between genes, not due to similarity of tissues. This would raise a red flag that we should model such correlations.\n",
    "* Even if the problem is confirmed we should use MASH model to show we can solve it, before incorporating the solution to M&M ASH. As MASH model is simpler, it will get us assessment from real data quickly and we'll decide if it worth to pursue the fix in M&M ASH.\n",
    "* To do it in MASH we should assume this residual correlation is the same as the tissues' correlations (eQTL effect is relatively small) and we estimate the 44 by 44 matrix of covariance directly from expression data. This is not a trivial problem; many methods get estimates that shrink the structure to diagonal. But sparse factor analysis methods can be a good technique to do this, as shown by Wei's work. We then plug this estimate to MASH model\n",
    "  * The advantage of this approach (over making inference jointly as what David has done for M&M ASH) is that this approach is modular and we can choose a good method (such as SFA, FLASH) to make this step of inference. The method may be biased (ignoring impact of eQTL) but has better variance\n",
    "* The problem with this approach is that if eQTL induces correlation we'll wrongfully believe there is residual covariance when in fact there is not. That is, after removing effect from eQTL the residual covariance is diagonal. This observation would favor the joint approach over the modular approach. To assess if this is a problem, we can choose genes with large covariance matrix, and remove the effect of top eQTL then see if the residual covariance matrix still retains correlations or is mostly diagonal.\n",
    "\n",
    "### Next steps\n",
    "We should start with the simplest version (that residual covariance is diagonal) and make it work. The hard part is computation. Using summary data whenever possible may help with computation. Additionally in updating mixture components we can use noiser estimates, that is, estimates from randomly sampled \\beta{hat} instead of 20K genes * 1000 SNPs * 50 conditions data points. We will have our next meeting (David and Gao with Matthew) after we get this simple version to work in practice.\n",
    "\n",
    "## Project meeting 20160921\n",
    "### Tentative schedule\n",
    "Status\n",
    "* The `m&m ash` [model](http://www.bioinformatics.org/labnotes/mnmash/mnmash-model.html) and [implementation](https://github.com/gaow/mnmashr).\n",
    "* Implementation is not working on data due to [data structure design](https://github.com/gaow/mnmashr/blob/master/src/mnmash.hpp#L41)\n",
    "  * When J is 40, P 2000, K 50 and L 20, the S and SI matrices will be of size 3.2G * 2 = 6.4G. Looping over such data is very slow.\n",
    "* Correctness of implementation not tested\n",
    "\n",
    "Next steps\n",
    "* Get implementation working\n",
    "* Run simulations\n",
    "* Put into OmicsBMA framework and do real data anlaysis\n",
    "\n",
    "### Minutes\n",
    "* We should conceptually distinguish a model using original data from the one using summary data, though in the VB algorithm they are very similar.\n",
    "* Currently the model assumes $\\Sigma_{J \\times J}$ known. This is not easy to estimate because it would involve a non-trivial multiple regression. We should try to model $\\Sigma_{J \\times J}$ as unknown diagonal matrix and estimate it in the VB framework. For starters, write up the J = 1 case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "celltoolbar": true,
   "default_kernel": "SoS",
   "kernels": [],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.16.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
