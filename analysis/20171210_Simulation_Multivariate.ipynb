{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of multiple phenotypes given genotypes and covariance\n",
    "Here we simulate effect size from mixture gaussian distribution and match strong effects with \"heavily LD convoluted\" SNPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, random\n",
    "\n",
    "class PhenotypeSimulator:\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "        self.Y = None\n",
    "        self.B = None\n",
    "        self.ld = None\n",
    "    \n",
    "    def permute_X(self):\n",
    "        # break LD structure\n",
    "        np.random.shuffle(self.X)\n",
    "\n",
    "    def get_ld(self, save_to = None):\n",
    "        '''r^2 based LD calculation'''\n",
    "        self.ld = np.corrcoef(self.X, rowvar = False)\n",
    "        self.ld = (np.square(self.ld) * np.sign(self.ld)).astype(np.float16)\n",
    "        if save_to is not None:\n",
    "            if os.path.isfile(save_to):\n",
    "                os.remove(save_to)\n",
    "            np.save(save_to, self.ld)\n",
    "    \n",
    "    def load_ld(self, fn):\n",
    "        self.ld = np.load(fn)\n",
    "    \n",
    "    def ld_heatmap(self, out):\n",
    "        use_abs = np.sum((self.ld < 0).values.ravel()) == 0\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, ax = plt.subplots()\n",
    "        cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=1, dark=0, as_cmap=True)\n",
    "        sns.heatmap(self.ld, ax = ax, cmap = cmap, vmin=-1 if not use_abs else 0, \n",
    "                    vmax=1, square=True, xticklabels = False, yticklabels = False)\n",
    "        plt.savefig(out, dpi = 500)\n",
    "        \n",
    "    def generate_B(self, pis, U, pi0 = 0):\n",
    "        '''\n",
    "        beta ~ \\pi_0\\delta_0 + \\sum \\pi_i N_R(0, wU)\n",
    "        '''\n",
    "        self.B = np.zeros((self.X.shape[1], U[0].shape[0]))\n",
    "        nbeta = self.B.shape[0]\n",
    "        mus = np.zeros(self.B.shape[1])\n",
    "        for j in range(nbeta):\n",
    "            if np.random.binomial(1, 1 - pi0, size = 1) > 0:\n",
    "                sigma = U[np.random.multinomial(1, pis, size = 1).tolist()[0].index(1)]\n",
    "                self.B[j,:] = np.random.multivariate_normal(mus, sigma, 1)\n",
    "    \n",
    "    def generate_Y(self, sigma):\n",
    "        self.Y = self.X @ self.B + np.random.multivariate_normal(np.zeros(self.B.shape[1]), sigma)\n",
    "    \n",
    "    def select_convoluted_snps(self, cutoff1 = 0.8, cutoff2 = 10, cutoff3 = 0.01):\n",
    "        '''based on LD matrix select SNPs in strong LD with other SNPs \n",
    "        yet are independent between themselves'''\n",
    "        print('Count strong LD')\n",
    "        import pandas as pd\n",
    "        ld = pd.DataFrame(self.ld)\n",
    "        strong_ld_count = ((np.absolute(ld) > cutoff1) * ld).sum(axis = 0).sort_values(ascending = False)\n",
    "        strong_ld_count = strong_ld_count[strong_ld_count > cutoff2]\n",
    "        print('Filter by LD')\n",
    "        exclude = []\n",
    "        for x in strong_ld_count.index:\n",
    "            if x in exclude:\n",
    "                continue\n",
    "            for y in strong_ld_count.index:\n",
    "                if y in exclude or y == x:\n",
    "                    continue\n",
    "                if np.absolute(ld[x][y]) > cutoff3:\n",
    "                    exclude.append(y)\n",
    "        print('Done')\n",
    "        return [i for i, x in enumerate(strong_ld_count.index) if not x in exclude]\n",
    "    \n",
    "    def swap_B(self, strength_index):\n",
    "        '''Set tops of beta to tops in strength_index'''\n",
    "        nb = np.zeros(self.B.shape)\n",
    "        beta_max = np.amax(np.absolute(self.B), axis = 1)\n",
    "        big_beta_index = [i[0] for i in sorted(enumerate(beta_max), key = lambda x: x[1], reverse = True)]\n",
    "        random.shuffle(big_beta_index)\n",
    "        for item in strength_index:\n",
    "            nb[item,:] = self.B[big_beta_index.pop(0),:]\n",
    "        for idx in range(nb.shape[0]):\n",
    "            if not idx in strength_index:\n",
    "                nb[idx,:] = self.B[big_beta_index.pop(0),:]\n",
    "        self.B = nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "dat = readRDS('/home/gaow/Documents/GTExV8/Thyroid.Lung.FMO2.filled.rds')\n",
    "attach(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "%get X Y --from R\n",
    "Y = Y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "model = PhenotypeSimulator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "model.get_ld('/home/gaow/Documents/GTExV8/FMO2.ld.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "from libgaow.regression_data import MASH\n",
    "mash = MASH(X=X,Y=Y)\n",
    "mash.set_prior({'identity': np.identity(2), \n",
    "                 'single_1': np.array([[1,0],[0,0]]), \n",
    "                 'single_2': np.array([[0,0], [0,1]]), \n",
    "                 'all_in': np.ones((2,2))}, \n",
    "                [0.5,1], \n",
    "                [0.9,0.01,0.01,0.01,0.01,0.01,0.01,0.02,0.02])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9 ,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.02,  0.02])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mash.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['null', 'identity.1', 'identity.2', 'single_1.1', 'single_1.2', 'single_2.1', 'single_2.2', 'all_in.1', 'all_in.2'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mash.U.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[ 0.25,  0.  ],\n",
       "        [ 0.  ,  0.25]]), 1: array([[ 1.,  0.],\n",
       "        [ 0.,  1.]]), 2: array([[ 0.25,  0.  ],\n",
       "        [ 0.  ,  0.  ]]), 3: array([[ 1.,  0.],\n",
       "        [ 0.,  0.]]), 4: array([[ 0.  ,  0.  ],\n",
       "        [ 0.  ,  0.25]]), 5: array([[ 0.,  0.],\n",
       "        [ 0.,  1.]]), 6: array([[ 0.25,  0.25],\n",
       "        [ 0.25,  0.25]]), 7: array([[ 1.,  1.],\n",
       "        [ 1.,  1.]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi0 = 0.9\n",
    "pis = [item / (1 - pi0) for item in mash.pi[1:]]\n",
    "U = dict([(idx, mash.U[key]) for idx, key in enumerate(mash.U.keys()) if key != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "model.generate_B(pis, U, pi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count strong LD\n",
      "Filter by LD\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "strong_index = model.select_convoluted_snps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "model.swap_B(strong_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "model.generate_Y(np.ones((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## M&M analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "from libgaow.regression_data import MNMASH\n",
    "import numpy as np\n",
    "mm = MNMASH(X=model.X,Y=model.Y)\n",
    "mm.set_prior({'identity': np.identity(2), \n",
    "                 'single_1': np.array([[1,0],[0,0]]), \n",
    "                 'single_2': np.array([[0,0], [0,1]]), \n",
    "                 'all_in': np.ones((2,2))}, \n",
    "                [0.5,1], \n",
    "                [0.9,0.01,0.01,0.01,0.01,0.01,0.01,0.02,0.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "mm.fit(niter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter([x+1 for x in range(len(model.B[:,0]))], model.B[:,0], cmap=\"viridis\")\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x+1 for x in range(len(model.B[:,1]))], model.B[:,1], cmap=\"viridis\")\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x+1 for x in range(len(mm.post_mean_mat[:,0]))], mm.post_mean_mat[:,0], cmap=\"viridis\")\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x+1 for x in range(len(mm.post_mean_mat[:,1]))], mm.post_mean_mat[:,1], cmap=\"viridis\")\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "Python3",
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFE771"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ]
   ],
   "panel": {
    "displayed": false,
    "height": 0,
    "style": "side"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
