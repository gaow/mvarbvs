{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UKB Multivariate fine-mapping workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sufficient statistics input XtX, XtY, YtY and n. We assume covariates C have been removed from X and Y. We provide a procedure to implement this.\n",
    "2. GWAS summary statistics input z and R. We assume z scores have been computed after removal of covariates C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[global]\n",
    "import glob\n",
    "# single column file each line is the data filename\n",
    "parameter: analysis_units = path\n",
    "# Path to data directory\n",
    "parameter: data_dir = path\n",
    "# data file suffix\n",
    "parameter: data_suffix = str\n",
    "# Path to work directory where output locates\n",
    "parameter: wd = path(\"./output\")\n",
    "# Path to prior data file: an RDS file with `U` and `w` for prior matrices and weights\n",
    "parameter: prior = path('.')\n",
    "# Path to residual cor/cov data file\n",
    "parameter: resid_cor = path('.')\n",
    "# Only analyze `cis` variants -- cis = N means using N variants around the center column of X matrix  \n",
    "parameter: cis = 'NULL'\n",
    "regions = [x.strip() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "genes = [f\"{data_dir:a}/{x}.{data_suffix}\" for x in regions if path(f\"{data_dir:a}/{x}.{data_suffix}\").exists()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert LD store file to RDS format\n",
    "[ldstore_to_rds]\n",
    "# An identifier for your run of analysis\n",
    "parameter: name = str\n",
    "parameter: ld_dir = path\n",
    "ld_files = glob.glob(f\"{ld_dir:a}/{name}*.matrix\")\n",
    "input: ld_files, group_by = 1\n",
    "output: f\"{wd:a}/{_input:bn}.ld.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h', mem = '20G', cores = 2, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    ld = as.matrix(data.table::fread(${_input:r}))\n",
    "    saveRDS(ld, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sufficient_summary_stats_preprocessing]\n",
    "parameter: phenoFile = path\n",
    "parameter: covarFile = path\n",
    "# path to z score file\n",
    "parameter: z_dir = path()\n",
    "parameter: z_suffix = str\n",
    "# path to LD file\n",
    "parameter: ld_dir = path()\n",
    "parameter: ld_suffix = str\n",
    "input: genes, group_by = 1\n",
    "output: suffstats = f\"{wd:a}/{_input:bn}.sufficient_stats.rds\", \n",
    "        sumstats =  f\"{wd:a}/{_input:bn}.summary_stats.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '4h', mem = '200G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\"\n",
    "    # FIXME: in practice we might need to \n",
    "    geno_file = ${_input:nr}\n",
    "    z.file = \"${z_dir:a}/${_input:bn}.${z_suffix}\"\n",
    "    ld.file = \"${ld_dir:a}/${_input:bn}.${ld_suffix}\"\n",
    "    library(data.table)\n",
    "    library(dplyr)\n",
    "    \n",
    "    X <- fread(paste0(geno_file, '.raw.gz'),sep = \"\\t\",header = TRUE,stringsAsFactors = FALSE)\n",
    "    map <- X[,1:6]\n",
    "    X = X[, c('FID','IID','PAT','MAT','SEX', 'PHENOTYPE') := NULL]\n",
    "    X <- as.matrix(X)\n",
    "    \n",
    "    X.info = fread(paste0(geno_file, '.pvar'),sep = \"\\t\",header = TRUE,stringsAsFactors = FALSE)\n",
    "    \n",
    "    # Read phenotype data\n",
    "    cat(\"Reading phenotype data.\\n\")\n",
    "    pheno <- suppressMessages(fread(${phenoFile:r}))\n",
    "\n",
    "    cat(\"Reading covariate file.\\n\")\n",
    "    Z = suppressMessages(fread(${covarFile:r}))\n",
    "\n",
    "    match.idx = match(map$IID, pheno$IID)\n",
    "    pheno = pheno[match.idx,]\n",
    "    match.idx = match(map$IID, Z$IID)\n",
    "    Z = Z[match.idx,]\n",
    "  \n",
    "    Y = pheno %>% select(-FID, -IID) %>% as.matrix\n",
    "    Z = Z %>% select(-FID, -IID) %>% as.matrix\n",
    "  \n",
    "    # centering\n",
    "    Y = sweep(Y, 2, colMeans(Y), '-')\n",
    "    Z = sweep(Z, 2, colMeans(Z), '-')\n",
    "  \n",
    "    A   <- crossprod(Z) # Z'Z\n",
    "    # chol decomposition for (Z'Z)^(-1)\n",
    "    R = chol(solve(A)) # R'R = (Z'Z)^(-1)\n",
    "    W = R %*% crossprod(Z, X) # RZ'X\n",
    "    S = R %*% crossprod(Z, Y) # RZ'Y\n",
    "\n",
    "    SNPnames = colnames(X)\n",
    "    rm(X)\n",
    "    rm(Z)\n",
    "\n",
    "    zscores = readRDS(z.file)\n",
    "\n",
    "    # Load LD matrix from raw genotype\n",
    "    ld = readRDS(ld.file)\n",
    "    XtX = sqrt(zscores$XtXD) * t(ld*sqrt(zscores$XtXD)) - crossprod(W) # W'W = X'ZR'RZ'X = X'Z(Z'Z)^{-1}Z'X\n",
    "    XtX = as.matrix(XtX)\n",
    "    rownames(XtX) = colnames(XtX) = SNPnames\n",
    "    R = cov2cor(XtX)\n",
    "\n",
    "    # X'Y\n",
    "    ## flip sign because X flip the REF, ALT\n",
    "    XtY = -as.matrix(zscores$XtY - crossprod(W, S)) # W'S = X'ZR'RZ'y = X'Z(Z'Z)^{-1}Z'y\n",
    "\n",
    "    # YtY\n",
    "    YtY = as.matrix(crossprod(Y) - crossprod(S))\n",
    "\n",
    "    Z = as.matrix(zscores$Z)\n",
    "    rownames(Z) = SNPnames\n",
    "    \n",
    "    meta = zscores$pos[,1:5]\n",
    "    if(!all.equal(meta, X.info, check.attributes = FALSE)){\n",
    "        stop(\"ALLELE doesn't match.\")\n",
    "    }\n",
    "\n",
    "    saveRDS(list(XtX = XtX, XtY = XtY, YtY = YtY, N = nrow(Y), meta = zscores$pos), ${_output[\"suffstats\"]:r})\n",
    "    saveRDS(list(Z = Z, LD = R, meta = zscores$pos, ld.file = ld.file), ${_output[\"sumstats\"]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[univariate_analysis]\n",
    "parameter: max_L = 10\n",
    "input: genes, group_by = 1\n",
    "output: rss_rem_covariates = f\"{wd:a}/{_input:bnn}/{_input:bnn}.susierss_rem_covariates.rds\", \n",
    "        rss_notrem_covariates =  f\"{wd:a}/{_input:bnn}/{_input:bnn}.susierss_notrem_covariates.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '36h', mem = '150G', cores = 1, tags = f'{step_name}_{_output[0]:bnn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\"\n",
    "    library(susieR)\n",
    "    dat_rss = readRDS(${_input:r})\n",
    "    ld.file = gsub('/project2/mstephens/yuxin/ukb-bloodcells/LD/', \n",
    "                   '/project/mstephens/yuxin/ukb-bloodcells/LD/', \n",
    "                   dat_rss$ld.file)\n",
    "    R = readRDS(ld.file)\n",
    "    rownames(R) = colnames(R) = rownames(dat_rss$LD)\n",
    "    fitted_rss_rem_covariates = list()\n",
    "    fitted_rss_notrem_covariates = list()\n",
    "    for (r in 1:ncol(dat_suff$XtY)) {\n",
    "        ## sufficient stats\n",
    "        st = proc.time()\n",
    "        fitted_rss_rem_covariates[[r]] <- susieR::susie_rss(z = dat_rss$Z[,r],\n",
    "                                                            R = dat_rss$LD,\n",
    "                                                            n = 248980,\n",
    "                                                            L=${max_L},\n",
    "                                                            max_iter=1000,\n",
    "                                                            estimate_residual_variance=FALSE,\n",
    "                                                            estimate_prior_variance=TRUE,\n",
    "                                                            refine=TRUE)\n",
    "        fitted_rss_rem_covariates[[r]]$time = proc.time() - st\n",
    "        fitted_rss_rem_covariates[[r]]$cs_corr = susieR:::get_cs_correlation(fitted_rss_rem_covariates[[r]], Xcorr=dat_rss$LD)\n",
    "        \n",
    "        ## rss, LD not correct for covariates\n",
    "        st = proc.time()\n",
    "        fitted_rss_notrem_covariates[[r]] <- susieR::susie_rss(z = dat_rss$Z[,r],\n",
    "                                                               R = R,\n",
    "                                                               n=248980,\n",
    "                                                               L=${max_L},\n",
    "                                                               max_iter=1000,\n",
    "                                                               estimate_prior_variance=TRUE,\n",
    "                                                               refine=TRUE)\n",
    "        fitted_rss_notrem_covariates[[r]]$time = proc.time() - st\n",
    "        fitted_rss_notrem_covariates[[r]]$cs_corr = susieR:::get_cs_correlation(fitted_rss_notrem_covariates[[r]], \n",
    "                                                                                Xcorr=R)\n",
    "    }\n",
    "    \n",
    "    names(fitted_rss_rem_covariates) = colnames(dat_suff$XtY)\n",
    "    names(fitted_rss_notrem_covariates) = colnames(dat_suff$XtY)\n",
    "        \n",
    "    saveRDS(fitted_rss_rem_covariates, ${_output[\"rss_rem_covariates\"]:r})\n",
    "    saveRDS(fitted_rss_notrem_covariates, ${_output[\"rss_notrem_covariates\"]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[mvsusie_analysis]\n",
    "parameter: max_L = 10\n",
    "parameter: ld_type = 'original'\n",
    "input: genes, group_by = 1\n",
    "output: f'{wd:a}/{_input:bnn}/{_input:bnn}.LD{ld_type}{resid_cor:bnx}.mvsusierss.rds'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h', mem = '150G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\"\n",
    "    get_prior_indices <- function(Z, U) {\n",
    "      # make sure the prior col/rows match the colnames of the Y matrix\n",
    "      z_names = colnames(Z)\n",
    "      u_names = colnames(U)\n",
    "      if (is.null(z_names) || is.null(u_names)) {\n",
    "          return(NULL)\n",
    "      } else if (identical(z_names, u_names)) {\n",
    "          return(NULL)\n",
    "      } else {\n",
    "          return(match(z_names, u_names))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    library(mvsusieR)\n",
    "    dat = readRDS(${_input:r})\n",
    "    V = readRDS(${resid_cor:r})\n",
    "    prior = readRDS(${prior:r})\n",
    "    print(paste(\"Number of components in the mixture prior:\", length(prior$U)))\n",
    "    prior = mvsusieR::create_mixture_prior(mixture_prior=list(weights=prior$w, matrices=prior$U), \n",
    "                                        include_indices = get_prior_indices(dat$Z, prior$U[[1]]), \n",
    "                                        max_mixture_len=-1)\n",
    "    if(\"${ld_type}\" == 'original'){\n",
    "        ld.file = gsub('/project2/mstephens/yuxin/ukb-bloodcells/LD/', \n",
    "                   '/project/mstephens/yuxin/ukb-bloodcells/LD/', \n",
    "                   dat$ld.file)\n",
    "        R = readRDS(ld.file)\n",
    "    }else if(\"${ld_type}\" == 'remove_cov'){\n",
    "        R = dat$LD\n",
    "    }\n",
    "    st = proc.time()\n",
    "    mv_res = mvsusieR::mvsusie_rss(dat$Z, R, L=${max_L}, N = 248980,\n",
    "                                   prior_variance=prior, residual_variance=V, \n",
    "                                   precompute_covariances=T, compute_objective=T, \n",
    "                                   estimate_prior_variance=T, estimate_prior_method='EM',\n",
    "                                   max_iter = 1000, n_thread=1)\n",
    "    mv_res$time = proc.time() - st\n",
    "    if(mv_res$convergence$converged == FALSE){\n",
    "        stop('Fail to converge.')\n",
    "    }\n",
    "    mv_res$cs_corr = susieR:::get_cs_correlation(mv_res, Xcorr=R)\n",
    "    saveRDS(mv_res, ${_output:r})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[CS_report]\n",
    "mvsusie_res = [f'{wd:a}/{x}/{x}.{data_suffix}' for x in regions if path(f\"{wd:a}/{x}/{x}.{data_suffix}\").exists()]\n",
    "input: mvsusie_res, group_by = 1\n",
    "output: text_summary = f\"{_input:n}.summary.md\"\n",
    "R: expand = '${ }'\n",
    "    res = readRDS(${_input:r})\n",
    "    num_cs = length(res$sets$cs)\n",
    "    regionname = gsub(\".${data_suffix}\", \"\",${_input:br})\n",
    "    write(paste(regionname, num_cs), ${_output[\"text_summary\"]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[analysis_report]\n",
    "parameter: CS_lfsr = 0.01\n",
    "parameter: CS_purity = 0.2\n",
    "sumstat = [f'{data_dir:a}/{x}.summary_stats.rds' for x in regions]\n",
    "mvsusie_res = [f'{wd:a}/{x}/{x}.{data_suffix}' for x in regions]\n",
    "input: sumstat, mvsusie_res, group_by = 'pairs'\n",
    "output: pip_plot = f\"{_input[1]:n}.manhattan.pdf\", \n",
    "        mv_post_plot = f\"{_input[1]:n}.bubble_finemap.pdf\", \n",
    "        mv_z_plot = f\"{_input[1]:n}.bubble_original.pdf\",\n",
    "        textfile = f\"{_input[1]:n}.CS_purity{CS_purity}.CS_lfsr{CS_lfsr}.summary.rds\"\n",
    "R: expand = '${ }', stdout = f\"{_output['textfile']:nn}.stdout\", stderr = f\"{_output['textfile']:nn}.stderr\"\n",
    "    library(mvsusieR)\n",
    "    library(ggplot2)\n",
    "    check_overlap = function(cs) {\n",
    "        if (length(cs) == 0) {\n",
    "            return(0)\n",
    "        } else {\n",
    "            overlaps_cs = matrix(NA, length(cs), length(cs))\n",
    "            rownames(overlaps_cs) = colnames(overlaps_cs) = names(cs)\n",
    "            for (i in 1:length(cs)) {\n",
    "                for (j in 1:i) {\n",
    "                    if (i == j){\n",
    "                        overlaps_cs[i,j] = length(cs[[i]])\n",
    "                    }else{\n",
    "                        overlap = intersect(cs[[i]], cs[[j]])\n",
    "                        overlaps_cs[i,j] = length(overlap)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            overlaps_cs = as.matrix(Matrix::forceSymmetric(overlaps_cs,uplo=\"L\"))\n",
    "            return(overlaps_cs)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    dat = readRDS(${_input[0]:r})\n",
    "    res = readRDS(${_input[1]:r})\n",
    "    regionname = \"${regions[_index]}\"\n",
    "    trait_names = res$condition_names\n",
    "    if(grepl('LDoriginal', ${_input[1]:r})){\n",
    "        ld = readRDS(dat$ld.file)\n",
    "    }else{\n",
    "        ld = dat$LD\n",
    "    }\n",
    "    res$sets = susieR::susie_get_cs(res, Xcorr = ld, min_abs_corr = ${CS_purity})\n",
    "    \n",
    "    snps = sort(union(which(res$pip > 0.05), unlist(res$sets$cs)))\n",
    "    res$variable_names = paste(dat$meta$CHR, dat$meta$POS, sep = '.')\n",
    "    if(length(snps) > 0){\n",
    "        # PIP\n",
    "        tb = data.frame('Region' = regionname, dat$meta[snps,], 'PIP' = res$pip[snps])\n",
    "        \n",
    "        # CS\n",
    "        snps_cs = unlist(res$sets$cs)\n",
    "        snps_cs_match = match(snps_cs, rownames(tb))\n",
    "        snps_cs_match = snps_cs_match[!is.na(snps_cs_match)]\n",
    "        tb$CS = NA\n",
    "        tb[snps_cs_match,]$CS = rep(res$sets$cs_index, times = sapply(res$sets$cs, length))\n",
    "        \n",
    "        # purity\n",
    "        tb$purity = NA\n",
    "        tb[snps_cs_match,]$purity = rep(res$sets$purity[,1], times = sapply(res$sets$cs, length))\n",
    "\n",
    "        # trait CS\n",
    "        tb$CS_trait = NA\n",
    "        tb[snps_cs_match,]$CS_trait = rep(sapply(res$sets$cs_index, \n",
    "                                                 function(i) paste(trait_names[which((res$single_effect_lfsr < ${CS_lfsr})[i,])], \n",
    "                                                                   collapse = ' | ')), \n",
    "                                          times = sapply(res$sets$cs, length))\n",
    "\n",
    "        write.csv(tb,\"${_output['textfile']:n}.csv\", row.names = FALSE, quote = FALSE)\n",
    "        \n",
    "        ## plot\n",
    "        pdf(${_output['pip_plot']:r}, width=8, height=4)\n",
    "        susieR::susie_plot(res,y='PIP', main = 'Cross-condition Posterior Inclusion Probability', \n",
    "                           xlab = 'SNP positions', add_legend = F)\n",
    "        dev.off()\n",
    "        p = mvsusieR::mvsusie_plot(res)\n",
    "        pdf(${_output['mv_post_plot']:r}, width = p$width, height = p$height)\n",
    "        print(p$plot)\n",
    "        dev.off()\n",
    "        res$z = dat$Z\n",
    "        p = mvsusieR::mvsusie_plot(res, plot_z=TRUE)\n",
    "        pdf(${_output['mv_z_plot']:r}, width = p$width, height = p$height)\n",
    "        print(p$plot)\n",
    "        dev.off()\n",
    "        \n",
    "        cs_corr = susieR:::get_cs_correlation(res, Xcorr=ld)\n",
    "        if(all(!is.na(cs_corr))){\n",
    "            rownames(cs_corr) = colnames(cs_corr) = names(res$sets$cs)\n",
    "        }\n",
    "        \n",
    "        saveRDS(list(total_snps = nrow(dat$Z), summary_tb = tb, \n",
    "                     expect_causal = sum(res$pip), \n",
    "                     num_pip_not_CS = sum(is.na(tb$CS)),\n",
    "                     cs_corr = cs_corr,\n",
    "                     cs_overlap = check_overlap(res$sets$cs)), ${_output['textfile']:r})\n",
    "    }else{\n",
    "        system(\"touch ${_output['textfile']:n}.csv\")\n",
    "        system(\"touch ${_output['pip_plot']}\")\n",
    "        system(\"touch ${_output['mv_post_plot']}\")\n",
    "        system(\"touch ${_output['mv_z_plot']}\")\n",
    "        system(\"touch ${_output['textfile']}\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[univariate_analysis_report]\n",
    "parameter: CS_purity = 0.2\n",
    "sumstat = [f'{data_dir:a}/{x}.summary_stats.rds' for x in regions]\n",
    "susie_res = [f'{wd:a}/{x}/{x}.{data_suffix}' for x in regions]\n",
    "input: sumstat, susie_res, group_by = 'pairs'\n",
    "output: pip_plot = f\"{_input[1]:n}.manhattan.pdf\", \n",
    "        textfile = f\"{_input[1]:n}.CS_purity{CS_purity}.summary.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[1]:bn}'\n",
    "R: expand = '${ }'\n",
    "    library(susieR)\n",
    "    library(ggplot2)\n",
    "    dat = readRDS(${_input[0]:r})\n",
    "    res = readRDS(${_input[1]:r})\n",
    "    regionname = \"${regions[_index]}\"\n",
    "    \n",
    "    if(grepl('susierss_notrem_covariates', ${_input[1]:r})){\n",
    "        ld = readRDS(dat$ld.file)\n",
    "    }else{\n",
    "        ld = dat$LD\n",
    "    }\n",
    "    \n",
    "    trait_names = names(res)\n",
    "    tb.all = c()\n",
    "    pdf(${_output['pip_plot']:r})\n",
    "    par(mfcol = c(2,2))\n",
    "    for (name in trait_names){\n",
    "        res_trait = res[[name]]\n",
    "        res_trait$sets = susieR::susie_get_cs(res_trait, Xcorr = ld, \n",
    "                                              min_abs_corr = ${CS_purity})\n",
    "        susieR::susie_plot(res_trait, y='PIP', main = name, \n",
    "                           xlab = 'SNP positions', add_legend = F, max_cs = 3000)\n",
    "        \n",
    "        snps = sort(union(which(res_trait$pip > 0.05), unlist(res_trait$sets$cs)))\n",
    "        if(length(snps) > 0){\n",
    "            # PIP\n",
    "            tb = data.frame('Region' = regionname, dat$meta[snps,], 'trait' = name, 'PIP' = res_trait$pip[snps])\n",
    "            # CS\n",
    "            snps_cs = unlist(res_trait$sets$cs)\n",
    "            snps_cs_match = match(snps_cs, rownames(tb))\n",
    "            snps_cs_match = snps_cs_match[!is.na(snps_cs_match)]\n",
    "            tb$CS = NA\n",
    "            tb[snps_cs_match,]$CS = rep(res_trait$sets$cs_index, times = sapply(res_trait$sets$cs, length))\n",
    "            # purity\n",
    "            tb$purity = NA\n",
    "            tb[snps_cs_match,]$purity = rep(res_trait$sets$purity[,1], times = sapply(res_trait$sets$cs, length))\n",
    "\n",
    "            tb.all = rbind(tb.all, tb)\n",
    "        }\n",
    "    }\n",
    "    dev.off()\n",
    "    if(nrow(tb.all) > 0){\n",
    "        write.csv(tb.all,\"${_output['textfile']:n}.csv\", \n",
    "                  row.names = FALSE, quote = FALSE)\n",
    "        saveRDS(list(total_snps = nrow(dat$Z), summary_tb = tb.all), \n",
    "                ${_output['textfile']:r})\n",
    "    }else{\n",
    "        system(\"touch ${_output['textfile']:n}.csv\")\n",
    "        system(\"touch ${_output['textfile']:r}\")\n",
    "    }\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
