{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UKB Multivariate fine-mapping workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sufficient statistics input XtX, XtY, YtY and n. We assume covariates C have been removed from X and Y. We provide a procedure to implement this.\n",
    "2. GWAS summary statistics input z and R. We assume z scores have been computed after removal of covariates C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[global]\n",
    "import glob\n",
    "# single column file each line is the data filename\n",
    "parameter: analysis_units = path\n",
    "# Path to data directory\n",
    "parameter: data_dir = path\n",
    "# data file suffix\n",
    "parameter: data_suffix = str\n",
    "# Path to work directory where output locates\n",
    "parameter: wd = path(\"./output\")\n",
    "# Path to prior data file: an RDS file with `U` and `w` for prior matrices and weights\n",
    "parameter: prior = path('.')\n",
    "# Path to residual cor/cov data file\n",
    "parameter: resid_cor = path('.')\n",
    "# Only analyze `cis` variants -- cis = N means using N variants around the center column of X matrix  \n",
    "parameter: cis = 'NULL'\n",
    "regions = [x.strip() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "genes = [f\"{data_dir:a}/{x}.{data_suffix}\" for x in regions if path(f\"{data_dir:a}/{x}.{data_suffix}\").exists()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert LD store file to RDS format\n",
    "[ldstore_to_rds]\n",
    "# An identifier for your run of analysis\n",
    "parameter: name = str\n",
    "parameter: ld_dir = path\n",
    "ld_files = glob.glob(f\"{ld_dir:a}/{name}*.matrix\")\n",
    "input: ld_files, group_by = 1\n",
    "output: f\"{wd:a}/{_input:bn}.ld.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h', mem = '20G', cores = 2, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    ld = as.matrix(data.table::fread(${_input:r}))\n",
    "    saveRDS(ld, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sufficient_summary_stats_preprocessing]\n",
    "parameter: phenoFile = path\n",
    "parameter: covarFile = path\n",
    "# path to z score file\n",
    "parameter: z_dir = path()\n",
    "parameter: z_suffix = str\n",
    "# path to LD file\n",
    "parameter: ld_dir = path()\n",
    "parameter: ld_suffix = str\n",
    "input: genes, group_by = 1\n",
    "output: suffstats = f\"{wd:a}/{_input:bn}.sufficient_stats.rds\", \n",
    "        sumstats =  f\"{wd:a}/{_input:bn}.summary_stats.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '4h', mem = '200G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\"\n",
    "    # FIXME: in practice we might need to \n",
    "    geno_file = ${_input:nr}\n",
    "    z.file = \"${z_dir:a}/${_input:bn}.${z_suffix}\"\n",
    "    ld.file = \"${ld_dir:a}/${_input:bn}.${ld_suffix}\"\n",
    "    library(data.table)\n",
    "    library(dplyr)\n",
    "    \n",
    "    X <- fread(paste0(geno_file, '.raw.gz'),sep = \"\\t\",header = TRUE,stringsAsFactors = FALSE)\n",
    "    map <- X[,1:6]\n",
    "    X = X[, c('FID','IID','PAT','MAT','SEX', 'PHENOTYPE') := NULL]\n",
    "    X <- as.matrix(X)\n",
    "    \n",
    "    X.info = fread(paste0(geno_file, '.pvar'),sep = \"\\t\",header = TRUE,stringsAsFactors = FALSE)\n",
    "    \n",
    "    # Read phenotype data\n",
    "    cat(\"Reading phenotype data.\\n\")\n",
    "    pheno <- suppressMessages(fread(${phenoFile:r}))\n",
    "\n",
    "    cat(\"Reading covariate file.\\n\")\n",
    "    Z = suppressMessages(fread(${covarFile:r}))\n",
    "\n",
    "    match.idx = match(map$IID, pheno$IID)\n",
    "    pheno = pheno[match.idx,]\n",
    "    match.idx = match(map$IID, Z$IID)\n",
    "    Z = Z[match.idx,]\n",
    "  \n",
    "    Y = pheno %>% select(-FID, -IID) %>% as.matrix\n",
    "    Z = Z %>% select(-FID, -IID) %>% as.matrix\n",
    "  \n",
    "    # centering\n",
    "    Y = sweep(Y, 2, colMeans(Y), '-')\n",
    "    Z = sweep(Z, 2, colMeans(Z), '-')\n",
    "  \n",
    "    A   <- crossprod(Z) # Z'Z\n",
    "    # chol decomposition for (Z'Z)^(-1)\n",
    "    R = chol(solve(A)) # R'R = (Z'Z)^(-1)\n",
    "    W = R %*% crossprod(Z, X) # RZ'X\n",
    "    S = R %*% crossprod(Z, Y) # RZ'Y\n",
    "\n",
    "    SNPnames = colnames(X)\n",
    "    rm(X)\n",
    "    rm(Z)\n",
    "\n",
    "    zscores = readRDS(z.file)\n",
    "\n",
    "    # Load LD matrix from raw genotype\n",
    "    ld = readRDS(ld.file)\n",
    "    XtX = sqrt(zscores$XtXD) * t(ld*sqrt(zscores$XtXD)) - crossprod(W) # W'W = X'ZR'RZ'X = X'Z(Z'Z)^{-1}Z'X\n",
    "    XtX = as.matrix(XtX)\n",
    "    rownames(XtX) = colnames(XtX) = SNPnames\n",
    "    R = cov2cor(XtX)\n",
    "\n",
    "    # X'Y\n",
    "    ## flip sign because X flip the REF, ALT\n",
    "    XtY = -as.matrix(zscores$XtY - crossprod(W, S)) # W'S = X'ZR'RZ'y = X'Z(Z'Z)^{-1}Z'y\n",
    "\n",
    "    # YtY\n",
    "    YtY = as.matrix(crossprod(Y) - crossprod(S))\n",
    "\n",
    "    Z = as.matrix(zscores$Z)\n",
    "    rownames(Z) = SNPnames\n",
    "    \n",
    "    meta = zscores$pos[,1:5]\n",
    "    if(!all.equal(meta, X.info, check.attributes = FALSE)){\n",
    "        stop(\"ALLELE doesn't match.\")\n",
    "    }\n",
    "\n",
    "    saveRDS(list(XtX = XtX, XtY = XtY, YtY = YtY, N = nrow(Y), meta = zscores$pos), ${_output[\"suffstats\"]:r})\n",
    "    saveRDS(list(Z = Z, LD = R, meta = zscores$pos, ld.file = ld.file), ${_output[\"sumstats\"]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[univariate_analysis_1]\n",
    "parameter: max_L = 10\n",
    "input: genes, group_by = 1\n",
    "output: suff = f\"{wd:a}/{_input:bnn}.susiesuff.rds\", \n",
    "        rss_rem_covariates =  f\"{wd:a}/{_input:bnn}.susierss_rem_covariates.rds\",\n",
    "        rss_notrem_covariates =  f\"{wd:a}/{_input:bnn}.susierss_notrem_covariates.rds\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '20h', mem = '100G', cores = 1, tags = f'{step_name}_{_output[0]:bnn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\"\n",
    "    library(susieR)\n",
    "    dat_suff = readRDS('${_input:nn}.sufficient_stats.rds')\n",
    "    dat_rss = readRDS('${_input:nn}.summary_stats.rds')\n",
    "    R = readRDS(dat_rss$ld.file)\n",
    "    rownames(R) = colnames(R) = rownames(dat_rss$LD)\n",
    "    fitted_suff = list()\n",
    "    fitted_rss_rem_covariates = list()\n",
    "    fitted_rss_notrem_covariates = list()\n",
    "    for (r in 1:ncol(dat_suff$XtY)) {\n",
    "        ## sufficient stats\n",
    "        st = proc.time()\n",
    "        fitted_suff[[r]] <- susieR::susie_suff_stat(XtX = dat_suff$XtX, \n",
    "                                               Xty = dat_suff$XtY[,r],\n",
    "                                               yty = dat_suff$YtY[r,r], n = dat_suff$N,\n",
    "                                               L=${max_L},\n",
    "                                               max_iter=1000,\n",
    "                                               estimate_residual_variance=TRUE,\n",
    "                                               estimate_prior_variance=TRUE,\n",
    "                                               refine=FALSE)\n",
    "        fitted_suff[[r]]$time = proc.time() - st\n",
    "        fitted_suff[[r]]$cs_corr = susieR:::get_cs_correlation(fitted_suff[[r]], Xcorr=cov2cor(dat_suff$XtX))\n",
    "        \n",
    "        ## rss, LD correct for covariates\n",
    "        st = proc.time()\n",
    "        fitted_rss_rem_covariates[[r]] <- susieR::susie_rss(z = dat_rss$Z[,r],\n",
    "                                                            R = dat_rss$LD,\n",
    "                                                            L=${max_L},\n",
    "                                                            max_iter=1000,\n",
    "                                                            estimate_prior_variance=TRUE,\n",
    "                                                            refine=FALSE)\n",
    "        fitted_rss_rem_covariates[[r]]$time = proc.time() - st\n",
    "        fitted_rss_rem_covariates[[r]]$cs_corr = susieR:::get_cs_correlation(fitted_rss_rem_covariates[[r]], \n",
    "                                                                             Xcorr=dat_rss$LD)\n",
    "        \n",
    "        ## rss, LD not correct for covariates\n",
    "        st = proc.time()\n",
    "        fitted_rss_notrem_covariates[[r]] <- susieR::susie_rss(z = dat_rss$Z[,r],R = R,\n",
    "                                                               L=${max_L},max_iter=1000,\n",
    "                                                               estimate_prior_variance=TRUE,\n",
    "                                                               refine=FALSE)\n",
    "        fitted_rss_notrem_covariates[[r]]$time = proc.time() - st\n",
    "        fitted_rss_notrem_covariates[[r]]$cs_corr = susieR:::get_cs_correlation(fitted_rss_notrem_covariates[[r]], \n",
    "                                                                                Xcorr=R)\n",
    "    }\n",
    "    \n",
    "    names(fitted_suff) = colnames(dat_suff$XtY)\n",
    "    names(fitted_rss_rem_covariates) = colnames(dat_suff$XtY)\n",
    "    names(fitted_rss_notrem_covariates) = colnames(dat_suff$XtY)\n",
    "        \n",
    "    saveRDS(fitted_suff, ${_output[\"suff\"]:r})\n",
    "    saveRDS(fitted_rss_rem_covariates, ${_output[\"rss_rem_covariates\"]:r})\n",
    "    saveRDS(fitted_rss_notrem_covariates, ${_output[\"rss_notrem_covariates\"]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sufficient_stats_analysis_1]\n",
    "parameter: max_L = 10\n",
    "input: genes, group_by = 1\n",
    "output: f'{wd:a}/{_input:bnn}{resid_cor:bnx}.mvsusiesuff.rds'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '4h', mem = '55G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\"\n",
    "    get_prior_indices <- function(Z, U) {\n",
    "      # make sure the prior col/rows match the colnames of the Y matrix\n",
    "      z_names = colnames(Z)\n",
    "      u_names = colnames(U)\n",
    "      if (is.null(z_names) || is.null(u_names)) {\n",
    "          return(NULL)\n",
    "      } else if (identical(z_names, u_names)) {\n",
    "          return(NULL)\n",
    "      } else {\n",
    "          return(match(z_names, u_names))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    library(mvsusieR)\n",
    "    dat = readRDS(${_input:r})\n",
    "    V = readRDS(${resid_cor:r})\n",
    "    prior = readRDS(${prior:r})\n",
    "    print(paste(\"Number of components in the mixture prior:\", length(prior$U)))\n",
    "    prior = mvsusieR::create_mash_prior(mixture_prior=list(weights=prior$w, matrices=prior$U), \n",
    "                                        include_indices = get_prior_indices(dat$XtY, prior$U[[1]]), \n",
    "                                        max_mixture_len=-1)\n",
    "    st = proc.time()\n",
    "    mv_res = mvsusieR::mvsusie_suff_stat(dat$XtX, dat$XtY, dat$YtY, dat$N, L=${max_L}, \n",
    "                                         prior_variance=prior, residual_variance=V, \n",
    "                                         precompute_covariances=T, compute_objective=T, \n",
    "                                         estimate_residual_variance=F, estimate_prior_variance=T, \n",
    "                                         estimate_prior_method='EM',max_iter = 1000, n_thread=1)\n",
    "    mv_res$time = proc.time() - st\n",
    "    if(mv_res$convergence$converged == FALSE){\n",
    "        stop('Fail to converge.')\n",
    "    }\n",
    "    mv_res$cs_corr = susieR:::get_cs_correlation(mv_res, Xcorr=cov2cor(dat$XtX))\n",
    "    saveRDS(mv_res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[summary_stats_analysis_1]\n",
    "parameter: max_L = 10\n",
    "parameter: ld_type = 'original'\n",
    "input: genes, group_by = 1\n",
    "output: f'{wd:a}/{_input:bnn}.LD{ld_type}{resid_cor:bnx}.mvsusierss.rds'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '4h', mem = '55G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\"\n",
    "    get_prior_indices <- function(Z, U) {\n",
    "      # make sure the prior col/rows match the colnames of the Y matrix\n",
    "      z_names = colnames(Z)\n",
    "      u_names = colnames(U)\n",
    "      if (is.null(z_names) || is.null(u_names)) {\n",
    "          return(NULL)\n",
    "      } else if (identical(z_names, u_names)) {\n",
    "          return(NULL)\n",
    "      } else {\n",
    "          return(match(z_names, u_names))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    library(mvsusieR)\n",
    "    dat = readRDS(${_input:r})\n",
    "    V = readRDS(${resid_cor:r})\n",
    "    prior = readRDS(${prior:r})\n",
    "    print(paste(\"Number of components in the mixture prior:\", length(prior$U)))\n",
    "    prior = mvsusieR::create_mash_prior(mixture_prior=list(weights=prior$w, matrices=prior$U), \n",
    "                                        include_indices = get_prior_indices(dat$Z, prior$U[[1]]), \n",
    "                                        max_mixture_len=-1)\n",
    "    if(\"${ld_type}\" == 'original'){\n",
    "        R = readRDS(dat$ld.file)\n",
    "    }else if(\"${ld_type}\" == 'remove_cov'){\n",
    "        R = dat$LD\n",
    "    }\n",
    "    st = proc.time()\n",
    "    mv_res = mvsusieR::mvsusie_rss(dat$Z, R, L=${max_L}, \n",
    "                                   prior_variance=prior, residual_variance=V, \n",
    "                                   precompute_covariances=T, compute_objective=T, \n",
    "                                   estimate_prior_variance=T, estimate_prior_method='EM',\n",
    "                                   max_iter = 1000, n_thread=1)\n",
    "    mv_res$time = proc.time() - st\n",
    "    if(mv_res$convergence$converged == FALSE){\n",
    "        stop('Fail to converge.')\n",
    "    }\n",
    "    mv_res$cs_corr = susieR:::get_cs_correlation(mv_res, Xcorr=R)\n",
    "    saveRDS(mv_res, ${_output:r})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[analysis_report]\n",
    "regions = [x.strip() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "sumstat = [f'{data_dir:a}/{x}.summary_stats.rds' for x in regions]\n",
    "mvsusie_res = [f'{wd:a}/{x}.{data_suffix}' for x in regions]\n",
    "input: sumstat, mvsusie_res, group_by = 'pairs'\n",
    "output: pip_plot = f\"{wd:a}/{_input[1]:bn}.manhattan.pdf\", \n",
    "        mv_post_plot = f\"{wd:a}/{_input[1]:bn}.bubble_finemap.pdf\", \n",
    "        mv_z_plot = f\"{wd:a}/{_input[1]:bn}.bubble_original.pdf\",\n",
    "        textfile = f\"{wd:a}/{_input[1]:bn}.summary.rds\"\n",
    "R: expand = '${ }'\n",
    "    library(mvsusieR)\n",
    "    library(ggplot2)\n",
    "    check_overlap = function(cs) {\n",
    "        if (length(cs) == 0) {\n",
    "            return(0)\n",
    "        } else {\n",
    "            overlaps_cs = matrix(NA, length(cs), length(cs))\n",
    "            rownames(overlaps_cs) = colnames(overlaps_cs) = names(cs)\n",
    "            for (i in 1:length(cs)) {\n",
    "                for (j in 1:i) {\n",
    "                    if (i == j){\n",
    "                        overlaps_cs[i,j] = length(cs[[i]])\n",
    "                    }else{\n",
    "                        overlap = intersect(cs[[i]], cs[[j]])\n",
    "                        overlaps_cs[i,j] = length(overlap)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            overlaps_cs = as.matrix(Matrix::forceSymmetric(overlaps_cs,uplo=\"L\"))\n",
    "            return(overlaps_cs)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    dat = readRDS(${_input[0]:r})\n",
    "    res = readRDS(${_input[1]:r})\n",
    "    regionname = gsub(\".${data_suffix}\", \"\",${_input[0]:br})\n",
    "    trait_names = colnames(res$sigma2)\n",
    "    snps = sort(union(which(res$pip > 0.05), unlist(res$sets$cs)))\n",
    "    if(length(snps) > 0){\n",
    "        # PIP\n",
    "        tb = data.frame('Region' = regionname, dat$meta[snps,], 'PIP' = res$pip[snps])\n",
    "        \n",
    "        # CS\n",
    "        snps_cs = unlist(res$sets$cs)\n",
    "        snps_cs_match = match(snps_cs, rownames(tb))\n",
    "        snps_cs_match = snps_cs_match[!is.na(snps_cs_match)]\n",
    "        tb$CS = NA\n",
    "        tb[snps_cs_match,]$CS = rep(res$sets$cs_index, times = sapply(res$sets$cs, length))\n",
    "        \n",
    "        # purity\n",
    "        tb$purity = NA\n",
    "        tb[snps_cs_match,]$purity = rep(res$sets$purity[,1], times = sapply(res$sets$cs, length))\n",
    "\n",
    "        # trait CS\n",
    "        tb$CS_trait = NA\n",
    "        tb[snps_cs_match,]$CS_trait = rep(sapply(res$sets$cs_index, \n",
    "                                                 function(i) paste(trait_names[which((res$single_effect_lfsr < 0.05)[i,])], \n",
    "                                                                   collapse = ' | ')), \n",
    "                                          times = sapply(res$sets$cs, length))\n",
    "\n",
    "        write.csv(tb,\"${_output['textfile':n]}.csv\", row.names = FALSE, quote = FALSE)\n",
    "        \n",
    "        ## plot\n",
    "        pdf(${_output['pip_plot']:r}, width=8, height=4)\n",
    "        susieR::susie_plot(res,y='PIP', main = 'Cross-condition Posterior Inclusion Probability', \n",
    "                           xlab = 'SNP positions', add_legend = F)\n",
    "        dev.off()\n",
    "        #p = mvsusieR::mvsusie_plot(res)\n",
    "        #pdf(${_output['mv_post_plot']:r}, width = p$width, height = p$height)\n",
    "        #print(p$plot)\n",
    "        #dev.off()\n",
    "        #res$z = dat$Z\n",
    "        #res$variable_names = paste(dat$meta$CHR, dat$meta$POS, sep = '.')\n",
    "        #res$condition_names = trait_names\n",
    "        #p = mvsusieR::mvsusie_plot(res, plot_z=TRUE)\n",
    "        #pdf(${_output['mv_z_plot']:r}, width = p$width, height = p$height)\n",
    "        #print(p$plot)\n",
    "        #dev.off()\n",
    "        system(\"touch ${_output['pip_plot']}\")\n",
    "        system(\"touch ${_output['mv_post_plot']}\")\n",
    "        system(\"touch ${_output['mv_z_plot']}\")\n",
    "        \n",
    "        cs_corr = res$cs_corr\n",
    "        if(all(!is.na(cs_corr))){\n",
    "            rownames(cs_corr) = colnames(cs_corr) = names(res$sets$cs)\n",
    "        }\n",
    "        \n",
    "        saveRDS(list(total_snps = nrow(dat$Z), summary_tb = tb, \n",
    "                     expect_causal = sum(res$pip), \n",
    "                     num_pip_not_CS = sum(is.na(tb$CS)),\n",
    "                     cs_corr = cs_corr,\n",
    "                     cs_overlap = check_overlap(res$sets$cs)), ${_output['textfile']:r})\n",
    "    }else{\n",
    "        system(\"touch ${_output['textfile']:n}.csv\")\n",
    "        system(\"touch ${_output['pip_plot']}\")\n",
    "        system(\"touch ${_output['mv_post_plot']}\")\n",
    "        system(\"touch ${_output['mv_z_plot']}\")\n",
    "        system(\"touch ${_output['textfile']}\")\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
