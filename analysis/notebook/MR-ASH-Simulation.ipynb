{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of quantitative phenotype given genotypes\n",
    "Here we simulate effect size from mixture gaussian distribution and match strong effects with \"heavily LD convoluted\" SNPs. See below for details. \n",
    "\n",
    "## Core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/SimUtils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/SimUtils.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "\n",
    "def shuffle(df, n=1, axis=1):     \n",
    "        df = df.copy()\n",
    "        for _ in range(n):\n",
    "            df.apply(np.random.permutation, axis=axis)\n",
    "        return df\n",
    "\n",
    "class PhenotypeSimulator:\n",
    "    def __init__(self, genotype_file):\n",
    "        self.gfile = genotype_file\n",
    "        self.phenotype = {}\n",
    "        self.beta = {}\n",
    "        self.pid = None\n",
    "        \n",
    "    def get_genes(self, limit = 5):\n",
    "        res = pd.HDFStore(self.gfile).keys()\n",
    "        if len(res) > limit:\n",
    "            res = res[:limit]\n",
    "        return res\n",
    "    \n",
    "    def get_X(self, table):\n",
    "        return pd.read_hdf(self.gfile, table)\n",
    "    \n",
    "    def permute_X(self, tables, save_to):\n",
    "        if os.path.isfile(save_to):\n",
    "            os.remove(save_to)\n",
    "        for table in tables:\n",
    "            X = pd.read_hdf(self.gfile, table)\n",
    "            X = shuffle(X)\n",
    "            X.to_hdf(save_to, table, mode = 'a', complevel = 9, complib = 'zlib')\n",
    "        self.gfile = save_to\n",
    "    \n",
    "    def get_ld(self, tables, save_to = None):\n",
    "        '''r^2 based LD calculation'''\n",
    "        ld = {table: pd.read_hdf(self.gfile, table).transpose().corr(method = 'pearson') for table in tables}\n",
    "        ld = {key: (np.power(value, 2) * np.sign(value)).astype(np.float16) for key, value in ld.items()}\n",
    "        if save_to is not None:\n",
    "            if os.path.isfile(save_to):\n",
    "                os.remove(save_to)\n",
    "            for key in ld:\n",
    "                ld[key].to_hdf(save_to, key, mode = 'a', complevel = 9, complib = 'zlib')\n",
    "        return ld\n",
    "    \n",
    "    def load_ld(self, tables, fn):\n",
    "        ld = {}\n",
    "        for table in tables:\n",
    "            ld[table] = pd.read_hdf(fn, table)\n",
    "        return ld\n",
    "    \n",
    "    def ld_heatmap(self, corrmat, out):\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(corrmat, ax = ax, vmin=-1, vmax=1, square=True, xticklabels = False, yticklabels = False)\n",
    "        plt.savefig(out, dpi = 500)\n",
    "        \n",
    "    def generate_betamix(self, nbeta, mus, sigmas, pis, pi0 = 0):\n",
    "        '''beta ~ \\pi_0\\delta_0 + \\sum \\pi_i N(0, sigma_i)\n",
    "        sigma here is a nbeta list or nbeta * nbeta matrix\n",
    "        '''\n",
    "        if isinstance(sigmas, list):\n",
    "            sigmas = np.diag(sigmas)\n",
    "        assert (len(pis), len(pis)) == sigmas.shape\n",
    "        masks = np.random.multinomial(1, pis, size = nbeta)\n",
    "        mix = np.random.multivariate_normal(mus, sigmas, nbeta)\n",
    "        return np.sum(mix * masks, axis = 1) * np.random.binomial(1, 1 - pi0, nbeta)\n",
    "    \n",
    "    def generate_y(self, X, beta, sigma, force = False):\n",
    "        if self.pid in self.phenotype and force is not True:\n",
    "            print('Name \"{}\" already exists. Use \"force = True\" to overwrite it'.format(self.pid))\n",
    "            return self.phenotype[self.pid]\n",
    "        assert X.shape[0] == len(beta)\n",
    "        self.beta[self.pid] = beta.tolist()\n",
    "        beta.reshape((len(beta),1))\n",
    "        y = np.dot(X.T, beta) + np.random.normal(0, sigma, X.shape[1])\n",
    "        y.reshape(len(y), 1)\n",
    "        y = pd.DataFrame(data = y, columns = [self.pid], index = X.columns).transpose()\n",
    "        self.phenotype[self.pid] = y\n",
    "        return y\n",
    "    \n",
    "    def select_convoluted_snps(self, ld, cutoff1 = 0.8, cutoff2 = 10, cutoff3 = 0.01):\n",
    "        '''based on LD matrix select SNPs in strong LD with other SNPs \n",
    "        yet are independent between themselves'''\n",
    "        print('Count strong LD')\n",
    "        strong_ld_count = ((np.absolute(ld) > cutoff1) * ld).sum(axis = 0).sort_values(ascending = False)\n",
    "        strong_ld_count = strong_ld_count[strong_ld_count > cutoff2]\n",
    "        print('Filter by LD')\n",
    "        exclude = []\n",
    "        for x in strong_ld_count.index:\n",
    "            if x in exclude:\n",
    "                continue\n",
    "            for y in strong_ld_count.index:\n",
    "                if y in exclude or y == x:\n",
    "                    continue\n",
    "                if np.absolute(ld[x][y]) > cutoff3:\n",
    "                    exclude.append(y)\n",
    "        print('Done')\n",
    "        return [i for i, x in enumerate(strong_ld_count.index) if not x in exclude]\n",
    "    \n",
    "    def swap_beta(self, beta, strength_index):\n",
    "        '''Set tops of beta to tops in strength_index'''\n",
    "        nb = [0] * len(beta)\n",
    "        beta = sorted(beta, key=abs, reverse=True)\n",
    "        for item in strength_index:\n",
    "            nb[item] = beta.pop(0)\n",
    "        random.shuffle(beta)\n",
    "        for idx in range(len(nb)):\n",
    "            if not idx in strength_index:\n",
    "                nb[idx] = beta.pop(0)\n",
    "        assert len(beta) == 0\n",
    "        return np.array(nb)\n",
    "    \n",
    "    def set_id(self, name):\n",
    "        self.pid = name\n",
    "\n",
    "        \n",
    "class BetaDist:\n",
    "    '''Reproducing simulated distributions of Stephens 2017 (ASH paper)'''\n",
    "    def __init__(self):\n",
    "        self.pi0 = 0\n",
    "        self.pis = [None]\n",
    "        self.mus = [None]\n",
    "        self.sigmas = [None]\n",
    "        \n",
    "    def set_pi0(self, pi0):\n",
    "        self.pi0 = pi0\n",
    "        \n",
    "    def set_spiky(self):\n",
    "        self.pis = [0.4,0.2,0.2,0.2]\n",
    "        self.mus = [0,0,0,0]\n",
    "        self.sigmas = [0.25,0.5,1,2]\n",
    "    \n",
    "    def set_near_normal(self):\n",
    "        self.pis = [2/3,1/3]\n",
    "        self.mus = [0,0]\n",
    "        self.sigmas = [1,2]\n",
    "        \n",
    "    def set_flat_top(self):\n",
    "        self.pis = [1/7] * 7\n",
    "        self.mus = [-1.5, -1, -.5 , 0, .5, 1, 1.5]\n",
    "        self.sigmas = [0.5] * 7\n",
    "        \n",
    "    def set_skew(self):\n",
    "        self.pis = [1/4,1/4,1/3,1/6]\n",
    "        self.mus = [-2,-1,0,1]\n",
    "        self.sigmas = [2,1.5,1,1]\n",
    "        \n",
    "    def set_big_normal(self):\n",
    "        self.pis = [1]\n",
    "        self.mus = [0]\n",
    "        self.sigmas = [4]\n",
    "\n",
    "    def set_bimodal(self):\n",
    "        self.pis = [0.5, 0.5]\n",
    "        self.mus = [-2, 2]\n",
    "        self.sigmas = [1, 1]\n",
    "        \n",
    "    def __str__(self):\n",
    "        params = ' + '.join([\"{} N({}, {}^2)\".format(x,y,z) for x, y, z in zip(self.pis, self.mus, self.sigmas)])\n",
    "        return '{:.3f} \\delta_0 + {:.3f} [{}]'.format(self.pi0, 1 - self.pi0, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.SimUtils import PhenotypeSimulator, BetaDist\n",
    "ms = PhenotypeSimulator(\"/home/gaow/Documents/GTEx/ToyExample/TY.genotype.h5\")\n",
    "tables = ms.get_genes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and save LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ld = ms.get_ld(tables, save_to = \"/home/gaow/Documents/GTEx/ToyExample/TY.ld.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together\n",
    "If you just want to get simulated data without knowing the details you can run the following code and find the output `/home/gaow/Documents/GTEx/ToyExample/TY.expr_simulated.h5`. Otherwise you should read on for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998 \\delta_0 + 0.0020000000000000018 [0.4 N(0, 0.25^2) + 0.2 N(0, 0.5^2) + 0.2 N(0, 1^2) + 0.2 N(0, 2^2)]\n",
      "Count strong LD\n",
      "Filter by LD\n",
      "Done\n",
      "Count strong LD\n",
      "Filter by LD\n",
      "Done\n",
      "Count strong LD\n",
      "Filter by LD\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "import json\n",
    "expr_file = '/home/gaow/Documents/GTEx/ToyExample/TY.expr_simulated.h5'\n",
    "if os.path.isfile(expr_file):\n",
    "    os.remove(expr_file)\n",
    "param = BetaDist()\n",
    "param.set_pi0(0.998)\n",
    "# Can use other settings\n",
    "param.set_spiky()\n",
    "print(param)\n",
    "for table in tables:\n",
    "    ms.set_id(os.path.basename(table))\n",
    "    nbeta = ld[table].shape[0]\n",
    "    beta = ms.generate_betamix(nbeta=nbeta,pi0=param.pi0, pis=param.pis, mus = param.mus, sigmas=param.sigmas)\n",
    "    strong_snps_idx = ms.select_convoluted_snps(ld[table])\n",
    "    beta = ms.swap_beta(beta, strong_snps_idx)\n",
    "    X = ms.get_X(table=table)\n",
    "    y = ms.generate_y(beta=beta,sigma=1, X=X, force = True)\n",
    "pd.concat(ms.phenotype.values()).to_hdf(expr_file, '/simulated', mode = 'a', complevel = 9, complib = 'zlib')\n",
    "meta = {'pi': param.pis, 'pi0': param.pi0, 'sigma': param.sigmas, 'beta': ms.beta}\n",
    "with open(\"/home/gaow/Documents/GTEx/ToyExample/TY.meta_simulation.json\", 'w') as fp:\n",
    "    json.dump(meta, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View and select LD structure\n",
    "Take gene `ENSG00000264247` for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ld['/chr18/ENSG00000264247'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "ms.ld_heatmap(ld['/chr18/ENSG00000264247'].iloc[:1000,:1000], 'img/ENSG00000264247.ld.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ENSG00000264247.ld.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating effect size\n",
    "Now let's degress to effect size simulation. Effect size refers to $\\beta$ in the linear model $ Y = X \\beta + E$ where for simplicity we assume $E_{ij} \\sim N(0,1)$. We sample $\\beta$ from a mixture of gaussian distribution and a point mass at zero.\n",
    "\n",
    "Here I start with a simple 3 components mixture under the alternative. 98% data will be the null (take that point mass at zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbeta = ld['/chr18/ENSG00000264247'].shape[0]\n",
    "pis = [0.25, 0.3, 0.45]\n",
    "pi0 = 0.98\n",
    "sigmas = [1, 0.4, 3]\n",
    "beta = ms.generate_betamix(nbeta=nbeta,pi0=pi0,pis=pis,sigmas=sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swap big effect size to most LD-convoluted SNPs\n",
    "To better illustrate the potential of mr-ash I identify from genotype matrix potentially the more LD-convoluted SNPs and assign them the largest effect size. Specifically, I rank SNPs by their number of having LD with other SNPs greater than 0.9 (unsigned), and filter the top ranked SNPs until there is no strong LD between them ($r^2<0.1$). Then I swap $\\beta$s so that these SNPs have large effect size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strong_snps_idx = ms.select_convoluted_snps(ld['/chr18/ENSG00000264247'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta = ms.swap_beta(beta, strong_snps_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ms.get_X(table='/chr18/ENSG00000264247')\n",
    "y = ms.generate_y(beta=beta,sigma=1, X=X, name = 'ENSG00000264247')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
