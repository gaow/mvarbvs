{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Molecular QTL workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table class=\"revision_table\">\n",
       "        <tr>\n",
       "        <th>Revision</th>\n",
       "        <th>Author</th>\n",
       "        <th>Date</th>\n",
       "        <th>Message</th>\n",
       "        <tr>\n",
       "        <tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/85c5de0082827d40f84d17c33681626370b21e9e/analysis/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">85c5de0<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-08</td>\n",
       "<td>More efficient implementation for CAVIAR follow up</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/6371e2b6f2d68e0e3dc55a420fca5d3f4c45c199/analysis/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">6371e2b<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-08</td>\n",
       "<td>follow up studies</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/53eff9f379bacbbad5cf3d244798151e20f885ce/analysis/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">53eff9f<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-06</td>\n",
       "<td>Another run of 100Kb region instead of 1Mb</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/63045aa248abe96b401e0d0cd683b7b6c7505f84/analysis/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">63045aa<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-05</td>\n",
       "<td>Change figure layout</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/8c6e7228fc00c568d0e38685b9325c69fdd2ac79/analysis/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">8c6e722<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-05</td>\n",
       "<td>Add cluster configurations</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/aeaf3fabea9f05ba33b9667f47f92dfdd819bbe7/analysis/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">aeaf3fa<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-05</td>\n",
       "<td>Fix susie execution pipeline step</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/1420e4c8e3300f7becd18b0fd4c6b749c8554e4e/analysis/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">1420e4c<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-05</td>\n",
       "<td>Use chromsomes as batches</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/044e3a10eece52e08e5c5ce34eeb11c1b713a196/analysis/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">044e3a1<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-04</td>\n",
       "<td>Add data convertion pipeline for molecular qtls</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%revisions -s -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Data\n",
    "\n",
    "Molecular QTL data from [Yang et al (2016) Science](http://eqtl.uchicago.edu/jointLCL/). Input are genotypes of ~100 YRI samples with their molecular QTL data measured in LCL.\n",
    "\n",
    "- alternative splicing (AS) data is of the primary interest here.\n",
    "\n",
    "### Genotypes\n",
    "\n",
    "[Genotype data for YRI](http://eqtl.uchicago.edu/jointLCL/genotypesYRI.gen.txt.gz) is the conventional VCF format but has dosage for genotypes.\n",
    "\n",
    "### Phenotypes\n",
    "\n",
    "Phenotype data has format:\n",
    "\n",
    "```\n",
    "#Chr\tstart\tend\tID\t18486\t18487\t18488\t18489\t18498\t18499\n",
    "chr1\t880180\t880422\tchr1:880180:880422:clu_15502\t0.201694364955\t0.665990212763\t-1.21881815589\t-0.342480185427\t0.165404160483\t-1.58524292941\n",
    "```\n",
    "\n",
    "The first 4 columns are genomic coordinates info. Others are molecular QTL in samples.\n",
    "\n",
    "We analyze:\n",
    "\n",
    "1. [Alternative splicing](http://eqtl.uchicago.edu/jointLCL/qqnorm_ASintron_RNAseqGeuvadis.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Analysis plan\n",
    "\n",
    "- For each analysis unit (gene, or intron cluster for AS), get the 1MB up/down-stream variants in genotypes\n",
    "- Remove top phenotype PC from phenotype data\n",
    "- Fine-mapping using various methods. SuSiE for starters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run 20180704_MolecularQTL_Workflow.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  preprocess\n",
      "  index_vcf\n",
      "  SuSiE\n",
      "  SuSiE_summary\n",
      "  CAVIAR_follow_up\n",
      "\n",
      "Global Workflow Options:\n",
      "  --x-data . (as path)\n",
      "                        X data, the genotype VCF file path\n",
      "  --y-data . (as path)\n",
      "                        Y data, the phenotype file paths\n",
      "  --cwd  f'{y_data:d}_output'\n",
      "\n",
      "                        Specify work directory\n",
      "  --max-dist 1000000 (as int)\n",
      "                        Maximum distance to site of interest, eg. 1Mb\n",
      "                        up/downstream to TSS for gene level QTL\n",
      "\n",
      "Sections\n",
      "  preprocess_1:         PCA on phenotype and remove top PCs\n",
      "    Workflow Options:\n",
      "      --num-pcs 3 (as int)\n",
      "                        Num. PC to remove from phenotype\n",
      "      --colname-pattern '^[0-9]+'\n",
      "                        column name patter for `grep` in R to select phenotype\n",
      "                        columns eg. \"^NA[0-9]+\" to extract sample names\n",
      "  index_vcf:            this step provides VCF file index\n",
      "  preprocess_2:         Extract cis-SNPs and make fine-mapping datasets\n",
      "  preprocess_3:         Summary statistics and PVE estimates\n",
      "  SuSiE:                Run finemapping with SuSiE\n",
      "    Workflow Options:\n",
      "      --maxL 5 (as int)\n",
      "                        SuSiE parameter: L\n",
      "      --prior-var 0.1 (as float)\n",
      "                        SuSiE parameter: prior variance\n",
      "  SuSiE_summary:        Make SuSiE result plots for significant results\n",
      "  CAVIAR_follow_up_1:   Run CAVIAR on SuSiE results of interest\n",
      "    Workflow Options:\n",
      "      --caviar-args '-c 2'\n",
      "  CAVIAR_follow_up_2:   Plot CAVIAR vs SuSiE results\n"
     ]
    }
   ],
   "source": [
    "!sos run 20180704_MolecularQTL_Workflow.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# X data, the genotype VCF file path\n",
    "parameter: x_data = path()\n",
    "# Y data, the phenotype file paths\n",
    "parameter: y_data = path()\n",
    "# Specify work directory\n",
    "parameter: cwd = f'{y_data:d}_output'\n",
    "# Maximum distance to site of interest, eg. 1Mb up/downstream to TSS for gene level QTL\n",
    "parameter: max_dist = 1000000\n",
    "fail_if(not x_data.is_file(), msg = 'Please provide ``--x-data`` or ``--h5-data``!')\n",
    "fail_if(not y_data.is_file(), msg = 'Please provide ``--y-data`` or ``--h5-data``!')\n",
    "pop = 'YRI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Preprocessing analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The preprocessing pipeline can be executed locally, takes 3hrs on my 40-thread machine:\n",
    "\n",
    "```\n",
    "sos run analysis/20180704_MolecularQTL_Workflow.ipynb preprocess \\\n",
    "    --x-data ~/GIT/LargeFiles/AS/genotypesYRI.gen.txt.gz \\\n",
    "    --y-data ~/GIT/LargeFiles/AS/fastqtl_qqnorm_ASintron_RNAseqGeuvadis_YangVCF.txt.gz \\\n",
    "    --max-dist 100000 --num-pcs 3 -j 38\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Regressing out top PCs on phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "There may well be better approach to control for covariates etc, but [here](https://github.com/bmvdgeijn/WASP/blob/master/examples/example_data/H3K27ac/get_PCs.R) is workflow from the authors and was deemed sufficient. See their supplemental table of Yang et al 2016 for how many PC to use for each molecular QTLs.\n",
    "\n",
    "Need to cope with missing phenotype data here. See `na.omit` function call in `prcomp` and `na.actions=na.exclude`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# PCA on phenotype and remove top PCs\n",
    "[preprocess_1, DAP_1 (Remove top phenotype PC)]\n",
    "# Num. PC to remove from phenotype\n",
    "parameter: num_pcs = 3 # Table S2 of NIHMS835311-supplement-supplement.pdf\n",
    "# column name patter for `grep` in R to select phenotype columns\n",
    "# eg. \"^NA[0-9]+\" to extract sample names\n",
    "parameter: colname_pattern = '^[0-9]+'\n",
    "input: y_data\n",
    "output: f\"{cwd}/{_input:bn}.PC{num_pcs}.removed.gz\"\n",
    "R: expand = \"${ }\", workdir = cwd, stdout = f\"{_output:n}.stdout\"\n",
    "    num_pcs = ${num_pcs}\n",
    "    dat <- read.table(${_input:r}, header=T, comment.char='', check.names=F)\n",
    "    phenotype.matrix <- dat[,5:ncol(dat)]\n",
    "    # extract columns of interest\n",
    "    phenotype.matrix <- phenotype.matrix[,grep(\"${colname_pattern}\", colnames(phenotype.matrix), value = T)]\n",
    "    # perform principal component analysis\n",
    "    pca <- prcomp(na.omit(phenotype.matrix))\n",
    "    # PCA summary\n",
    "    print(summary(pca))\n",
    "    cat(\"output\", num_pcs, \"PCs \\n\")\n",
    "    # remove top PC from phenotype; takes a while\n",
    "    cov_pcs <- pca$rotation[, 1:num_pcs]\n",
    "    new.phenotype.matrix <- do.call(rbind, lapply(1:nrow(phenotype.matrix), function(i) residuals(lm(t(phenotype.matrix[i,]) ~ as.matrix(cov_pcs), na.action=na.exclude))))\n",
    "    colnames(new.phenotype.matrix) <- colnames(phenotype.matrix)\n",
    "    new.dat <- cbind(dat[,1:4], new.phenotype.matrix)\n",
    "    colnames(new.dat)[1] <- 'chr'\n",
    "    write.table(new.dat, gzfile(${_output:r}), sep=\"\\t\", quote=F, col.names=T, row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Extract per unit variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# this step provides VCF file index\n",
    "[index_vcf: provides = '{filename}.gz.tbi']\n",
    "depends: executable('tabix')\n",
    "input: f\"{filename}.gz\"\n",
    "bash: expand=True\n",
    "   tabix -p vcf {_input}\n",
    "\n",
    "# Extract cis-SNPs and make fine-mapping datasets\n",
    "[preprocess_2, DAP_2 (Get per-unit dataset)]\n",
    "depends: Py_Module('pysam'), Py_Module('pandas'), Py_Module('feather'), f\"{x_data}.tbi\"\n",
    "chroms = [f'chr{x+1}' for x in range(22)]\n",
    "input: for_each = 'chroms', concurrent = True\n",
    "output: dynamic(glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/chr*/*.feather'))\n",
    "python: workdir = cwd, expand = \"${ }\"\n",
    "    def read_header(gzfile):\n",
    "        import gzip\n",
    "        with gzip.open(gzfile,'r') as f:\n",
    "            for line in f:\n",
    "                res = [x.decode() for x in line.split()]\n",
    "                break\n",
    "        return res\n",
    "\n",
    "    chrom = \"${_chroms}\"\n",
    "    phenotype_id = [f'${pop}_{x}' for x in read_header(${_input:r})[4:]]\n",
    "    vcf_id = [f'${pop}_{x}' for x in read_header(${x_data:r})[9:]]\n",
    "    from pathlib import Path\n",
    "    import pysam\n",
    "    tbx = pysam.TabixFile(${x_data:r})    \n",
    "    import pandas as pd, numpy as np\n",
    "    from feather import write_dataframe\n",
    "    qts = pd.read_csv(${_input:r}, sep = '\\t')\n",
    "    qts = qts.loc[qts['chr'] == chrom]\n",
    "    #\n",
    "    import os, time, tempfile\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    for site in sorted(set(qts['start'].tolist())):\n",
    "        if(i % 100 == 0):\n",
    "            print('[chrom %s percent completed] %.1f (%.1f sec elapsed)' % (chrom, (float(i+1)/qts.shape[0])*100, time.time() - start_time))        \n",
    "        unit = qts.loc[qts['start'] == site]\n",
    "        i += unit.shape[0]\n",
    "        start = max(site - ${max_dist}, 0)\n",
    "        end = site + ${max_dist}\n",
    "        genotypes = np.array([row for row in tbx.fetch(chrom, start, end, parser=pysam.asTuple())])\n",
    "        if len(genotypes) == 0:\n",
    "            continue\n",
    "        Y_data = unit.drop([\"chr\", \"start\", \"end\", \"ID\"], axis=1).T\n",
    "        Y_data.columns = [x.replace(':', '_') for x in unit['ID']]\n",
    "        Y_data.index = phenotype_id\n",
    "        X_data = pd.DataFrame(genotypes[:,9:].T,\n",
    "                              columns = ['_'.join(x) for x in genotypes[:,[2,0,1,3,4]]], \n",
    "                              index = vcf_id)\n",
    "        merged = Y_data.join(X_data, how='inner').astype(np.float32)\n",
    "        Path(f'${cwd}/${y_data:bnn}_${int(max_dist/1000)}Kb/{chrom}').mkdir(exist_ok=True, parents=True)\n",
    "        basename = f'${cwd}/${y_data:bnn}_${int(max_dist/1000)}Kb/{chrom}/{chrom}_{site}_{max(unit[\"end\"].tolist())}'\n",
    "        # FIXME: this will be a large file because feather format is not yet compressed ... \n",
    "        # This is being discussed by the feather development group and hopefully compression will be supported in later 2018\n",
    "        write_dataframe(merged, basename + '.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Summary statistics and PVE estimate\n",
    "\n",
    "We want to estimate PVE from the top signal in each unit, to have an idea of how SuSiE prior variance should be configured. We can also compute summary statistics at this stage. We save only z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Summary statistics and PVE estimates\n",
    "[preprocess_3 (PVE)]\n",
    "depends: R_library('feather'), R_library('susieR')\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.rds'\n",
    "R: expand = '${ }'\n",
    "    library(feather)\n",
    "    dat = read_feather(${_input:r})\n",
    "    n_y = length(grep(\"^chr\", colnames(dat), value = T))\n",
    "    Y = as.matrix(dat[,1:n_y,drop=F])\n",
    "    X = as.matrix(dat[,(n_y+1):ncol(dat),drop=F])\n",
    "    storage.mode(X) = 'double'\n",
    "    storage.mode(Y) = 'double'\n",
    "    bad = which(sapply(1:ncol(X), function(i) all(is.na(X[,i]))))\n",
    "    if (length(bad) >= 1) {\n",
    "      snps = colnames(X)[-bad]\n",
    "      X = X[,-bad]\n",
    "    } else {\n",
    "      snps = colnames(X)\n",
    "    }\n",
    "    res = list()\n",
    "    for (r in 1:ncol(Y)) {\n",
    "      keep_rows = which(!is.na(Y[,r]))\n",
    "      x = X[keep_rows,]\n",
    "      y = Y[,r][keep_rows]\n",
    "      reg = susieR:::univariate_regression(x,y)\n",
    "      z_score = reg$betahat/reg$sebetahat\n",
    "      names(z_score) = snps\n",
    "      top_idx = which.max(abs(z_score))\n",
    "      pve = var(x[,top_idx] * reg$betahat[top_idx]) / var(y)\n",
    "      res[[r]] = list(X=x, y=y, z_score=z_score, pve=pve, uname=colnames(Y)[[r]])\n",
    "    }\n",
    "    saveRDS(res, ${_output:r})\n",
    "_input.zap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Prepare for DAP-g full data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# DAP input format\n",
    "[DAP_3]\n",
    "depends: R_library('feather')\n",
    "input: glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/chr*/*.feather'), group_by = 1, concurrent = True\n",
    "output: f'{_input:dd}/DAP-g/{_input:bn}.DAP.gz'\n",
    "R: expand = '${ }'\n",
    "    library(feather)\n",
    "    dat = read_feather(${_input:r})\n",
    "    n_y = length(grep(\"^chr\", colnames(dat), value = T))\n",
    "    Y = as.matrix(dat[,1:n_y,drop=F])\n",
    "    X = as.matrix(dat[,(n_y+1):ncol(dat),drop=F])\n",
    "    storage.mode(X) = 'double'\n",
    "    storage.mode(Y) = 'double'\n",
    "    bad = which(sapply(1:ncol(X), function(i) all(is.na(X[,i]))))\n",
    "    if (length(bad) >= 1) {\n",
    "      snps = colnames(X)[-bad]\n",
    "      X = X[,-bad]\n",
    "    } else {\n",
    "      snps = colnames(X)\n",
    "    }\n",
    "    # usually r = 1\n",
    "    pheno = NULL\n",
    "    geno = NULL\n",
    "    for (r in 1:ncol(Y)) {\n",
    "      keep_rows = which(!is.na(Y[,r]))\n",
    "      x = X[keep_rows,]\n",
    "      y = Y[,r][keep_rows]\n",
    "      ydat = c('pheno', '${y_data:bnn}', colnames(Y)[r], y)\n",
    "      xdat = cbind(rep('geno', ncol(x)), colnames(x), rep(colnames(Y)[r], ncol(x)), t(x))\n",
    "      if (is.null(pheno)) {\n",
    "          pheno = ydat\n",
    "          geno = xdat\n",
    "      } else {\n",
    "          pheno = rbind(pheno, ydat)\n",
    "          geno = rbind(geno, xdat)\n",
    "      }\n",
    "    }\n",
    "    write.table(rbind(pheno, geno), gzfile(${_output:r}), quote=F,col.names=F,row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Finemapping with SuSiE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This step takes 3hrs on my 40-thread machine: \n",
    "\n",
    "```\n",
    "sos run analysis/20180704_MolecularQTL_Workflow.ipynb SuSiE \\\n",
    "    --x-data ~/GIT/LargeFiles/AS/genotypesYRI.gen.txt.gz \\\n",
    "    --y-data ~/GIT/LargeFiles/AS/fastqtl_qqnorm_ASintron_RNAseqGeuvadis_YangVCF.txt.gz \\\n",
    "    --max-dist 100000 -j 38\n",
    "```\n",
    "\n",
    "and we only plot the ones SuSiE reports at least 1 CS: \n",
    "\n",
    "```\n",
    "sos run analysis/20180704_MolecularQTL_Workflow.ipynb SuSiE_summary \\\n",
    "    --x-data ~/GIT/LargeFiles/AS/genotypesYRI.gen.txt.gz \\\n",
    "    --y-data ~/GIT/LargeFiles/AS/fastqtl_qqnorm_ASintron_RNAseqGeuvadis_YangVCF.txt.gz \\\n",
    "    --max-dist 100000 -j 38\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run finemapping with SuSiE\n",
    "[SuSiE (SuSiE analysis)]\n",
    "depends: R_library('susieR')\n",
    "# SuSiE parameter: L\n",
    "parameter: maxL = 5\n",
    "# SuSiE parameter: prior variance\n",
    "parameter: prior_var = 0.1\n",
    "input: glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/chr*/*.rds'), group_by = 1, concurrent = True\n",
    "output: dynamic(glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/SuSiE_CS_*/*.rds'))\n",
    "#task: trunk_workers = 1, queue = 'midway2_head', walltime = '10m', trunk_size = 1000, mem = '2G', cores = 1, workdir = cwd, concurrent = True\n",
    "R: expand = \"${ }\"\n",
    "    library(susieR)\n",
    "    set.seed(1)\n",
    "    dat = readRDS(${_input:r})\n",
    "    for (r in length(dat)) {\n",
    "      fitted = susie(dat[[r]]$X, dat[[r]]$y,\n",
    "               L=${maxL},\n",
    "               estimate_residual_variance=TRUE, \n",
    "               prior_variance=${prior_var}, \n",
    "               intercept=FALSE,\n",
    "               tol=1e-3)\n",
    "      sets = susie_get_CS(fitted,\n",
    "                    coverage = 0.95,\n",
    "                    X = dat[[r]]$X, \n",
    "                    min_abs_corr = 0.4)\n",
    "      pip = susie_get_PIP(fitted, sets$cs_index)\n",
    "      dirname = paste0('${cwd}/${y_data:bnn}_${int(max_dist/1000)}Kb/SuSiE_CS_', length(sets$cs_index), '/')\n",
    "      system(paste(\"mkdir -p\", dirname))\n",
    "      if (length(sets$cs_index) > 0) {\n",
    "          saveRDS(list(input=${_input:r},idx=r,fitted=fitted,sets=sets,pip=pip), paste0(dirname, dat[[r]]$uname, '.rds'))\n",
    "      } else {\n",
    "          saveRDS(list(input=${_input:r},idx=r,fitted=fitted), paste0(dirname, dat[[r]]$uname, '.rds'))       \n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Make SuSiE result plots for significant results\n",
    "[SuSiE_summary (plot SuSiE results)]\n",
    "input: glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/SuSiE_CS_[1-9]/*.rds'), group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.png'\n",
    "R: expand = '${ }', stdout = f'{_output:n}.log'\n",
    "    library(susieR)\n",
    "    dat = readRDS(${_input:r})\n",
    "    z_score = readRDS(dat$input)[[dat$idx]]$z_score\n",
    "    b = rep(0,length(z_score))\n",
    "    b[which.max(abs(z_score))] = 1\n",
    "    png(${_output:r}, 12, 6, units = 'in', res = 500)\n",
    "    par(mfrow=c(1,2))\n",
    "    susie_pplot(z_score, dtype='z', b=b)\n",
    "    susie_pplot(dat$pip, fitted=dat$fitted, dtype='PIP', b=b) \n",
    "    dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Finemapping with DAP\n",
    "\n",
    "```\n",
    "sos run analysis/20180704_MolecularQTL_Workflow.ipynb DAP \\\n",
    "    --x-data ~/GIT/LargeFiles/AS/genotypesYRI.gen.txt.gz \\\n",
    "    --y-data ~/GIT/LargeFiles/m6A/fastqtl_m6A_merged_peaks_IPcounts_YangVCF.txt.gz \\\n",
    "    --max-dist 100000 --num-pcs 7 -j 38\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run DAP-g\n",
    "[DAP_4 (run DAP-g)]\n",
    "depends: Py_Module('dsc'), Py_Module('rpy2')\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.output.rds'\n",
    "bash: expand = True, stdout = f'{_output:n}.log'\n",
    "    dap-g -d <(zcat {_input}) -o {_output:n} -t 1 --all\n",
    "\n",
    "python: expand = '${ }'\n",
    "    import pandas as pd\n",
    "    def extract_dap_output(fn):\n",
    "        out = [x.strip().split() for x in open(fn).readlines()]\n",
    "        pips = []\n",
    "        clusters = []\n",
    "        still_pip = True\n",
    "        for line in out:\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            if len(line) > 2 and line[2] == 'cluster_pip':\n",
    "                still_pip = False\n",
    "                continue\n",
    "            if still_pip and (not line[0].startswith('((')):\n",
    "                continue\n",
    "            if still_pip:\n",
    "                pips.append([line[1], float(line[2]), float(line[3]), int(line[4])])\n",
    "            else:\n",
    "                clusters.append([len(clusters) + 1, float(line[2]), float(line[3])])\n",
    "        pips = pd.DataFrame(pips, columns = ['snp', 'snp_prob', 'snp_log10bf', 'cluster'])\n",
    "        clusters = pd.DataFrame(clusters, columns = ['cluster', 'cluster_prob', 'cluster_avg_r2'])\n",
    "        clusters = pd.merge(clusters, pips.groupby(['cluster'])['snp'].apply(','.join).reset_index(), on = 'cluster')\n",
    "        return {'snp': pips, 'set': clusters}\n",
    "\n",
    "    from dsc.dsc_io import save_rds\n",
    "    save_rds(extract_dap_output(${_output:nr}), ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Follow-up: verify with CAVIAR\n",
    "\n",
    "I found ~1600 splicing QTLs. Only about 150 reports more than 1 CS. But most of these 2+ QTLs are from a scenarios that there seemingly is one signal cluster from the z-score but SuSiE decides to use two CS to capture that cluster.\n",
    "\n",
    "Another observation from the SuSiE analysis is that in a number of cases the smallest p-value is not picked up.\n",
    "\n",
    "To verify how many signals are in there when there is seemingly one cluster visually, we run CAVIAR for those data. Input for CAVIAR are z-scores and LD matrices.\n",
    "\n",
    "```\n",
    "sos run analysis/20180704_MolecularQTL_Workflow.ipynb CAVIAR_follow_up \\\n",
    "    --x-data ~/GIT/LargeFiles/AS/genotypesYRI.gen.txt.gz \\\n",
    "    --y-data ~/GIT/LargeFiles/AS/fastqtl_qqnorm_ASintron_RNAseqGeuvadis_YangVCF.txt.gz \\\n",
    "    --max-dist 100000 -b ~/GIT/github/mvarbvs/dsc/modules/linux/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run CAVIAR on SuSiE results of interest\n",
    "[CAVIAR_follow_up_1]\n",
    "parameter: caviar_args = '-c 2'\n",
    "input: glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/SuSiE_CS_[2-9]/*.rds'), group_by = 1, concurrent = True\n",
    "output: dynamic(glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/CAVIAR_follow_up/*.rds'))\n",
    "R: expand = '${ }', stdout = False, stderr = False\n",
    "    library('dplyr')\n",
    "    library('magrittr')\n",
    "    #' CAVIAR I/O\n",
    "    write_caviar_sumstats <- function(z, prefix) {\n",
    "      cfg = list(z=paste0(prefix,\".z\"),\n",
    "                 set=paste0(prefix,\"_set\"),\n",
    "                 post=paste0(prefix,\"_post\"),\n",
    "                 log=paste0(prefix,\".log\"))\n",
    "      write.table(z,cfg$z,quote=F,col.names=F)\n",
    "      return(cfg)\n",
    "    }\n",
    "\n",
    "    #' Run CAVIAR\n",
    "    #' https://github.com/fhormoz/caviar\n",
    "    run_caviar <- function(z, X, args = \"\", prefix=\"data\")\n",
    "    {\n",
    "      cfg = write_caviar_sumstats(z, prefix)\n",
    "      LD_file = paste0(prefix, '.ld')\n",
    "      write.table(cor(X), LD_file,quote=F,col.names=F,row.names=F)\n",
    "      cmd = paste(\"CAVIAR\", \"-z\", cfg$z, \"-l\", LD_file, \"-o\", prefix, args)\n",
    "      dscrutils::run_cmd(cmd)\n",
    "      if(!all(file.exists(cfg$post, cfg$set, cfg$log))) {\n",
    "          stop(\"Cannot find one of the post, set, and log files\")\n",
    "      }\n",
    "\n",
    "      log <- readLines(cfg$log)\n",
    "\n",
    "      # read output tables\n",
    "      snp <- read.delim(cfg$post)  \n",
    "      stopifnot(ncol(snp) == 3)\n",
    "      names(snp) <- c(\"snp\", \"snp_prob_set\", \"snp_prob\")\n",
    "      snp$snp <- as.character(snp$snp)\n",
    "      snp <- rank_snp(snp)\n",
    "\n",
    "      # `set` of snps\n",
    "      set <- readLines(cfg$set)\n",
    "      set_ordered <- left_join(data_frame(snp = set), snp, by = \"snp\") %>% \n",
    "        arrange(rank) %$% snp\n",
    "      return(list(snp=snp, set=set_ordered))\n",
    "    }\n",
    "\n",
    "    rank_snp <- function(snp) {\n",
    "      snp <- arrange(snp, -snp_prob) %>%\n",
    "        mutate(\n",
    "            rank = seq(1, n()),\n",
    "            snp_prob_cumsum = cumsum(snp_prob) / sum(snp_prob)) %>%\n",
    "        select(rank, snp, snp_prob, snp_prob_cumsum, snp_prob_set)\n",
    "      return(snp)    \n",
    "    }\n",
    "    #\n",
    "    susie_res = readRDS(${_input:r})\n",
    "    dat = readRDS(susie_res$input)[[susie_res$idx]]\n",
    "    dirname = '${cwd}/${y_data:bnn}_${int(max_dist/1000)}Kb/CAVIAR_follow_up/'\n",
    "    system(paste(\"mkdir -p\", dirname))\n",
    "    # CAVIAR CODE\n",
    "    caviar = run_caviar(dat$z_score, dat$X, args = '${caviar_args}', prefix = paste0(${_input:nr}, '_', dat$uname))\n",
    "    saveRDS(list(susie_res=${_input:r}, pip=caviar$snp,sets=caviar$set_ordered), paste0(dirname, dat$uname, '.rds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Plot CAVIAR vs SuSiE results\n",
    "[CAVIAR_follow_up_2]\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.png'\n",
    "R: expand = '${ }'\n",
    "    library(susieR)\n",
    "    caviar_res = readRDS(${_input:r})\n",
    "    susie_res = readRDS(caviar_res$susie_res)\n",
    "    z_score = readRDS(susie_res$input)[[susie_res$idx]]$z_score\n",
    "    b = rep(0,length(z_score))\n",
    "    b[which.max(abs(z_score))] = 1\n",
    "    # re-organize caviar\n",
    "    caviar_pip = caviar_res$pip$snp_prob\n",
    "    names(caviar_pip) = caviar_res$pip$snp\n",
    "    caviar_pip = caviar_pip[names(z_score)]\n",
    "    png(${_output:r}, 12, 12, units = 'in', res = 500)\n",
    "    par(mfrow=c(2,2))\n",
    "    susie_pplot(z_score, dtype='z', b=b)\n",
    "    susie_pplot(susie_res$pip, fitted=susie_res$fitted, dtype='PIP', b=b)\n",
    "    plot(susie_pip, caviar_pip, pch = 16, xlab='SuSiE_PIP', ylab = 'CAVIAR_PIP')\n",
    "    abline(a=0,b=1,col='red')\n",
    "    susie_pplot(caviar_pip, dtype='PIP', b=b)\n",
    "    dev.off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
