{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Molecular QTL workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table class=\"revision_table\">\n",
       "        <tr>\n",
       "        <th>Revision</th>\n",
       "        <th>Author</th>\n",
       "        <th>Date</th>\n",
       "        <th>Message</th>\n",
       "        <tr>\n",
       "        <tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/63045aa248abe96b401e0d0cd683b7b6c7505f84/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">63045aa<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-05</td>\n",
       "<td>Change figure layout</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/8c6e7228fc00c568d0e38685b9325c69fdd2ac79/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">8c6e722<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-05</td>\n",
       "<td>Add cluster configurations</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/aeaf3fabea9f05ba33b9667f47f92dfdd819bbe7/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">aeaf3fa<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-05</td>\n",
       "<td>Fix susie execution pipeline step</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/1420e4c8e3300f7becd18b0fd4c6b749c8554e4e/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">1420e4c<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-05</td>\n",
       "<td>Use chromsomes as batches</td></tr><tr><td><a target=\"_blank\" href=\"http://github.com/gaow/mvarbvs/blob/044e3a10eece52e08e5c5ce34eeb11c1b713a196/20180704_MolecularQTL_Workflow.ipynb\"><span class=\"revision_id\">044e3a1<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-07-04</td>\n",
       "<td>Add data convertion pipeline for molecular qtls</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%revisions -s -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Data\n",
    "\n",
    "Molecular QTL data from [Yang et al (2016) Science](http://eqtl.uchicago.edu/jointLCL/). Input are genotypes of ~100 YRI samples with their molecular QTL data measured in LCL.\n",
    "\n",
    "- alternative splicing (AS) data is of the primary interest here.\n",
    "\n",
    "### Genotypes\n",
    "\n",
    "[Genotype data for YRI](http://eqtl.uchicago.edu/jointLCL/genotypesYRI.gen.txt.gz) is the conventional VCF format but has dosage for genotypes.\n",
    "\n",
    "### Phenotypes\n",
    "\n",
    "Phenotype data has format:\n",
    "\n",
    "```\n",
    "#Chr\tstart\tend\tID\t18486\t18487\t18488\t18489\t18498\t18499\n",
    "chr1\t880180\t880422\tchr1:880180:880422:clu_15502\t0.201694364955\t0.665990212763\t-1.21881815589\t-0.342480185427\t0.165404160483\t-1.58524292941\n",
    "```\n",
    "\n",
    "The first 4 columns are genomic coordinates info. Others are molecular QTL in samples.\n",
    "\n",
    "We analyze:\n",
    "\n",
    "1. [Alternative splicing](http://eqtl.uchicago.edu/jointLCL/qqnorm_ASintron_RNAseqGeuvadis.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Analysis plan\n",
    "\n",
    "- For each analysis unit (gene, or intron cluster for AS), get the 1MB up/down-stream variants in genotypes\n",
    "- Remove top phenotype PC from phenotype data\n",
    "- Fine-mapping using various methods. SuSiE for starters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run 20180704_MolecularQTL_Workflow.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  preprocess\n",
      "  index_vcf\n",
      "  SuSiE\n",
      "  SuSiE_Summary\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd /home/gaow/GIT/LargeFiles/AS_output (as path)\n",
      "                        Specify work directory\n",
      "  --x-data . (as path)\n",
      "                        X data, the genotype VCF file path\n",
      "  --y-data . (as path)\n",
      "                        Y data, the phenotype file paths\n",
      "  --max-dist 1000000 (as int)\n",
      "                        Maximum distance to site of interest, eg. 1Mb\n",
      "                        up/downstream to TSS for gene level QTL\n",
      "\n",
      "Sections\n",
      "  preprocess_1:         PCA on phenotype and remove top PCs\n",
      "    Workflow Options:\n",
      "      --num-pcs 3 (as int)\n",
      "                        Num. PC to remove from phenotype\n",
      "      --colname-pattern '^[0-9]+'\n",
      "                        column name patter for `grep` in R to select phenotype\n",
      "                        columns eg. \"^NA[0-9]+\" to extract sample names\n",
      "  index_vcf:            this step provides VCF file index\n",
      "  preprocess_2:         Extract cis-SNPs and make fine-mapping datasets\n",
      "  SuSiE:                Run finemapping with SuSiE\n",
      "    Workflow Options:\n",
      "      --maxL 5 (as int)\n",
      "      --prior-var 0.1 (as float)\n",
      "  SuSiE_Summary:        Make SuSiE result plots for significant results\n"
     ]
    }
   ],
   "source": [
    "!sos run 20180704_MolecularQTL_Workflow.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Specify work directory\n",
    "parameter: cwd = path(\"~/GIT/LargeFiles/AS_output\")\n",
    "# X data, the genotype VCF file path\n",
    "parameter: x_data = path()\n",
    "# Y data, the phenotype file paths\n",
    "parameter: y_data = path()\n",
    "# Maximum distance to site of interest, eg. 1Mb up/downstream to TSS for gene level QTL\n",
    "parameter: max_dist = 1000000\n",
    "fail_if(not x_data.is_file() and not h5_data.is_file(), msg = 'Please provide ``--x-data`` or ``--h5-data``!')\n",
    "fail_if(not y_data.is_file() and not h5_data.is_file(), msg = 'Please provide ``--y-data`` or ``--h5-data``!')\n",
    "pop = 'YRI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The preprocessing pipeline can be executed locally, takes 2hrs:\n",
    "\n",
    "```\n",
    "sos run analysis/20180704_MolecularQTL_Workflow.ipynb preprocess \\\n",
    "    --x-data ~/GIT/LargeFiles/AS/genotypesYRI.gen.txt.gz \\\n",
    "    --y-data ~/GIT/LargeFiles/AS/fastqtl_qqnorm_ASintron_RNAseqGeuvadis_YangVCF.txt.gz \\\n",
    "    --max-dist 1000000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Regressing out top PCs on phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "There may well be better approach to control for covariates etc, but [here](https://github.com/bmvdgeijn/WASP/blob/master/examples/example_data/H3K27ac/get_PCs.R) is workflow from the authors and was deemed sufficient. See their supplemental table of Yang et al 2016 for how many PC to use for each molecular QTLs.\n",
    "\n",
    "Need to cope with missing phenotype data here. See `na.omit` function call in `prcomp` and `na.actions=na.exclude`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# PCA on phenotype and remove top PCs\n",
    "[preprocess_1 (Remove top phenotype PC)]\n",
    "# Num. PC to remove from phenotype\n",
    "parameter: num_pcs = 3 # Table S2 of NIHMS835311-supplement-supplement.pdf\n",
    "# column name patter for `grep` in R to select phenotype columns\n",
    "# eg. \"^NA[0-9]+\" to extract sample names\n",
    "parameter: colname_pattern = '^[0-9]+'\n",
    "input: y_data\n",
    "output: f\"{cwd}/{_input:bn}.PC{num_pcs}.removed.gz\"\n",
    "R: expand = \"${ }\", workdir = cwd, stdout = f\"{_output:n}.stdout\"\n",
    "    num_pcs = ${num_pcs}\n",
    "    dat <- read.table(${_input:r}, header=T, comment.char='', check.names=F)\n",
    "    phenotype.matrix <- dat[,5:ncol(dat)]\n",
    "    # extract columns of interest\n",
    "    phenotype.matrix <- phenotype.matrix[,grep(\"${colname_pattern}\", colnames(phenotype.matrix), value = T)]\n",
    "    # perform principal component analysis\n",
    "    pca <- prcomp(na.omit(phenotype.matrix))\n",
    "    # PCA summary\n",
    "    print(summary(pca))\n",
    "    cat(\"output\", num_pcs, \"PCs \\n\")\n",
    "    # remove top PC from phenotype; takes a while\n",
    "    cov_pcs <- pca$rotation[, 1:num_pcs]\n",
    "    new.phenotype.matrix <- do.call(rbind, lapply(1:nrow(phenotype.matrix), function(i) residuals(lm(t(phenotype.matrix[i,]) ~ as.matrix(cov_pcs), na.action=na.exclude))))\n",
    "    colnames(new.phenotype.matrix) <- colnames(phenotype.matrix)\n",
    "    new.dat <- cbind(dat[,1:4], new.phenotype.matrix)\n",
    "    colnames(new.dat)[1] <- 'chr'\n",
    "    write.table(new.dat, gzfile(${_output:r}), sep=\"\\t\", quote=F, col.names=T, row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Extract per unit variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# this step provides VCF file index\n",
    "[index_vcf: provides = '{filename}.gz.tbi']\n",
    "depends: executable('tabix')\n",
    "input: f\"{filename}.gz\"\n",
    "bash: expand=True\n",
    "   tabix -p vcf {_input}\n",
    "\n",
    "# Extract cis-SNPs and make fine-mapping datasets\n",
    "[preprocess_2 (Get per-unit dataset)]\n",
    "depends: Py_Module('pysam'), Py_Module('pandas'), Py_Module('feather'), Py_Module('rpy2'), f\"{x_data}.tbi\"\n",
    "chroms = [f'chr{x+1}' for x in range(22)]\n",
    "input: for_each = 'chroms', concurrent = True\n",
    "output: dynamic(glob.glob('{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/chr*/*.rds'))\n",
    "python: workdir = cwd, expand = \"${ }\"\n",
    "    def read_header(gzfile):\n",
    "        import gzip\n",
    "        with gzip.open(gzfile,'r') as f:\n",
    "            for line in f:\n",
    "                res = [x.decode() for x in line.split()]\n",
    "                break\n",
    "        return res\n",
    "\n",
    "    chrom = \"${_chroms}\"\n",
    "    phenotype_id = [f'${pop}_{x}' for x in read_header(${_input:r})[4:]]\n",
    "    vcf_id = [f'${pop}_{x}' for x in read_header(${x_data:r})[9:]]\n",
    "    from pathlib import Path\n",
    "    import pysam\n",
    "    tbx = pysam.TabixFile(${x_data:r})    \n",
    "    import pandas as pd, numpy as np\n",
    "    from feather import write_dataframe\n",
    "    qts = pd.read_csv(${_input:r}, sep = '\\t')\n",
    "    qts = qts.loc[qts['chr'] == chrom]\n",
    "    #\n",
    "    import os, time, tempfile\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    cmds = [\"library(feather)\"]\n",
    "    tf = tempfile.NamedTemporaryFile()\n",
    "    for site in sorted(set(qts['start'].tolist())):\n",
    "        if(i % 100 == 0):\n",
    "            print('[chrom %s percent completed] %.1f (%.1f sec elapsed)' % (chrom, (float(i+1)/qts.shape[0])*100, time.time() - start_time))\n",
    "            if len(cmds) > 1:\n",
    "                with open(tf.name, 'w') as f:\n",
    "                    f.write('\\n'.join(cmds))\n",
    "                os.system(f\"Rscript {tf.name}\")\n",
    "                cmds = [\"library(feather)\"]            \n",
    "        unit = qts.loc[qts['start'] == site]\n",
    "        i += unit.shape[0]\n",
    "        start = max(site - ${max_dist}, 0)\n",
    "        end = site + ${max_dist}\n",
    "        genotypes = np.array([row for row in tbx.fetch(chrom, start, end, parser=pysam.asTuple())])\n",
    "        if len(genotypes) == 0:\n",
    "            continue\n",
    "        Y_data = unit.drop([\"chr\", \"start\", \"end\", \"ID\"], axis=1).T\n",
    "        Y_data.columns = [x.replace(':', '_') for x in unit['ID']]\n",
    "        Y_data.index = phenotype_id\n",
    "        X_data = pd.DataFrame(genotypes[:,9:].T,\n",
    "                              columns = ['_'.join(x) for x in genotypes[:,[2,0,1,3,4]]], \n",
    "                              index = vcf_id)\n",
    "        merged = Y_data.join(X_data, how='inner').astype(np.float32)\n",
    "        Path(f'${cwd}/${y_data:bnn}_${int(max_dist/1000)}Kb/{chrom}').mkdir(exist_ok=True, parents=True)\n",
    "        basename = f'${cwd}/${y_data:bnn}_${int(max_dist/1000)}Kb/{chrom}/{chrom}_{site}_{max(unit[\"end\"].tolist())}'\n",
    "        write_dataframe(merged, basename + '.feather')\n",
    "        cmds.append(\"saveRDS(read_feather('{0}'), '{1}');system('rm -f {0}')\".format(basename + '.feather', basename + '.rds'))\n",
    "    #\n",
    "    if len(cmds) > 1:\n",
    "        with open(tf.name, 'w') as f:\n",
    "            f.write('\\n'.join(cmds))\n",
    "        os.system(f\"Rscript {tf.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Finemapping with SuSiE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This step is to be executed on midway. \n",
    "\n",
    "```\n",
    "sos run analysis/20180704_MolecularQTL_Workflow.ipynb SuSiE \\\n",
    "    --x-data ~/GIT/LargeFiles/AS/genotypesYRI.gen.txt.gz \\\n",
    "    --y-data ~/GIT/LargeFiles/AS/fastqtl_qqnorm_ASintron_RNAseqGeuvadis_YangVCF.txt.gz \\\n",
    "    --max-dist 100000 \\\n",
    "    -c ~/software/sos.config.yml -J 40\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run finemapping with SuSiE\n",
    "[SuSiE (SuSiE analysis)]\n",
    "depends: R_library('susieR')\n",
    "parameter: maxL = 5\n",
    "parameter: prior_var = 0.1\n",
    "input: glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/chr*/*.rds'), group_by = 1, concurrent = True\n",
    "output: dynamic(glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/SuSiE_CS_*/*.rds'))\n",
    "#task: trunk_workers = 1, queue = 'midway2_head', walltime = '10m', trunk_size = 1000, mem = '2G', cores = 1, workdir = cwd, concurrent = True\n",
    "R: expand = \"${ }\"\n",
    "    library(susieR)\n",
    "    dat = readRDS(${_input:r})\n",
    "    n_y = length(grep(\"^chr\", colnames(dat), value = T))\n",
    "    Y = as.matrix(dat[,1:n_y,drop=F])\n",
    "    X = as.matrix(dat[,(n_y+1):ncol(dat),drop=F])\n",
    "    storage.mode(X) = 'double'\n",
    "    storage.mode(Y) = 'double'\n",
    "    bad = which(sapply(1:ncol(X), function(i) all(is.na(X[,i]))))\n",
    "    if (length(bad) >= 1) {\n",
    "      snps = colnames(X)[-bad]\n",
    "      X = X[,-bad]\n",
    "    } else {\n",
    "      snps = colnames(X)\n",
    "    }\n",
    "    for (r in ncol(Y)) {\n",
    "      keep_rows = which(!is.na(Y[,r]))\n",
    "      x = X[keep_rows,]\n",
    "      y = Y[,r][keep_rows]\n",
    "      z_score = susieR:::calc_z(x,y)\n",
    "      names(z_score) = snps\n",
    "      fitted = susie(x, y,\n",
    "               L=${maxL},\n",
    "               estimate_residual_variance = TRUE, \n",
    "               prior_variance = ${prior_var}, \n",
    "               intercept=FALSE,\n",
    "               tol=1e-3)\n",
    "      sets = susie_get_CS(fitted,\n",
    "                    coverage = 0.95,\n",
    "                    X = x, \n",
    "                    min_abs_corr = 0.4)\n",
    "      pip = susie_get_PIP(fitted, sets$cs_index)\n",
    "      dirname = paste0('${cwd}/${y_data:bnn}_${int(max_dist/1000)}Kb/SuSiE_CS_', length(sets$cs_index), '/')\n",
    "      system(paste(\"mkdir -p\", dirname))\n",
    "      if (length(sets$cs_index) > 0) {\n",
    "          saveRDS(list(z_score=z_score,fitted=fitted,sets=sets,pip=pip), paste0(dirname, colnames(Y)[r], '.rds'))\n",
    "      } else {\n",
    "          saveRDS(list(z_score=z_score,fitted=fitted), paste0(dirname, colnames(Y)[r], '.rds'))          \n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Make SuSiE result plots for significant results\n",
    "[SuSiE_Summary (plot SuSiE results)]\n",
    "input: glob.glob(f'{cwd}/{y_data:bnn}_{int(max_dist/1000)}Kb/SuSiE_CS_[1-9]/*.rds'), group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.png'\n",
    "R: expand = '${ }', stdout = f'{_output:n}.log'\n",
    "    library(susieR)\n",
    "    dat = readRDS(${_input:r})\n",
    "    b = rep(0,length(dat$z_score))\n",
    "    b[which.max(abs(dat$z_score))] = 1\n",
    "    png(${_output:r}, 12, 6, units = 'in', res = 500)\n",
    "    par(mfrow=c(1,2))\n",
    "    susie_pplot(dat$z_score, dtype='z', b=b)\n",
    "    susie_pplot(dat$pip, fitted=dat$fitted, dtype='PIP', b=b) \n",
    "    dev.off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
