{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# UKB Blood Cells Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. For each data-set, take the strongest snp as the strong set\n",
    "2. Also select from each data-set 2 \"null\" snps.\n",
    "3. then try to run your estimate of Vhat to get Vhat first, and run Yunqi / Peter's ED\n",
    "\n",
    "In UKB bloodcells, we have about 600 regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path('/project2/mstephens/yuxin/ukb-bloodcells')\n",
    "parameter: name = 'ukbbloodcells_prepare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project2/mstephens/gaow/mvarbvs/dsc/mnm_prototype/mnm_sumstats"
     ]
    }
   ],
   "source": [
    "%cd /project2/mstephens/yuxin/ukb-bloodcells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Get top SNP and random close to null SNP per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract data from summary stats\n",
    "[extract_effects_1]\n",
    "parameter: datadir = path\n",
    "parameter: seed = 999\n",
    "parameter: n_null = 2\n",
    "# Analysis units file. For RDS files it can be generated by `ls *.rds | sed 's/\\.rds//g' > analysis_units.txt`\n",
    "parameter: analysis_units = path\n",
    "# handle N = per_chunk data-set in one job\n",
    "parameter: per_chunk = 1000\n",
    "regions = [x.strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input: [f'{datadir}/{x[0]}.rds' for x in regions], group_by = per_chunk\n",
    "output: f\"{cwd}/{name}/cache/{name}_{_index+1}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    set.seed(${seed})\n",
    "    matxMax <- function(mtx) {\n",
    "      return(arrayInd(which.max(mtx), dim(mtx)))\n",
    "    }\n",
    "    remove_rownames = function(x) {\n",
    "        for (name in names(x)) rownames(x[[name]]) = NULL\n",
    "        return(x)\n",
    "    }\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$zhat[which(is.nan(x$bhat))] = 0\n",
    "      return(x)\n",
    "    }\n",
    "    extract_one_data = function(infile, n_null) {\n",
    "        # If cannot read the input for some reason then we just skip it, assuming we have other enough data-sets to use.\n",
    "        dat = tryCatch(readRDS(infile)$Z, error = function(e) return(NULL))\n",
    "        if (is.null(dat)) return(NULL)\n",
    "        dat = as.matrix(dat)\n",
    "        z = as.matrix(abs(dat))\n",
    "        max_idx = matxMax(z)\n",
    "        # strong effect samples\n",
    "        strong = list(zhat = dat[max_idx[1],,drop=F])\n",
    "        # null samples defined as |z| < 2\n",
    "        null.id = which(apply(abs(dat), 1, max) < 2)\n",
    "        if (length(null.id) == 0) {\n",
    "          warning(paste(\"Null data is empty for input file\", infile))\n",
    "          null = list()\n",
    "        } else {\n",
    "          null_idx = sample(null.id, min(n_null, length(null.id)), replace = F)\n",
    "          null = list(zhat = dat[null_idx,,drop=F])\n",
    "        }\n",
    "        dat = (list(null = remove_rownames(null), strong = remove_rownames(strong)))\n",
    "        dat$null = handle_nan_etc(dat$null)\n",
    "        dat$strong = handle_nan_etc(dat$strong)\n",
    "        return(dat)\n",
    "    }\n",
    "    reformat_data = function(dat) {\n",
    "        # make output consistent in format with \n",
    "        # https://github.com/stephenslab/gtexresults/blob/master/workflows/mashr_flashr_workflow.ipynb      \n",
    "        res = list(strong.z = dat$strong$zhat, null.z = dat$null$zhat)\n",
    "      return(res)\n",
    "    }\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else if (is.null(one_data)) {\n",
    "          return(res)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            if (is.null(one_data[[d]])) {\n",
    "              next\n",
    "            } else {\n",
    "                res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "            }\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    res = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      res = merge_data(res, reformat_data(extract_one_data(f, ${n_null})))\n",
    "    }\n",
    "    saveRDS(res, ${_output:r})\n",
    "\n",
    "[extract_effects_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{name}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    dat = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      dat = merge_data(dat, readRDS(f))\n",
    "    }\n",
    "    # compute empirical covariance XtX\n",
    "    dat$XtX = t(as.matrix(dat$strong.z)) %*% as.matrix(dat$strong.z) / nrow(dat$strong.z)\n",
    "                       \n",
    "    saveRDS(dat, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "m=/project2/mstephens/yuxin/ukb-bloodcells/zscores\n",
    "cd $m && ls *.rds | sed 's/\\.rds//g' > analysis_units.txt && cd -\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb extract_effects \\\n",
    "        --analysis-units $m/analysis_units.txt \\\n",
    "        --datadir $m &> extract_effects.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Covariance from Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Ycov]\n",
    "parameter: Ydata = 'bloodcells.pheno.resid.txt'\n",
    "output: f\"{cwd}/{name}.Vcov.rds\"\n",
    "R: expand = \"${ }\"\n",
    "    library(data.table)\n",
    "    traits = fread('/project2/mstephens/yuxin/ukb-bloodcells/bloodcells.pheno.resid.txt')\n",
    "    Ycov = cov(traits[,3:18])\n",
    "    saveRDS(Ycov, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb Ycov \\\n",
    "    &> Ycov.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Ycor]\n",
    "parameter: Ydata = 'bloodcells.pheno.resid.txt'\n",
    "output: f\"{cwd}/{name}.Vcor.rds\"\n",
    "R: expand = \"${ }\"\n",
    "    library(data.table)\n",
    "    traits = fread('/project2/mstephens/yuxin/ukb-bloodcells/bloodcells.pheno.resid.txt')\n",
    "    Ycor = cor(traits[,3:18])\n",
    "    saveRDS(Ycor, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb Ycor \\\n",
    "    &> Ycor.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Correlation from z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[zcor]\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.zcor.rds\"\n",
    "R: expand = \"${ }\"\n",
    "    dat = readRDS(\"${input}\")\n",
    "    saveRDS(cor(dat$null.z), ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.21.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
