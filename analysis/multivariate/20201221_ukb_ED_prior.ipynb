{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# UKB Blood Cells Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. For each data-set, take the strongest snp as the strong set\n",
    "2. Also select from each data-set 2 \"null\" snps.\n",
    "3. then try to run your estimate of Vhat to get Vhat first, and run Yunqi / Peter's ED\n",
    "\n",
    "In UKB bloodcells, we have about 600 regions with number of SNPs between 1000 and 5000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path('/project2/mstephens/yuxin/ukb-bloodcells')\n",
    "parameter: name = 'ukbbloodcells_prepare'\n",
    "parameter: mixture_components = ['flash', 'pca', 'canonical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project2/mstephens/gaow/mvarbvs/dsc/mnm_prototype/mnm_sumstats"
     ]
    }
   ],
   "source": [
    "%cd /project2/mstephens/yuxin/ukb-bloodcells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Get top SNP and random close to null SNP per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract data from summary stats\n",
    "[extract_effects_1]\n",
    "parameter: datadir = path\n",
    "parameter: seed = 999\n",
    "parameter: n_null = 2\n",
    "# Analysis units file. For RDS files it can be generated by `ls *.rds | sed 's/\\.rds//g' > analysis_units.txt`\n",
    "parameter: analysis_units = path\n",
    "# handle N = per_chunk data-set in one job\n",
    "parameter: per_chunk = 1000\n",
    "regions = [x.strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input: [f'{datadir}/{x[0]}.rds' for x in regions], group_by = per_chunk\n",
    "output: f\"{cwd}/{name}/cache/{name}_{_index+1}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    set.seed(${seed})\n",
    "    matxMax <- function(mtx) {\n",
    "      return(arrayInd(which.max(mtx), dim(mtx)))\n",
    "    }\n",
    "    remove_rownames = function(x) {\n",
    "        for (name in names(x)) rownames(x[[name]]) = NULL\n",
    "        return(x)\n",
    "    }\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$zhat[which(is.nan(x$bhat))] = 0\n",
    "      return(x)\n",
    "    }\n",
    "    extract_one_data = function(infile, n_null) {\n",
    "        # If cannot read the input for some reason then we just skip it, assuming we have other enough data-sets to use.\n",
    "        dat = tryCatch(readRDS(infile)$Z, error = function(e) return(NULL))\n",
    "        if (is.null(dat)) return(NULL)\n",
    "        dat = as.matrix(dat)\n",
    "        z = as.matrix(abs(dat))\n",
    "        max_idx = matxMax(z)\n",
    "        # strong effect samples\n",
    "        strong = list(zhat = dat[max_idx[1],,drop=F])\n",
    "        # null samples defined as |z| < 2\n",
    "        null.id = which(apply(abs(dat), 1, max) < 2)\n",
    "        if (length(null.id) == 0) {\n",
    "          warning(paste(\"Null data is empty for input file\", infile))\n",
    "          null = list()\n",
    "        } else {\n",
    "          null_idx = sample(null.id, min(n_null, length(null.id)), replace = F)\n",
    "          null = list(zhat = dat[null_idx,,drop=F])\n",
    "        }\n",
    "        dat = (list(null = remove_rownames(null), strong = remove_rownames(strong)))\n",
    "        dat$null = handle_nan_etc(dat$null)\n",
    "        dat$strong = handle_nan_etc(dat$strong)\n",
    "        return(dat)\n",
    "    }\n",
    "    reformat_data = function(dat) {\n",
    "        # make output consistent in format with \n",
    "        # https://github.com/stephenslab/gtexresults/blob/master/workflows/mashr_flashr_workflow.ipynb      \n",
    "        res = list(strong.z = dat$strong$zhat, null.z = dat$null$zhat)\n",
    "      return(res)\n",
    "    }\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else if (is.null(one_data)) {\n",
    "          return(res)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            if (is.null(one_data[[d]])) {\n",
    "              next\n",
    "            } else {\n",
    "                res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "            }\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    res = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      res = merge_data(res, reformat_data(extract_one_data(f, ${n_null})))\n",
    "    }\n",
    "    saveRDS(res, ${_output:r})\n",
    "\n",
    "[extract_effects_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{name}.z.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    dat = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      dat = merge_data(dat, readRDS(f))\n",
    "    }\n",
    "    # compute null correlation matrix\n",
    "    dat$null.cor = cor(dat$null.z)\n",
    "    # compute empirical covariance XtX\n",
    "    dat$XtX = t(as.matrix(dat$strong.z)) %*% as.matrix(dat$strong.z) / nrow(dat$strong.z)\n",
    "    \n",
    "                       \n",
    "    saveRDS(dat, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "m=/project2/mstephens/yuxin/ukb-bloodcells/zscores\n",
    "cd $m && ls *.rds | sed 's/\\.rds//g' > analysis_units.txt && cd -\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb extract_effects \\\n",
    "        --analysis-units $m/analysis_units.txt \\\n",
    "        --datadir $m &> extract_effects.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Covariance from Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Ycov]\n",
    "parameter: Ydata = 'bloodcells.pheno.resid.txt'\n",
    "input: f\"{cwd}/{name}.z.rds\"\n",
    "output: f\"{cwd}/{name}.rds\"\n",
    "R: expand = \"${ }\"\n",
    "    traits = fread('/project2/mstephens/yuxin/ukb-bloodcells/bloodcells.pheno.resid.txt')\n",
    "    Ycov = cov(traits[,3:18])\n",
    "    dat = readRDS(${_input:r})\n",
    "    dat$Ycov = Ycov\n",
    "    saveRDS(dat, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb Ycov \\\n",
    "    &> Ycov.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLASH mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[flash]\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.flash.rds\"\n",
    "task: trunk_workers = 1, walltime = '6h', trunk_size = 1, mem = '8G', cores = 2, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_flash(dat, factors=\"default\", remove_singleton=${\"TRUE\" if \"canonical\" in mixture_components else \"FALSE\"}, output_model=\"${_output:n}.model.rds\")\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb flash \\\n",
    "    &> factor_analysis.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pca]\n",
    "parameter: npc = 3\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.pca.rds\"\n",
    "task: trunk_workers = 1, walltime = '2h', trunk_size = 1, mem = '8G', cores = 2, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_pca(dat, ${npc})\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb pca \\ \n",
    "    &>> factor_analysis.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[canonical]\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.canonical.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '8G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_canonical(dat)\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb canonical \\\n",
    "    &>> factor_analysis.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run extreme deconvolution using `udr` or `mashr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installed commit d6d4c0e\n",
    "[ud]\n",
    "# Method is `ed` or `teem`\n",
    "parameter: ud_method = \"ed\"\n",
    "parameter: residcor = 'Y'\n",
    "# A list of models where we only update the scales and not the matrices\n",
    "# A typical choice is to estimate scales only for canonical components\n",
    "parameter: scale_only = []\n",
    "input: [f\"{cwd}/{name}.rds\"] + [f\"{cwd}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f'{cwd}/{name}.{residcor}.{ud_method}.{\"_unconstrained\" if len(scale_only) == 0 else \"\"}.rds'\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '10G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    scale_only = c(${paths([\"%s/%s.%s.rds\" % (cwd, name, m) for m in scale_only]):r,})\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    U_scaled = list()\n",
    "    for (f in rds_files[2:length(rds_files)]) {\n",
    "        if (f %in% scale_only) {\n",
    "          U_scaled = c(U_scaled, readRDS(f))\n",
    "        } else {\n",
    "          U = c(U, readRDS(f))\n",
    "        }\n",
    "    }\n",
    "    # Fit mixture model using udr package\n",
    "    library(udr)\n",
    "    message(paste(\"Running ${ud_method.upper()} via udr package for\", length(U), \"mixture components\"))\n",
    "    if (residcor == 'Y'){\n",
    "        V = cov2cor(dat$Ycov)\n",
    "    }else if (residcor == 'znull'){\n",
    "        V = dat$null.cor\n",
    "    }\n",
    "    f0 = ud_init(X = as.matrix(dat$strong.z), V = V, U_scaled = U_scaled, U_unconstrained = U, n_rank1=0)\n",
    "    res = ud_fit(f0, control = list(unconstrained.update = \"${ud_method}\", resid.update = 'none', scaled.update = \"em\", maxiter=5000, tol = 1e-06), verbose=TRUE)\n",
    "    # add back col and row names to U\n",
    "    # https://github.com/stephenslab/udr/issues/9\n",
    "    for (i in 1:length(res$U)) {\n",
    "        colnames(res$U[[i]]) = rownames(res$U[[i]]) = colnames(dat$strong.z)\n",
    "    }\n",
    "    saveRDS(list(U=res$U, w=res$w, loglik=res$loglik), ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ed]\n",
    "parameter: residcor = 'Y'\n",
    "input: [f\"{cwd}/{name}.rds\"] + [f\"{cwd}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f\"{cwd}/{name}.{residcor}.ed_bovy.rds\"\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '10G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    for (f in rds_files[2:length(rds_files)]) U = c(U, readRDS(f))\n",
    "    if (residcor == 'Y'){\n",
    "        V = cov2cor(dat$Ycov)\n",
    "    }else if (residcor == 'znull'){\n",
    "        V = dat$null.cor\n",
    "    }\n",
    "    # Fit mixture model using ED code by J. Bovy\n",
    "    mash_data = mashr::mash_set_data(dat$strong.z, V=V)\n",
    "    message(paste(\"Running ED via J. Bovy's code for\", length(U), \"mixture components\"))\n",
    "    res = mashr:::bovy_wrapper(mash_data, U, logfile=${_output:nr}, tol = 1e-06)\n",
    "    saveRDS(list(U=res$Ulist, w=res$pi, loglik=scan(\"${_output:n}_loglike.log\")), ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot patterns of sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[plot_U]\n",
    "parameter: model_data = path\n",
    "# number of components to show\n",
    "parameter: max_comp = -1\n",
    "# whether or not to convert to correlation\n",
    "parameter: to_cor = False\n",
    "parameter: tol = \"1E-6\"\n",
    "parameter: remove_label = False\n",
    "input: model_data\n",
    "output: f'{cwd:a}/{_input:bn}{(\"_\" + name.replace(\"$\", \"_\")) if name != \"\" else \"\"}.pdf'\n",
    "R: expand = \"${ }\"\n",
    "    plot_sharing = function(X, to_cor=FALSE, title=\"\", remove_names=F) {\n",
    "        clrs <- colorRampPalette(rev(c(\"#D73027\",\"#FC8D59\",\"#FEE090\",\"#FFFFBF\",\n",
    "                                       \"#E0F3F8\",\"#91BFDB\",\"#4575B4\")))(128)\n",
    "        if (to_cor) lat <- cov2cor(X)\n",
    "        else lat = X/max(diag(X))\n",
    "        lat[lower.tri(lat)] <- NA\n",
    "        n <- nrow(lat)\n",
    "        if (remove_names) {\n",
    "          colnames(lat) = NULL\n",
    "          rownames(lat) = NULL\n",
    "        }\n",
    "        return(lattice::levelplot(lat[n:1,],col.regions = clrs,\n",
    "                                xlab = \"\",ylab = \"\", main=title,\n",
    "                                colorkey = TRUE,at = seq(-1,1,length.out = 128),\n",
    "                                scales = list(cex = 0.6,x = list(rot = 45))))\n",
    "    }\n",
    "  \n",
    "    dat = readRDS(${_input:r})\n",
    "    name = \"${name}\"\n",
    "    if (name != \"\") {\n",
    "      if (is.null(dat[[name]])) stop(\"Cannot find data ${name} in ${_input}\")\n",
    "        dat = dat[[name]]\n",
    "    }\n",
    "    if (is.null(names(dat$U))) names(dat$U) = paste0(\"Comp_\", 1:length(dat$U))\n",
    "    meta = data.frame(names(dat$U), dat$w, stringsAsFactors=F)\n",
    "    colnames(meta) = c(\"U\", \"w\")\n",
    "    tol = ${tol}\n",
    "    n_comp = length(meta$U[which(dat$w>tol)])\n",
    "    meta = head(meta[order(meta[,2], decreasing = T),], ${max_comp if max_comp > 1 else \"nrow(meta)\"})\n",
    "    message(paste(n_comp, \"components out of\", length(dat$w), \"total components have weight greater than\", tol))\n",
    "    res = list()\n",
    "    for (i in 1:n_comp) {\n",
    "        title = paste(meta$U[i], \"w =\", round(meta$w[i], 6))\n",
    "        res[[i]] = plot_sharing(dat$U[[meta$U[i]]], to_cor = ${\"T\" if to_cor else \"F\"}, \n",
    "                                title=title, remove_names = ${\"TRUE\" if remove_label else \"FALSE\"})\n",
    "    }\n",
    "    unit = 4\n",
    "    n_col = 5\n",
    "    n_row = ceiling(n_comp / n_col)\n",
    "    pdf(${_output:r}, width = unit * n_col, height = unit * n_row)\n",
    "    do.call(gridExtra::grid.arrange, c(res, list(ncol = n_col, nrow = n_row, \n",
    "                                                 bottom = \"Data source: readRDS(${_input:br})${('$'+name) if name else ''}\")))\n",
    "    dev.off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.21.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
