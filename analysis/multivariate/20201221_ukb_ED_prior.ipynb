{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# UKB Blood Celles Data Drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Here is the analysis plan:\n",
    "\n",
    "1. For each data-set, take the strongest snp as the strong set\n",
    "2. Also select from each data-set 2 \"null\" snps.\n",
    "3. then try to run your estimate of Vhat to get Vhat first, and run Yunqi / Peter's ED\n",
    "\n",
    "In UKB bloodcells, we have about 600 regions with number of SNPs between 1000 and 5000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path('/project2/mstephens/yuxin/ukb-bloodcells')\n",
    "parameter: name = 'ukbbloodcells_prepare'\n",
    "parameter: mixture_components = ['flash', 'pca', 'canonical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project2/mstephens/gaow/mvarbvs/dsc/mnm_prototype/mnm_sumstats"
     ]
    }
   ],
   "source": [
    "%cd /project2/mstephens/yuxin/ukb-bloodcells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Get top SNP and random close to null SNP per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract data from summary stats\n",
    "[extract_effects_1]\n",
    "parameter: datadir = path\n",
    "parameter: seed = 999\n",
    "parameter: n_null = 2\n",
    "# Analysis units file. For RDS files it can be generated by `ls *.rds | sed 's/\\.rds//g' > analysis_units.txt`\n",
    "parameter: analysis_units = path\n",
    "# handle N = per_chunk data-set in one job\n",
    "parameter: per_chunk = 1000\n",
    "regions = [x.strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input: [f'{datadir}/{x[0]}.rds' for x in regions], group_by = per_chunk\n",
    "output: f\"{cwd}/{name}/cache/{name}_{_index+1}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    set.seed(${seed})\n",
    "    matxMax <- function(mtx) {\n",
    "      return(arrayInd(which.max(mtx), dim(mtx)))\n",
    "    }\n",
    "    remove_rownames = function(x) {\n",
    "        for (name in names(x)) rownames(x[[name]]) = NULL\n",
    "        return(x)\n",
    "    }\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$zhat[which(is.nan(x$bhat))] = 0\n",
    "      return(x)\n",
    "    }\n",
    "    extract_one_data = function(infile, n_null) {\n",
    "        # If cannot read the input for some reason then we just skip it, assuming we have other enough data-sets to use.\n",
    "        dat = tryCatch(readRDS(infile)$Z, error = function(e) return(NULL))\n",
    "        if (is.null(dat)) return(NULL)\n",
    "        dat = as.matrix(dat)\n",
    "        z = as.matrix(abs(dat))\n",
    "        max_idx = matxMax(z)\n",
    "        # strong effect samples\n",
    "        strong = list(zhat = dat[max_idx[1],,drop=F])\n",
    "        # null samples defined as |z| < 2\n",
    "        null.id = which(apply(abs(dat), 1, max) < 2)\n",
    "        if (length(null.id) == 0) {\n",
    "          warning(paste(\"Null data is empty for input file\", infile))\n",
    "          null = list()\n",
    "        } else {\n",
    "          null_idx = sample(null.id, min(n_null, length(null.id)), replace = F)\n",
    "          null = list(zhat = dat[null_idx,,drop=F])\n",
    "        }\n",
    "        dat = (list(null = remove_rownames(null), strong = remove_rownames(strong)))\n",
    "        dat$null = handle_nan_etc(dat$null)\n",
    "        dat$strong = handle_nan_etc(dat$strong)\n",
    "        return(dat)\n",
    "    }\n",
    "    reformat_data = function(dat) {\n",
    "        # make output consistent in format with \n",
    "        # https://github.com/stephenslab/gtexresults/blob/master/workflows/mashr_flashr_workflow.ipynb      \n",
    "        res = list(strong.z = dat$strong, null.z = dat$null)\n",
    "      return(res)\n",
    "    }\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else if (is.null(one_data)) {\n",
    "          return(res)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            if (is.null(one_data[[d]])) {\n",
    "              next\n",
    "            } else {\n",
    "                res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "            }\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    res = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      res = merge_data(res, reformat_data(extract_one_data(f, ${n_null})))\n",
    "    }\n",
    "    saveRDS(res, ${_output:r})\n",
    "\n",
    "[extract_effects_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{name}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\"\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    dat = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      dat = merge_data(dat, readRDS(f))\n",
    "    }\n",
    "    # compute null correlation matrix\n",
    "    dat$null.cor = cor(dat$null.z)\n",
    "    # compute empirical covariance XtX\n",
    "    dat$XtX = t(as.matrix(dat$strong.z)) %*% as.matrix(dat$strong.z) / nrow(dat$strong.z)\n",
    "    saveRDS(dat, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "m=/project2/mstephens/yuxin/ukb-bloodcells/zscores\n",
    "cd $m && ls *.rds | sed 's/\\.rds//g' > analysis_units.txt && cd -\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb extract_effects \\\n",
    "        --analysis-units $m/analysis_units.txt \\\n",
    "        --datadir $m --name `basename $m` &> extract_effects.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLASH mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[flash]\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.flash.rds\"\n",
    "task: trunk_workers = 1, walltime = '6h', trunk_size = 1, mem = '8G', cores = 2, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_flash(dat, factors=\"default\", remove_singleton=${\"TRUE\" if \"canonical\" in mixture_components else \"FALSE\"}, output_model=\"${_output:n}.model.rds\")\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "m=/project2/mstephens/yuxin/ukb-bloodcells/zscores\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb flash \\\n",
    "    --name `basename $m` -s build &> factor_analysis.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pca]\n",
    "parameter: npc = 3\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.pca.rds\"\n",
    "task: trunk_workers = 1, walltime = '2h', trunk_size = 1, mem = '8G', cores = 2, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_pca(dat, ${npc})\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "m=/project2/mstephens/yuxin/ukb-bloodcells/zscores\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb pca \\\n",
    "    --name `basename $m` -s build &> factor_analysis.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[canonical]\n",
    "input: f\"{cwd}/{name}.rds\"\n",
    "output: f\"{cwd}/{name}.canonical.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '8G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    dat = mashr::mash_set_data(readRDS(${_input:r})$strong.z)\n",
    "    res = mashr::cov_canonical(dat)\n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it:\n",
    "\n",
    "```\n",
    "m=/project2/mstephens/yuxin/ukb-bloodcells/zscores\n",
    "sos run /project2/mstephens/yuxin/mvarbvs/analysis/multivariate/20201221_ukb_ED_prior.ipynb canonical \\\n",
    "    --name `basename $m` -s build &> factor_analysis.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run extreme deconvolution using `udr` or `mashr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installed commit d6d4c0e\n",
    "[ud]\n",
    "# Method is `ed` or `teem`\n",
    "parameter: ud_method = \"ed\"\n",
    "# A list of models where we only update the scales and not the matrices\n",
    "# A typical choice is to estimate scales only for canonical components\n",
    "parameter: scale_only = []\n",
    "input: [f\"{cwd}/{name}.rds\"] + [f\"{cwd}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f'{cwd}/{name}.{ud_method}{\"_unconstrained\" if len(scale_only) == 0 else \"\"}.rds'\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '10G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    scale_only = c(${paths([\"%s/%s.%s.rds\" % (cwd, name, m) for m in scale_only]):r,})\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    U_scaled = list()\n",
    "    for (f in rds_files[2:length(rds_files)]) {\n",
    "        if (f %in% scale_only) {\n",
    "          U_scaled = c(U_scaled, readRDS(f))\n",
    "        } else {\n",
    "          U = c(U, readRDS(f))\n",
    "        }\n",
    "    }\n",
    "    # Fit mixture model using udr package\n",
    "    library(udr)\n",
    "    message(paste(\"Running ${ud_method.upper()} via udr package for\", length(U), \"mixture components\"))\n",
    "    f0 = ud_init(X = as.matrix(dat$strong.z), V = dat$null.cor, U_scaled = U_scaled, U_unconstrained = U, n_rank1=0)\n",
    "    res = ud_fit(f0, control = list(unconstrained.update = \"${ud_method}\", resid.update = 'none', scaled.update = \"em\", maxiter=5000, tol = 1e-06), verbose=TRUE)\n",
    "    # add back col and row names to U\n",
    "    # https://github.com/stephenslab/udr/issues/9\n",
    "    for (i in 1:length(res$U)) {\n",
    "        colnames(res$U[[i]]) = rownames(res$U[[i]]) = colnames(dat$strong.z)\n",
    "    }\n",
    "    saveRDS(list(U=res$U, w=res$w, loglik=res$loglik), ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ed]\n",
    "input: [f\"{cwd}/{name}.rds\"] + [f\"{cwd}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f\"{cwd}/{name}.ed_bovy.rds\"\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '10G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    for (f in rds_files[2:length(rds_files)]) U = c(U, readRDS(f))\n",
    "    # Fit mixture model using ED code by J. Bovy\n",
    "    mash_data = mashr::mash_set_data(dat$strong.z, V=dat$null.cor)\n",
    "    message(paste(\"Running ED via J. Bovy's code for\", length(U), \"mixture components\"))\n",
    "    res = mashr:::bovy_wrapper(mash_data, U, logfile=${_output:nr}, tol = 1e-06)\n",
    "    saveRDS(list(U=res$Ulist, w=res$pi, loglik=scan(\"${_output:n}_loglike.log\")), ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.21.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
