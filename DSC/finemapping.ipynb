{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finemapping benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods evaluated:\n",
    "\n",
    "- Variational methods:\n",
    "    - spike-slab, mixture normal, sum of single effects, m&m\n",
    "- Popular fine-mapping methods:\n",
    "    - DAP, FINEMAP, CAVIAR\n",
    "    \n",
    "[PAINTOR](https://github.com/gkichaev/PAINTOR_V3.0) is not included because [FINEMAP is recommanded over PAINTOR when used without annotation](https://github.com/gkichaev/PAINTOR_V3.0/issues/11#issuecomment-303135031)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mnm.dsc`\n",
    "\n",
    "Master DSC script.\n",
    "\n",
    "* `debug_mnm_2`: this shows increase on ELBO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"mnm.dsc\" target=\"_blank\">mnm.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to mnm.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f mnm.dsc\n",
    "#!/usr/bin/env dsc\n",
    "\n",
    "%include modules/setup\n",
    "%include modules/simulate\n",
    "%include modules/fit\n",
    "%include modules/evaluate\n",
    "\n",
    "DSC:\n",
    "  define:\n",
    "    get_data: full_data, lite_data, liter_data, two_effect\n",
    "    get_Y: original_Y\n",
    "    fit: (init_mnm * fit_mnm * plot_sse), \n",
    "        fit_susie, fit_varbvs, \n",
    "        (fit_finemap * plot_finemap), \n",
    "        (fit_dap * plot_dap)\n",
    "  run:\n",
    "    setup: liter_data * summarize_ld\n",
    "    benchmark: full_data * summarize_ld * get_Y * get_sumstats * fit\n",
    "    debug_mnm_1: lite_data * summarize_ld * get_Y * get_sumstats * init_mnm * fit_mnm_debug\n",
    "    debug_mnm_2: liter_data * summarize_ld * get_Y * get_sumstats * init_mnm * fit_mnm_debug   \n",
    "    caviar: lite_data * summarize_ld * get_Y * get_sumstats * (fit_caviar * plot_caviar)\n",
    "  output: benchmark\n",
    "  exec_path: modules\n",
    "  global:\n",
    "    data_file: ~/Documents/GTExV8/Thyroid.Lung.FMO2.filled.rds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `setup.dsc`\n",
    "\n",
    "Data generators. See `20171103_MNMASH_Data.ipynb` for GTEx multitissue data preparation, if more real data are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/setup.dsc\" target=\"_blank\">modules/setup.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/setup.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/setup.dsc\n",
    "\n",
    "# Modules to provide data\n",
    "# Real or simulated\n",
    "\n",
    "# Module output\n",
    "# =============\n",
    "# $data: full data\n",
    "# $sumstats: summary statistics\n",
    "\n",
    "full_data: R(data =readRDS(${data_file});\n",
    "            if (end>start) data$X = as.matrix(data$X[,start:end]);\n",
    "            r2 = cor(data$X);\n",
    "            saveRDS(r2 ^ 2 * sign(r2), ld_mat);\n",
    "            write.table(r2,ld_file,quote=F,col.names=F,row.names=F))\n",
    "  tag: full\n",
    "  start, end: (0, 0)\n",
    "  $data: data\n",
    "  $top_idx: raw(NULL)\n",
    "  $ld_file: file(ld)\n",
    "  $ld_mat: file(rds)\n",
    "        \n",
    "lite_data(full_data):\n",
    "  tag: 2k\n",
    "  start, end: (2500, 4500)\n",
    "             \n",
    "liter_data(full_data):\n",
    "  tag: 1k\n",
    "  start, end: (3000, 4000)           \n",
    "            \n",
    "two_effect(full_data):\n",
    "  tag: two\n",
    "  start, end: (3500, 3501)\n",
    "\n",
    "get_sumstats: regression.R + R(res = mm_regression(as.matrix(data$X), \n",
    "                                                   as.matrix(data$Y)))\n",
    "  @CONF: R_libs = abind\n",
    "  data: $data\n",
    "  $sumstats: res\n",
    "                                                   \n",
    "summarize_ld: lib_regression_simulator.py + \\\n",
    "                regression_simulator.py + \\\n",
    "                Python(res = summarize_LD(data['X'], ld_mat, ld_plot))\n",
    "  data: $data\n",
    "  ld_mat: $ld_mat\n",
    "  $ld_plot: file(png)\n",
    "  $top_idx: res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `simulate.dsc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/simulate.dsc\" target=\"_blank\">modules/simulate.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/simulate.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/simulate.dsc\n",
    "\n",
    "# base_sim:\n",
    "# - A base simulator of 2 independent multivariate effects\n",
    "# - using MultivariateMixture\n",
    "# original_Yï¼š\n",
    "# - do not simulate data, just use original\n",
    "\n",
    "base_sim: lib_regression_simulator.py + \\\n",
    "                regression_simulator.py + \\\n",
    "                Python(data = simulate_main(data, conf, conf['cache']))\n",
    "  @CONF: python_modules = (seaborn, matplotlib, pprint)\n",
    "  data: $data\n",
    "  top_idx: $top_idx\n",
    "  n_signal: 3\n",
    "  n_traits: 2\n",
    "  eff_mode: mash_low_het\n",
    "  residual_mode: identity\n",
    "  swap_eff: raw(True)\n",
    "  keep_ld: raw(True)\n",
    "  center_data: raw(True)\n",
    "  cache: file(sim)\n",
    "  tag: sim1\n",
    "  @ALIAS: conf = Dict(!data, !eff_mode)\n",
    "  $data: data\n",
    "  $V: np.cov(data['Y'], rowvar = False)\n",
    "  $N: data['Y'].shape[0]\n",
    "\n",
    "original_Y(base_sim):\n",
    "  eff_mode: original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit.dsc`\n",
    "\n",
    "Fine mapping methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit.dsc\" target=\"_blank\">modules/fit.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit.dsc\n",
    "# workhorse(s) for finemapping\n",
    "\n",
    "# Module input\n",
    "# ============\n",
    "# $data: full data; or\n",
    "# $sumstats: summary statistics; or / and\n",
    "# $ld: LD information\n",
    "\n",
    "# Module output\n",
    "# =============\n",
    "# $fitted: for diagnostics\n",
    "# $posterior: for inference\n",
    "\n",
    "init_mnm: init_mnm.R\n",
    "  # mashr comes from `dev` branch on github\n",
    "  @CONF: R_libs = mashr\n",
    "  V: $V\n",
    "  reg: $sumstats\n",
    "  # FIXME: these quantities are to be computed seperately and globally using mashr procedure\n",
    "  # See http://stephenslab.github.io/gtex-eqtls/analysis/20171002_MASH_V8.html\n",
    "  Sigma: empirical\n",
    "  (U, grid, p): (auto, (0.9,0.01,0.01,0.01,0.01,0.01,0.01,0.02,0.02), auto)\n",
    "  $model: model\n",
    "  $V: V\n",
    "\n",
    "fit_mnm_debug: regression.R + elbo_mnm.R + fit_mnm.R\n",
    "  @CONF: R_libs = mashr\n",
    "  maxL: 5\n",
    "  maxI: 20\n",
    "  get_elbo: raw(T)\n",
    "  data: $data\n",
    "  model: $model\n",
    "  V: $V\n",
    "  $fitted: fitted_track\n",
    "  $posterior: posterior\n",
    "\n",
    "fit_mnm(fit_mnm_debug):\n",
    "  maxI: 10\n",
    "  get_elbo: raw(F)\n",
    "\n",
    "fit_susie: fit_susie.R\n",
    "  # Prior variance of nonzero effects.\n",
    "  @CONF: R_libs = susieR@stephenslab/susieR\n",
    "  maxL: 5\n",
    "  maxI: 50\n",
    "  data: $data\n",
    "  $posterior: posterior\n",
    "  $fitted: fitted\n",
    "\n",
    "fit_varbvs(fit_susie): setup_varbvs.R + fit_varbvs.R\n",
    "  @CONF: R_libs = varbvs@pcarbo/varbvs/varbvs-R\n",
    "  sa: 1\n",
    "\n",
    "fit_caviar: fit_caviar.R + \\\n",
    "             R(posterior = finemap_mcaviar(sumstats[1,,]/sumstats[2,,], \n",
    "                                            ld, args, prefix=cache))\n",
    "  @CONF: R_libs = (dplyr, magrittr)\n",
    "  sumstats: $sumstats\n",
    "  ld: $ld_file\n",
    "  args: -c 1, -c 2\n",
    "  cache: file(CAVIAR)\n",
    "  $posterior: posterior\n",
    "\n",
    "fit_finemap(fit_caviar): fit_finemap.R + \\\n",
    "             R(posterior = finemap_mvar(sumstats[1,,]/sumstats[2,,], \n",
    "                                        ld, N, k,\n",
    "                                        args, prefix=cache))\n",
    "  N: $N\n",
    "  k: R(rep(1/5,5)), (0.6,0.25,0.1,0.05)\n",
    "  args: --regions 1 --prior-std 0.4 --n-causal-max 5\n",
    "  cache: file(FM)\n",
    "\n",
    "fit_dap: fit_dap.py + Python(posterior = dap_batch(data['X'], data['Y'], cache, args))\n",
    "  data: $data\n",
    "  args: -ld_control 0.25\n",
    "  cache: file(DAP)\n",
    "  $posterior: posterior\n",
    "\n",
    "# fit_dap_mv(fit_dap): fit_dap.py + Python(res = dap_mv())\n",
    "\n",
    "# fit_dap_ss(fit_dap): fit_dap.py + Python(res = dap_batch_ss())\n",
    "#   data: $sumstats\n",
    "\n",
    "# fit_dap_mv_ss(fit_dap): fit_dap.py + Python(res = dap_mv_ss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `evaluate.dsc`\n",
    "\n",
    "Methods evaluation / visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/evaluate.dsc\" target=\"_blank\">modules/evaluate.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/evaluate.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/evaluate.dsc\n",
    "# Modules to evaluate various methods\n",
    "# for finemapping-m\n",
    "\n",
    "# Module input\n",
    "# ============\n",
    "# $fit: see fit.dsc\n",
    "# $result: see fit.dsc\n",
    "\n",
    "# Module output\n",
    "# =============\n",
    "# ? an object or plot for diagnosis\n",
    "\n",
    "plot_finemap: plot_finemap.R\n",
    "  @CONF: R_libs = (dplyr, ggplot2, cowplot)\n",
    "  result: $posterior\n",
    "  top_rank: 10\n",
    "  $plot_file: file(pdf)\n",
    "\n",
    "plot_caviar(plot_finemap): plot_caviar.R\n",
    "plot_dap(plot_finemap): plot_dap.R\n",
    "\n",
    "plot_sse: lib_regression_simulator.py + \\\n",
    "            plot_sse.py + \\\n",
    "            Python(plot_sse(result['PosteriorMean'], data['true_coef'],\n",
    "                            result['in_CI'], ld_mat, plot_file))\n",
    "  @CONF: python_modules = seaborn\n",
    "  data: $data\n",
    "  result: $posterior\n",
    "  ld_mat: $ld_mat\n",
    "  $plot_file: file(SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workhorses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `regression.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/regression.R\" target=\"_blank\">modules/regression.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/regression.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/regression.R\n",
    "## Perform univariate regression for each column of Y on each column of X\n",
    "univariate_regression = function(X, y, Z=NULL, return_residue=FALSE) {\n",
    "  if (!is.null(Z)) {\n",
    "    y = .lm.fit(Z, y)$residuals\n",
    "  }\n",
    "  calc_stderr = function(X, residuals) {\n",
    "    # S = (X'X)^-1 \\Sigma\n",
    "    sqrt(diag(sum(residuals^2) / (nrow(X) - 2) * chol2inv(chol(t(X) %*% X))))\n",
    "  }\n",
    "  output = do.call(rbind,\n",
    "                   lapply(1:ncol(X), function(i) {\n",
    "                     g = .lm.fit(cbind(1, X[,i]), y)\n",
    "                     return(c(coef(g)[2], calc_stderr(cbind(1, X[,i]), g$residuals)[2]))\n",
    "                   })\n",
    "                   )\n",
    "  if (return_residue) {\n",
    "    return(list(betahat = output[,1], sebetahat = output[,2],\n",
    "                residuals = y))\n",
    "  } else {\n",
    "    return(list(betahat = output[,1], sebetahat = output[,2]))\n",
    "  }\n",
    "}\n",
    "\n",
    "library(abind)\n",
    "mm_regression = function(X, Y, Z=NULL) {\n",
    "  reg = lapply(seq_len(ncol(Y)), function (i) simplify2array(univariate_regression(X, Y[,i])))\n",
    "  reg = do.call(abind, c(reg, list(along=0)))\n",
    "  # return array: out[1,,] is betahat, out[2,,] is shat\n",
    "  return(aperm(reg, c(3,2,1)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `setup_varbvs.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/setup_varbvs.R\" target=\"_blank\">modules/setup_varbvs.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/setup_varbvs.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/setup_varbvs.R\n",
    "\n",
    "X <- data$X\n",
    "storage.mode(X) <- \"double\"\n",
    "n <- nrow(X)\n",
    "p <- ncol(X)\n",
    "X <- scale(X,center = TRUE,scale = FALSE)\n",
    "alpha0  <- runif(p)\n",
    "alpha0  <- alpha0/sum(alpha0)\n",
    "mu0     <- rnorm(p)\n",
    "pp      <- rep(maxL/p, p)\n",
    "logodds <- varbvs:::logit(pp)\n",
    "Y <- data$Y\n",
    "for (r in 1:ncol(Y)) {\n",
    "  Y[,r] <- Y[,r] - mean(Y[,r])\n",
    "}\n",
    "storage.mode(Y) <- \"double\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit_varbvs.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_varbvs.R\" target=\"_blank\">modules/fit_varbvs.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_varbvs.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_varbvs.R\n",
    "fitted <- list()\n",
    "for (r in 1:ncol(Y)) {\n",
    "  sigma <- var(Y[,r])\n",
    "  fitted[[r]] <- varbvs::varbvsnorm(X,Y[,r],sigma,sa,logodds,alpha0,mu0,update.order = 1:p,\n",
    "                                    update.sigma = FALSE,update.sa = FALSE,tol = 1e-6,\n",
    "                                    verbose = FALSE, maxiter=maxI)\n",
    "}\n",
    "\n",
    "post_mean <- do.call(cbind, lapply(1:length(fitted), function(i) fitted[[i]]$alpha * fitted[[i]]$mu))\n",
    "lfdr <- do.call(cbind, lapply(1:length(fitted), function(i) 1 - fitted[[i]]$alpha))\n",
    "posterior <- list(PosteriorMean=post_mean, lfdr=lfdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `init_mnm.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/init_mnm.R\" target=\"_blank\">modules/init_mnm.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/init_mnm.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/init_mnm.R\n",
    "# Initialize model data: priors and init values\n",
    "\n",
    "if (Sigma != 'empirical') {\n",
    "  # FIXME data$V has to be changed\n",
    "  V = diag(nrow(V))\n",
    "}\n",
    "mash_data = mashr::mash_set_data(reg[1,,], Shat = reg[2,,], V = as.matrix(V))\n",
    "if (U == 'auto') {\n",
    "  U = mashr::cov_canonical(mash_data)\n",
    "} else {\n",
    "  ## FIXME: add other methods to get U\n",
    "  U = mashr::cov_canonical(mash_data)\n",
    "}\n",
    "model = list()\n",
    "if (p == 'auto') {\n",
    "  model$fitted_g = mashr::mash(mash_data, Ulist=U, outputlevel=1, usepointmass=TRUE)$fitted_g\n",
    "} else {\n",
    "  ## FIXME: need to use pre-fitted pi on larger data from mash procedure\n",
    "  model$fitted_g = list(pi=p, Ulist=U, grid=grid, usepointmass=TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `elbo_mnm.R`\n",
    "\n",
    "Here we compute ELBO along the lines of the FLASH paper: justify that it is the multivariate normal-mean problem (MASH), then computer ELBO mostly using MASH updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/elbo_mnm.R\" target=\"_blank\">modules/elbo_mnm.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/elbo_mnm.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/elbo_mnm.R\n",
    "#' @title Residual covariance for a M&M fit\n",
    "#' B is J X R matrix of M&M output\n",
    "#' SM is J X R X R matrix of M&M output with 2nd moment option on\n",
    "#' XtX is just precomputed t(X) %*% X\n",
    "compute_mnm_residual_covariance = function(X, Y, XtX, B, SM) {\n",
    "    # out = t(Y) %*% Y - 2 * t(B) %*% t(X) %*% Y # + E[B^TX^TXB]\n",
    "    # E[B^TX^TXB] is not easy to compute properly\n",
    "    # use MLE for now\n",
    "    return(t(Y - X%*%B) %*% (Y - X%*%B) / nrow(X))\n",
    "} \n",
    "                                            \n",
    "#' @title expected loglikelihood for a M&M fit\n",
    "# https://gaow.github.io/mvarbvs/writeup/20171215_MNMModel_Finemap.html\n",
    "#' S is simply XtX pre-computed\n",
    "#' Sigma is current estimate of residual variance\n",
    "#' B is J X R matrix of M&M output\n",
    "#' SM is J X R X R matrix of M&M output with 2nd moment option on\n",
    "compute_mnm_Eloglik = function(X,Y,S,Sigma,B,SM){\n",
    "    inv_Sigma = solve(Sigma)\n",
    "    det_Sigma = det(Sigma)\n",
    "    N = nrow(Y)\n",
    "    R = ncol(Y)\n",
    "    t0 = vector()\n",
    "    for (j in 1:ncol(X)) {\n",
    "        t0[j] = S[j,j] * sum(inv_Sigma * SM[,,j])\n",
    "    }\n",
    "    t1 = sum(diag(inv_Sigma %*% t(B) %*% S %*% B)) + sum(t0) -\n",
    "            2 * sum(diag(Y %*% inv_Sigma %*% t(B) %*% t(X))) +\n",
    "            sum(diag(Y %*% inv_Sigma %*% t(Y)))\n",
    "    out = -0.5 * N * R * log(2 * pi) - 0.5 * N * log(det_Sigma) - 0.5 * t1\n",
    "    return(out)\n",
    "}\n",
    "\n",
    "#' @title posterior expected loglikelihood for a MASH problem\n",
    "## E[log(\\hat{B}|B, Shat)]\n",
    "## Need posterior mean and posterior second moment from MASH\n",
    "## do not use any computational trick here because this is \n",
    "## just for sanity check\n",
    "compute_mash_Eloglik = function(betahat, Shat, b, b2) {\n",
    "    inv_Shat = solve(Shat)\n",
    "    det_Shat = det(Shat)\n",
    "    res = nrow(b) * log(2*pi) + log(det_Shat) +\n",
    "            (t(betahat) %*% inv_Shat %*% betahat -\n",
    "            2 * t(betahat) %*% inv_Shat %*% b +\n",
    "            sum(diag(inv_Shat %*% b2)))\n",
    "    return(-0.5 * res)\n",
    "}\n",
    "\n",
    "#' @title sum of MASH posterior expected loglikelihood\n",
    "#' Bhat is J x R matrix of MASH input\n",
    "#' SDhat is J X R matrix to be expanded with V, turning into J X R X R\n",
    "#' V is R X R matrix of MASH input\n",
    "#' Sigma is residual variance\n",
    "#' alpah is a J vector of weights\n",
    "#' B is J X R matrix of MASH output\n",
    "#' SM is J X R X R matrix of MASH output with 2nd moment option on\n",
    "compute_sse_Eloglik = function(Bhat, SDhat, V, Sigma, alpha, B, SM) {\n",
    "    ## FIXME: I think it is wrong here because it is not single effect model\n",
    "    ## where J effects should NOT be factorized.\n",
    "    ## But otherwise isn't it a matrix normal density with both row and column covariances?\n",
    "    res = vector()\n",
    "    for (j in 1:nrow(Bhat)) {\n",
    "        ## Is R X R\n",
    "        Shat = SDhat[j,] * t(V * SDhat[j,]) # faster than diag(SDhat[j,]) %*% V %*% diag(SDhat[j,])\n",
    "        ## Is R X 1\n",
    "        B_j = B[j,] * alpha[j]\n",
    "        ## 2nd moment, R X R\n",
    "        B2_j = (B[j,] %*% t(B[j,]) + SM[,,j]) * alpha[j]\n",
    "        res[j] = compute_mash_Eloglik(Bhat[j,], Shat, B_j, B2_j)\n",
    "    }\n",
    "    return(sum(res))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit_mnm.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_mnm.R\" target=\"_blank\">modules/fit_mnm.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_mnm.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_mnm.R\n",
    "## M&M ash module core update\n",
    "mnm_update_model <- function(X, Y, V, fitted_g, fitted, get_kl = FALSE) {\n",
    "  ## \"fitted\" include p_alpha, alpha, mu and Xr\n",
    "  maxL = ncol(fitted$alpha)\n",
    "  for (l in 1:maxL) {\n",
    "    ## remove the lth effect\n",
    "    fitted$Xr <- fitted$Xr - X %*% (fitted$alpha[,l] * fitted$mu[[l]])\n",
    "    ## update mash model\n",
    "    reg <- mm_regression(X, Y - fitted$Xr)\n",
    "    mash_data <- mashr::mash_set_data(reg[1,,], Shat = reg[2,,], V = V)\n",
    "    mout <- mashr::mash(mash_data, g = fitted_g, fixg = TRUE, outputlevel=3)\n",
    "    ## update fitted values\n",
    "    fitted$mu[[l]] <- mout$result$PosteriorMean\n",
    "    fitted$s[[l]] <- mout$result$PosteriorCov\n",
    "    fitted$lfsr[[l]] <- mout$result$lfsr\n",
    "    fitted$neg[[l]] <- mout$result$NegativeProb\n",
    "    l10bf <- mashr::get_log10bf(mout)\n",
    "    ## FIXME: mashr issue 35\n",
    "    l10bf[is.infinite(l10bf)] <- range(l10bf, finite=TRUE)[2] * 100\n",
    "    alpha_post <- exp((l10bf - max(l10bf)) * log(10)) * fitted$p_alpha\n",
    "    fitted$alpha[,l] <- alpha_post / sum(alpha_post)\n",
    "    ## add back the updated lth effect\n",
    "    fitted$Xr <- fitted$Xr + X %*% (fitted$alpha[,l] * fitted$mu[[l]])\n",
    "    if (get_kl) {\n",
    "        # Justified by A.46 of FLASH paper\n",
    "        # Here KL is denoted as (13.28) of BDA 3\n",
    "        fitted$kl[l] <- -1 * mout$loglik + compute_sse_Eloglik(reg[1,,], reg[2,,], V,\n",
    "                                                               fitted$Sigma, \n",
    "                                                               fitted$alpha[,l],\n",
    "                                                               mout$result$PosteriorMean,\n",
    "                                                               mout$result$PosteriorCov)\n",
    "    }\n",
    "  }\n",
    "  return(fitted)\n",
    "}\n",
    "\n",
    "## Compute posterior mean and covariances\n",
    "mnm_compute_posterior_matrices = function(fitted, J, R, L) {\n",
    "    post_mean <- matrix(0, J, R)\n",
    "    for (l in 1:L) {\n",
    "      post_mean <- post_mean + fitted$mu[[l]] * fitted$alpha[,l]\n",
    "    }\n",
    "    post_cov <- array(0, dim=c(R, R, J))\n",
    "    for (j in 1:J) {\n",
    "      for (l in 1:L) {\n",
    "        post_cov[,,j] <- post_cov[,,j] + (fitted$mu[[l]][j,] %*% t(fitted$mu[[l]][j,]) + fitted$s[[l]][,,j]) * fitted$alpha[j,l]\n",
    "      }\n",
    "      post_cov[,,j] <- post_cov[,,j] - post_mean[j,] %*% t(post_mean[j,])\n",
    "    }\n",
    "    return(list(PosteriorMean = post_mean, PosteriorCov = post_cov))\n",
    "}\n",
    "\n",
    "## Initialize storage for results\n",
    "data$X <- as.matrix(data$X)\n",
    "data$Y <- as.matrix(data$Y)\n",
    "maxL <- min(maxL, ncol(data$X))\n",
    "p_alpha <- rep(1, ncol(data$X)) / ncol(data$X)\n",
    "alpha <- matrix(0, ncol(data$X), maxL)\n",
    "mu <- lapply(1:maxL, function(i) matrix(0, ncol(data$X), ncol(data$Y)))\n",
    "Xr <- matrix(0, nrow(data$Y), ncol(data$Y))\n",
    "fitted <- list(p_alpha=p_alpha, alpha=alpha, mu=mu, s=list(), Xr=Xr, kl=vector(), lfsr=list(), neg=list(), Sigma=V)\n",
    "fitted_track <- list()\n",
    "Vcorr <- cov2cor(V)\n",
    "## For ELBO\n",
    "XtX <- t(data$X) %*% data$X\n",
    "## Fit m&m model\n",
    "for (i in 1:maxI) {\n",
    "  fitted <- mnm_update_model(data$X, data$Y, Vcorr, model$fitted_g, fitted, get_elbo)\n",
    "  if (get_elbo) {\n",
    "      post_mat = mnm_compute_posterior_matrices(fitted, ncol(data$X), ncol(data$Y), maxL)\n",
    "      fitted$Sigma = compute_mnm_residual_covariance(data$X, data$Y, XtX,\n",
    "                                                     post_mat$PosteriorMean, \n",
    "                                                     post_mat$PosteriorCov)\n",
    "      fitted$post_loglik = compute_mnm_Eloglik(data$X, data$Y, \n",
    "                                          XtX, fitted$Sigma,\n",
    "                                          post_mat$PosteriorMean, \n",
    "                                          post_mat$PosteriorCov)\n",
    "      fitted$elbo = fitted$post_loglik - sum(fitted$kl)\n",
    "  }\n",
    "  fitted_track[[i]] <- fitted\n",
    "}\n",
    "\n",
    "post_mat = mnm_compute_posterior_matrices(fitted, ncol(data$X), ncol(data$Y), maxL)\n",
    "\n",
    "## Compute lfsr\n",
    "lfsr <- do.call(rbind, lapply(1:maxL, function(l) colSums(fitted$alpha[,l] * fitted$lfsr[[l]])))\n",
    "posterior <- list(PosteriorMean=post_mat$PosteriorMean,\n",
    "                  PosteriorCov=post_mat$PosteriorCov,\n",
    "                  alpha = fitted$alpha,\n",
    "                  lfsr=lfsr,\n",
    "                  n_in_CI=susieR:::n_in_CI(t(fitted$alpha)),\n",
    "                  in_CI=susieR:::in_CI(t(fitted$alpha))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `plot_sse.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "%save -f modules/plot_sse.py\n",
    "\n",
    "def plot_sse(coef, true_coef, in_set, ld, plot_prefix):\n",
    "    reg = RegressionData()\n",
    "    reg.set_xcorr(ld)\n",
    "    in_set = np.sum(np.array(in_set), axis = 0)\n",
    "    coef = np.array(coef)\n",
    "    if true_coef is not None:\n",
    "        true_coef = np.array(true_coef)\n",
    "    for j in range(coef.shape[1]):\n",
    "        plot_file = f'{plot_prefix}.{j+1}.pdf'\n",
    "        reg.plot_property_vector(coef[:,j], None,\n",
    "                                 xz_cutoff = (0, 0.8), out = plot_file,\n",
    "                                 conf = {'title': f'Response {j+1}', \n",
    "                                    'ylabel': 'effect size estimate', \n",
    "                                    'zlabel': 'In 95 CI set'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit_susie.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_susie.R\" target=\"_blank\">modules/fit_susie.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_susie.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_susie.R\n",
    "fitted <- list()\n",
    "for (r in 1:ncol(data$Y)) {\n",
    "  fitted[[r]] <- susieR::susie(data$X,data$Y[,r],L=maxL,max_iter=maxI)\n",
    "  fitted[[r]]$lfsr <- susieR:::lfsr_fromfit(fitted[[r]])\n",
    "  fitted[[r]]$n_in_CI <- susieR:::n_in_CI(fitted[[r]])\n",
    "  fitted[[r]]$in_CI <- susieR:::in_CI(fitted[[r]])\n",
    "}\n",
    "\n",
    "posterior <- list(PosteriorMean=do.call(cbind, lapply(1:length(fitted), function(i) susieR:::coef.susie(fitted[[i]]))),\n",
    "                  lfsr=do.call(cbind, lapply(1:length(fitted), function(i) fitted[[i]]$lfsr)),\n",
    "                  alpha=do.call(cbind, lapply(1:length(fitted), function(i) fitted[[i]]$alpha)),\n",
    "                  n_in_CI=do.call(cbind, lapply(1:length(fitted), function(i) fitted[[i]]$n_in_CI)),\n",
    "                  in_CI= do.call(cbind, lapply(1:length(fitted), function(i) fitted[[i]]$in_CI))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit_dap.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAP version 1 was published as Wen et al 2016 AJHG. Here William has polished the software `dap-g` with another manuscript that describes improved algorithm and working with summary statistics. This benchmark uses DAP version 2. Below is an example output that I parse and save.\n",
    "\n",
    "```\n",
    "Posterior expected model size: 0.500 (sd = 0.500)\n",
    "LogNC = -0.30685 ( Log10NC = -0.133 )\n",
    "Posterior inclusion probability\n",
    "\n",
    "((1))              7492 6.68581e-05       0.000 1\n",
    "((2))              7490 6.68581e-05       0.000 1\n",
    "((3))              7484 6.68581e-05       0.000 1\n",
    "((4))              7486 6.68581e-05       0.000 1\n",
    "((5))              7481 6.68581e-05       0.000 1\n",
    "((6))              7476 6.68581e-05       0.000 1\n",
    "((7))              7479 6.68581e-05       0.000 1\n",
    "((8))              7491 6.68046e-05       0.000 2\n",
    "((9))              7483 6.68046e-05       0.000 2\n",
    "((10))             7485 6.68046e-05       0.000 2\n",
    "((11))             7488 6.68046e-05       0.000 2\n",
    "((12))             7474 6.68046e-05       0.000 2\n",
    "((13))             7475 6.68046e-05       0.000 2\n",
    "((14))             7478 6.68046e-05       0.000 2\n",
    "((15))             7465 6.68046e-05       0.000 2\n",
    "((16))             7473 6.68046e-05       0.000 2\n",
    "((17))             7470 6.68046e-05       0.000 2\n",
    "((18))             7467 6.68046e-05       0.000 2\n",
    "((19))             7461 6.68046e-05       0.000 2\n",
    "((20))             7459 6.68046e-05       0.000 2\n",
    "((21))             7482 6.67422e-05       0.000 -1\n",
    "((22))             7489 6.67422e-05       0.000 -1\n",
    "((23))             7487 6.67422e-05       0.000 -1\n",
    "((24))             7477 6.67422e-05       0.000 -1\n",
    "((25))             7480 6.67422e-05       0.000 -1\n",
    "((26))             7463 6.67422e-05       0.000 -1\n",
    "...\n",
    "Independent association signal clusters\n",
    "\n",
    "     cluster         member_snp      cluster_pip      average_r2\n",
    "       {1}              7            4.680e-04          0.951                 0.951   0.037\n",
    "       {2}             13            8.685e-04          0.623                 0.037   0.623\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_dap.py\" target=\"_blank\">modules/fit_dap.py</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_dap.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_dap.py\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def dap_single(x, y, prefix, r, args):\n",
    "    names = np.array([('geno', i+1, str(r)) for i in range(x.shape[1])])\n",
    "    with open(f'{prefix}.data', 'w') as f:\n",
    "        print(*(['pheno', 'pheno', str(r)] + list(y.ravel())), file=f)\n",
    "        np.savetxt(f, np.hstack((names, x.T)), fmt = '%s', delimiter = ' ')\n",
    "    grid = '''         \n",
    "        0.0000  0.1000\n",
    "        0.0000  0.2000\n",
    "        0.0000  0.4000\n",
    "        0.0000  0.8000\n",
    "        0.0000  1.6000\n",
    "        '''\n",
    "    grid = '\\n'.join([x.strip() for x in grid.strip().split('\\n')])\n",
    "    with open(f'{prefix}.grid', 'w') as f:\n",
    "        print(grid, file=f)\n",
    "    cmd = ['dap-g', '-d', f'{prefix}.data', '-g', f'{prefix}.grid', '-o', f'{prefix}.result', '--all'] + ' '.join(args).split()\n",
    "    subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n",
    "    out = [x.strip().split() for x in open(f'{prefix}.result').readlines()]\n",
    "    pips = []\n",
    "    clusters = []\n",
    "    still_pip = True\n",
    "    for line in out:\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        if len(line) > 2 and line[2] == 'cluster_pip':\n",
    "            still_pip = False\n",
    "            continue\n",
    "        if still_pip and (not line[0].startswith('((') or int(line[-1]) < 0):\n",
    "            continue\n",
    "        if still_pip:\n",
    "            pips.append([line[1], float(line[2]), float(line[3]), int(line[4])])\n",
    "        else:\n",
    "            clusters.append([len(clusters) + 1, float(line[2]), float(line[3])])\n",
    "    pips = pd.DataFrame(pips, columns = ['snp', 'snp_prob', 'snp_log10bf', 'cluster'])\n",
    "    clusters = pd.DataFrame(clusters, columns = ['cluster', 'cluster_prob', 'cluster_avg_r2'])\n",
    "    clusters = pd.merge(clusters, pips.groupby(['cluster'])['snp'].apply(','.join).reset_index(), on = 'cluster')\n",
    "    return {'snp': pips, 'set': clusters}\n",
    "\n",
    "def dap_batch(X, Y, prefix, *args):\n",
    "    return dict([(r, dap_single(X, Y[:,r], f'{prefix}_condition_{r+1}', r+1, args)) for r in range(Y.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit_finemap.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_finemap.R\" target=\"_blank\">modules/fit_finemap.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_finemap.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_finemap.R\n",
    "#' FINEMAP I/O\n",
    "write_finemap_sumstats <- function(z, LD_file, n, k, prefix) {\n",
    "  cfg = list(z=paste0(prefix,\".z\"),\n",
    "             ld=LD_file,\n",
    "             snp=paste0(prefix,\".snp\"),\n",
    "             config=paste0(prefix,\".config\"),\n",
    "             k=paste0(prefix,\".k\"),\n",
    "             log=paste0(prefix,\".log\"),\n",
    "             meta=paste0(prefix,\".master\"))\n",
    "  write.table(z,cfg$z,quote=F,col.names=F)\n",
    "  write.table(t(k),cfg$k,quote=F,col.names=F,row.names=F)\n",
    "  write(\"z;ld;snp;config;k;log;n-ind\",file=cfg$meta)\n",
    "  write(paste(cfg$z, cfg$ld, cfg$snp, cfg$config, cfg$k, cfg$log, n, sep=\";\"),\n",
    "        file=cfg$meta,append=TRUE)\n",
    "  return(cfg)\n",
    "}\n",
    "\n",
    "#' Run FINEMAP.\n",
    "#' http://www.christianbenner.com\n",
    "## FIXME: read the finemapr implementation for data sanity check.\n",
    "## Can be useful as a general data sanity checker (in previous modules)\n",
    "\n",
    "run_finemap <- function(z, LD_file, n, k, args = \"\", prefix=\"data\")\n",
    "{\n",
    "  cfg = write_finemap_sumstats(z, LD_file, n, k, prefix)\n",
    "  cmd = paste(\"finemap --sss --log\", \"--in-files\", cfg$meta, args)\n",
    "  dscrutils::run_cmd(cmd)\n",
    "\n",
    "  # read output tables\n",
    "  snp = read.table(cfg$snp,header=TRUE,sep=\" \")\n",
    "  snp$snp = as.character(snp$snp)\n",
    "\n",
    "  snp = rank_snp(snp)\n",
    "  config = read.table(cfg$config,header=TRUE,sep=\" \")\n",
    "\n",
    "  # extract number of causal\n",
    "  ncausal = finemap_extract_ncausal(cfg$log)\n",
    "  return(list(snp=snp, set=config, ncausal=ncausal))\n",
    "}\n",
    "\n",
    "rank_snp <- function(snp) {\n",
    "  snp <- arrange(snp, -snp_prob) %>%\n",
    "    mutate(\n",
    "        rank = seq(1, n()),\n",
    "        snp_prob_cumsum = cumsum(snp_prob) / sum(snp_prob)) %>%\n",
    "    select(rank, snp, snp_prob, snp_prob_cumsum, snp_log10bf)\n",
    "  return(snp)    \n",
    "}\n",
    "\n",
    "finemap_extract_ncausal <- function(logfile)\n",
    "{\n",
    "  lines <- grep(\"->\", readLines(logfile), value = TRUE)\n",
    "  lines <- gsub(\"\\\\(|\\\\)|>\", \"\", lines)\n",
    "  splits <- strsplit(lines, \"\\\\s+\")\n",
    "  tab <- data.frame(\n",
    "    ncausal_num = sapply(splits, function(x) as.integer(x[2])),\n",
    "    ncausal_prob = sapply(splits, function(x) as.double(x[4])))\n",
    "  tab <- mutate(tab, type = ifelse(duplicated(ncausal_num), \"post\", \"prior\"))\n",
    "  return(tab)\n",
    "}\n",
    "\n",
    "finemap_mvar <- function(zscore, LD_file, n, k, args, prefix) {\n",
    "  return(parallel::mclapply(1:ncol(zscore), function(r) \n",
    "          run_finemap(zscore[,r], LD_file, n, k, args, \n",
    "                      paste0(prefix, '_condition_', r)),\n",
    "                            mc.cores = min(8, ncol(zscore))))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit_caviar.R`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CAVIAR` output file (`*_post`): \n",
    "- column #1 is the variant name;\n",
    "- column #2 is the [posterior prob. that the variant is causal](https://github.com/fhormoz/caviar/issues/1#issuecomment-286521771);\n",
    "- column #3 is the amount that this variant contributes to 95%-causal credible set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_caviar.R\" target=\"_blank\">modules/fit_caviar.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_caviar.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_caviar.R\n",
    "#' CAVIAR I/O\n",
    "write_caviar_sumstats <- function(z, prefix) {\n",
    "  cfg = list(z=paste0(prefix,\".z\"),\n",
    "             set=paste0(prefix,\"_set\"),\n",
    "             post=paste0(prefix,\"_post\"),\n",
    "             log=paste0(prefix,\".log\"))\n",
    "  write.table(z,cfg$z,quote=F,col.names=F)\n",
    "  return(cfg)\n",
    "}\n",
    "\n",
    "#' Run CAVIAR\n",
    "#' https://github.com/fhormoz/caviar\n",
    "\n",
    "run_caviar <- function(z, LD_file, args = \"\", prefix=\"data\")\n",
    "{\n",
    "  cfg = write_caviar_sumstats(z, prefix)\n",
    "  cmd = paste(\"CAVIAR\", \"-z\", cfg$z, \"-l\", LD_file, \"-o\", prefix, args)\n",
    "  dscrutils::run_cmd(cmd)\n",
    "  if(!all(file.exists(cfg$post, cfg$set, cfg$log))) {\n",
    "      stop(\"Cannot find one of the post, set, and log files\")\n",
    "  }\n",
    "  \n",
    "  log <- readLines(cfg$log)\n",
    "\n",
    "  # read output tables\n",
    "  snp <- read.delim(cfg$post)  \n",
    "  stopifnot(ncol(snp) == 3)\n",
    "  names(snp) <- c(\"snp\", \"snp_prob_set\", \"snp_prob\")\n",
    "  snp$snp <- as.character(snp$snp)\n",
    "  snp <- rank_snp(snp)\n",
    "\n",
    "  # `set` of snps\n",
    "  set <- readLines(cfg$set)\n",
    "  set_ordered <- left_join(data_frame(snp = set), snp, by = \"snp\") %>% \n",
    "    arrange(rank) %$% snp\n",
    "  return(list(snp=snp, set=set_ordered))\n",
    "}\n",
    "\n",
    "rank_snp <- function(snp) {\n",
    "  snp <- arrange(snp, -snp_prob) %>%\n",
    "    mutate(\n",
    "        rank = seq(1, n()),\n",
    "        snp_prob_cumsum = cumsum(snp_prob) / sum(snp_prob)) %>%\n",
    "    select(rank, snp, snp_prob, snp_prob_cumsum, snp_prob_set)\n",
    "  return(snp)    \n",
    "}\n",
    "\n",
    "finemap_mcaviar <- function(zscore, LD_file, args, prefix) {\n",
    "  return(parallel::mclapply(1:ncol(zscore), function(r)\n",
    "          run_caviar(zscore[,r], LD_file, args, \n",
    "                     paste0(prefix, '_condition_', r)), \n",
    "                            mc.cores = min(8, ncol(zscore))))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `plot_finemap.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_finemap.R\" target=\"_blank\">modules/plot_finemap.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_finemap.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_finemap.R\n",
    "\n",
    "plot_finemap <- function(x,\n",
    "                         grid_nrow = NULL, \n",
    "                         grid_ncol = NULL, \n",
    "                         label_size = 2,\n",
    "                         top_rank = 5,\n",
    "                         lim_prob = c(0, 1.2),\n",
    "                         ...)\n",
    "{\n",
    "  label_size_config = label_size\n",
    "  label_size_snp = label_size\n",
    "  top_rank_config = top_rank\n",
    "  top_rank_snp = top_rank\n",
    "  lim_prob_config = lim_prob\n",
    "  lim_prob_snp = lim_prob\n",
    "  lim_prob_ncausal = lim_prob   \n",
    "    \n",
    "  p1 <- plot_ncausal(x, \n",
    "    lim_prob = lim_prob_ncausal, ...)\n",
    "  p2 <- plot_set(x,  \n",
    "    top_rank = top_rank_config, \n",
    "    label_size = label_size_config, \n",
    "    lim_prob = lim_prob_config, ...)\n",
    "  p3 <- plot_snp(x, \n",
    "    top_rank = top_rank_snp,\n",
    "    label_size = label_size_snp, \n",
    "    lim_prob = lim_prob_snp, ...)\n",
    "  \n",
    "  plot_grid(p1, p2, p3,  labels = \"AUTO\", nrow = grid_nrow, ncol = grid_ncol)\n",
    "}\n",
    "\n",
    "\n",
    "plot_ncausal <- function(x, lim_prob, ...)\n",
    "{\n",
    "  ptab <- x$ncausal\n",
    "  \n",
    "  sum_prop_zero <- filter(ptab, ncausal_num == 0)[[\"prob\"]]  %>% sum\n",
    "  if(sum_prop_zero == 0) {\n",
    "    ptab <- filter(ptab, ncausal_num != 0)\n",
    "  }\n",
    "  \n",
    "  ptab <- mutate(ptab, \n",
    "    ncausal_num = factor(ncausal_num, levels = sort(unique(ncausal_num), \n",
    "                                                    decreasing = TRUE)),\n",
    "    type = factor(type, levels = c(\"prior\", \"post\")))\n",
    "    \n",
    "  p <- ggplot(ptab, aes(ncausal_num, ncausal_prob, fill = type)) + \n",
    "    geom_hline(yintercept = 1, linetype = 3) + \n",
    "    geom_bar(stat = \"identity\", position = \"dodge\") + \n",
    "    coord_flip() + theme(legend.position = \"top\") + \n",
    "    scale_fill_manual(values = c(\"grey50\", \"orange\")) +\n",
    "    ylim(lim_prob)\n",
    "    \n",
    "  return(p)\n",
    "}\n",
    "\n",
    "plot_set <- function(x, lim_prob, label_size, top_rank, ...)\n",
    "{\n",
    "  ptab <- x$set\n",
    "\n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    label = paste0(config, \"\\n\", \n",
    "      \"P = \", round(config_prob, 2),\n",
    "      \"; \", \"log10(BF) = \", round(config_log10bf, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(config_prob, rank)) + \n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = config_prob, yend = rank, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(top_rank + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "\n",
    "plot_snp <- function(x, lim_prob, label_size, top_rank, ...)\n",
    "{\n",
    "  ptab <- x$snp\n",
    "  \n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    rank = seq(1, n()), \n",
    "    label = paste0(snp, \"\\n\", \n",
    "      \"P = \", round(snp_prob, 2),\n",
    "      \"; \", \"log10(BF) = \", round(snp_log10bf, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(snp_prob, rank)) +\n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = snp_prob, yend = rank, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(top_rank + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "pdf(plot_file)\n",
    "for (r in 1:length(result)) {\n",
    "    print(plot_finemap(result[[r]], top_rank = top_rank))\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `plot_caviar.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_caviar.R\" target=\"_blank\">modules/plot_caviar.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_caviar.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_caviar.R\n",
    "plot_caviar <- function(x,\n",
    "                        grid_nrow = NULL, \n",
    "                        grid_ncol = NULL, \n",
    "                        label_size = 2,\n",
    "                        top_rank = 5,\n",
    "                        lim_prob = c(0, 1.5),\n",
    "                        ...)\n",
    "{\n",
    "  plot_snp(x, label_size, top_rank, lim_prob, ...)\n",
    "}\n",
    "\n",
    "plot_snp <- function(x, label_size, top_rank, lim_prob, ...)\n",
    "{\n",
    "  ptab <- x$snp\n",
    "\n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    label = paste0(snp, \"\\n\", \n",
    "      \"P = \", round(snp_prob, 2),\n",
    "      \"; \", \"P(set) = \", round(snp_prob_set, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(snp_prob, rank)) +\n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = snp_prob, yend = rank, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(top_rank + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "pdf(plot_file)\n",
    "for (r in 1:length(result)) {\n",
    "    print(plot_caviar(result[[r]], top_rank = top_rank))\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `plot_dap.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_dap.R\" target=\"_blank\">modules/plot_dap.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_dap.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_dap.R\n",
    "\n",
    "\n",
    "plot_dap <- function(x,\n",
    "                     grid_nrow = 2, \n",
    "                     grid_ncol = 1, \n",
    "                     label_size = 2,\n",
    "                     top_rank = 5,\n",
    "                     lim_prob = c(0, 1.2),\n",
    "                     ...)\n",
    "{\n",
    "  label_size_config = label_size\n",
    "  label_size_snp = label_size\n",
    "  top_rank_config = top_rank\n",
    "  top_rank_snp = top_rank\n",
    "  lim_prob_config = lim_prob\n",
    "  lim_prob_snp = lim_prob\n",
    "    \n",
    "  p2 <- plot_set(x,  \n",
    "    top_rank = top_rank_config, \n",
    "    label_size = label_size_config, \n",
    "    lim_prob = lim_prob_config, ...)\n",
    "  p3 <- plot_snp(x, \n",
    "    top_rank = top_rank_snp,\n",
    "    label_size = label_size_snp, \n",
    "    lim_prob = lim_prob_snp, ...)\n",
    "  \n",
    "  plot_grid(p2, p3,  labels = \"AUTO\", nrow = grid_nrow, ncol = grid_ncol)\n",
    "}\n",
    "\n",
    "\n",
    "plot_set <- function(x, lim_prob, label_size, top_rank, ...)\n",
    "{\n",
    "  ptab <- x$set\n",
    "\n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    label = paste0(snp, \"\\n\", \n",
    "      \"P = \", round(cluster_prob, 2),\n",
    "      \"; \", \"avg(r^2) = \", round(cluster_avg_r2, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(cluster_prob, cluster)) + \n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = cluster_prob, yend = cluster, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(min(top_rank, nrow(ptab)) + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "\n",
    "plot_snp <- function(x, lim_prob, label_size, top_rank, ...)\n",
    "{\n",
    "  ptab <- x$snp\n",
    "  \n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    rank = seq(1, n()), \n",
    "    label = paste0(snp, \"\\n\", \n",
    "      \"P = \", round(snp_prob, 2),\n",
    "      \"; \", \"log10(BF) = \", round(snp_log10bf, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(snp_prob, rank)) +\n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = snp_prob, yend = rank, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(top_rank + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "pdf(plot_file)\n",
    "for (r in 1:length(result)) {\n",
    "    print(plot_dap(result[[r]], top_rank = top_rank))\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation under regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lib_regression_simulator.py`\n",
    "\n",
    "- `RegressionData`: Stores multivariate $Y$ and multiple feature $X$ data.\n",
    "- `UnivariateMixture`: Simulating univariate effects with mixture distribution of effects: $\\beta$ are sampled from normal mixtures as described in Stephens 2017 the ASH paper.\n",
    "- `MultivariateMixture`: Multivariate mixture of Urbut 2017 the MASH paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/lib_regression_simulator.py\" target=\"_blank\">modules/lib_regression_simulator.py</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/lib_regression_simulator.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/lib_regression_simulator.py\n",
    "import numpy as np\n",
    "import os, copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pprint import pformat\n",
    "from collections import OrderedDict\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        try:\n",
    "            return self[item]\n",
    "        except KeyError:\n",
    "            raise AttributeError(item)\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        return dotdict(copy.deepcopy(dict(self)))\n",
    "    \n",
    "class RegressionData(dotdict):\n",
    "    def __init__(self, X = None, Y = None, Z = None):\n",
    "        # FIXME: check if inputs are indeed numpy arrays\n",
    "        self.debug = dotdict()\n",
    "        self.x_centered = self.y_centered = self.z_centered = False\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.Z = None\n",
    "        self.xcorr = None\n",
    "\n",
    "    def get_summary_stats(self):\n",
    "        '''\n",
    "        Computer univariate regression for every X_j (N by 1) and Y_r (N by 1)\n",
    "        Bhat: J by R matrix of estimated effects\n",
    "        Shat: J by R matrix of SE of Bhat\n",
    "        '''\n",
    "        if self.Z is not None:\n",
    "            self.remove_covariates()\n",
    "        # Compute betahat\n",
    "        XtX_vec = np.einsum('ji,ji->i', self.X, self.X)\n",
    "        self.Bhat = (self.X.T @ self.Y) / XtX_vec[:,np.newaxis]\n",
    "        # Compute se(betahat)\n",
    "        Xr = self.Y - np.einsum('ij,jk->jik', self.X, self.B)\n",
    "        Re = np.einsum('ijk,ijk->ik', Xr, Xr)\n",
    "        self.Shat = np.sqrt(Re / XtX_vec[:,np.newaxis] / (self.X.shape[0] - 2))\n",
    "\n",
    "    def remove_covariates(self):\n",
    "        if self.Z is not None:\n",
    "            self.Y -= self.Z @ (np.linalg.inv(self.Z.T @ self.Z) @ self.Z.T @ self.Y)\n",
    "            self.Z = None\n",
    "\n",
    "    def center_data(self):\n",
    "        # for np.array: np.mean(Z, axis=0, keepdims=True)\n",
    "        # for np.matrix, no keepdims argument\n",
    "        if self.X is not None and not self.x_centered:\n",
    "            self.X -= np.mean(self.X, axis=0)\n",
    "            self.x_centered = True\n",
    "        if self.Y is not None and not self.y_centered:\n",
    "            self.Y -= np.mean(self.Y, axis=0)\n",
    "            self.y_centered = True\n",
    "        if self.Z is not None and not self.z_centered:\n",
    "            self.Z -= np.mean(self.Z, axis=0)\n",
    "            self.z_centered = True\n",
    "\n",
    "    def set_xcorr(self, xcorr):\n",
    "        if xcorr is not None:\n",
    "            self.xcorr = np.array(xcorr)\n",
    "        else:\n",
    "            self.xcorr = np.corrcoef(self.X, rowvar = False)\n",
    "            self.xcorr = (np.square(self.xcorr) * np.sign(self.xcorr)).astype(np.float16)\n",
    "\n",
    "    def plot_xcorr(self, out, limit = 5000):\n",
    "        use_abs = np.sum(self.xcorr < 0) == 0\n",
    "        fig, ax = plt.subplots()\n",
    "        limit = min(self.xcorr.shape[0], limit)\n",
    "        if out.endswith('pdf'):\n",
    "            raise ValueError('Please use png extension for output file.')\n",
    "        print(f'Plotting figure {out} for {limit} markers (default limit set to 5000) ...')\n",
    "        cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=1, dark=0, as_cmap=True)\n",
    "        sns.heatmap(self.xcorr[1:limit,1:limit], ax = ax, cmap = cmap, vmin=-1 if not use_abs else 0,\n",
    "                    vmax=1, square=True, xticklabels = False, yticklabels = False)\n",
    "        ax = plt.gca()\n",
    "        print(f'Saving figure {out} ...')        \n",
    "        plt.savefig(out, dpi = 500)\n",
    "        \n",
    "    def permute_X_columns(self):\n",
    "        '''\n",
    "        Permute X columns, i.e. break blocked correlation structure\n",
    "        '''\n",
    "        np.random.shuffle(self.X) \n",
    "        \n",
    "    def plot_property_vector(self, yaxis, zaxis, xz_cutoff = None, out = '/tmp/1.pdf',\n",
    "                            conf = {'title': '', 'ylabel': '', 'zlabel': ''}):\n",
    "        '''\n",
    "        - yaxis can be eg $\\beta$ or log10BF or -log10Prob\n",
    "        - zaxis can be some other quantity whose value will be \n",
    "        reflected by color shade\n",
    "        - xz_cutoff: (c1, c2). c1 is correlation cutoff to highlight\n",
    "        when c2 is satisfied by a given position on x-axis\n",
    "        '''\n",
    "        xaxis = [x+1 for x in range(len(yaxis))]\n",
    "        cmap = sns.cubehelix_palette(start=2.8, rot=.1, as_cmap=True)\n",
    "        f, ax = plt.subplots(figsize=(18,5))\n",
    "        if zaxis is not None:\n",
    "            points = ax.scatter(xaxis, yaxis, c=zaxis, cmap=cmap)\n",
    "            f.colorbar(points, label=conf['zlabel'])\n",
    "        else:\n",
    "            points = ax.scatter(xaxis, yaxis, cmap=cmap)\n",
    "        if xz_cutoff is not None and zaxis is not None:\n",
    "            c1, c2 = xz_cutoff\n",
    "            if len([i for i in zaxis if i > c2]) > 100:\n",
    "                print('Too many to highlight!')\n",
    "            else:\n",
    "                for idx, item in enumerate(zaxis):\n",
    "                    if item > c2:\n",
    "                        ax.scatter(xaxis[idx], yaxis[idx], s=80, \n",
    "                                   facecolors='none', edgecolors='r')\n",
    "                        for ii, xx in enumerate(self.xcorr[idx,:]):\n",
    "                            if xx > c1 and xx < 1.0:\n",
    "                                ax.scatter(xaxis[ii], yaxis[ii], \n",
    "                                           color='y', marker='+')\n",
    "        ax.set_title(conf['title'])\n",
    "        ax.set_ylabel(conf['ylabel'])\n",
    "        plt.gca()\n",
    "        plt.savefig(out, dpi = 500)\n",
    "        \n",
    "    def get_representative_features(self, block_r2 = 0.8, block_size = 10, max_indep_r2 = 0.02):\n",
    "        '''\n",
    "        Based on xcorr matrix, select \"most representative features\". \n",
    "        That is, these features are potentially most convoluted by other features (have stronger xcorr)\n",
    "        yet are independent among each other.\n",
    "        - block_r2: definition of correlated block -- abs squared correlation have to be > cutoff1\n",
    "        - block_size: define a large enough block -- block size have to be > block_size\n",
    "        - max_indep_r2: now select features that are completely independent -- r2 < max_indep_r2\n",
    "        '''\n",
    "        if self.xcorr is None:\n",
    "            self.set_xcorr(None)\n",
    "        # get r2 summary\n",
    "        r2 = pd.DataFrame(self.xcorr)\n",
    "        strong_r2_count = ((np.absolute(r2) > block_r2) * r2).sum(axis = 0).sort_values(ascending = False)\n",
    "        strong_r2_count = strong_r2_count[strong_r2_count > block_size]\n",
    "        # filter by r2\n",
    "        exclude = []\n",
    "        for x in strong_r2_count.index:\n",
    "            if x in exclude:\n",
    "                continue\n",
    "            for y in strong_r2_count.index:\n",
    "                if y in exclude or y == x:\n",
    "                    continue\n",
    "                if np.absolute(r2[x][y]) > max_indep_r2:\n",
    "                    exclude.append(y)\n",
    "        return [x for x in strong_r2_count.index if not x in exclude]\n",
    "\n",
    "    def __str__(self):\n",
    "        return pformat(self.__dict__, indent = 4)\n",
    "    \n",
    "class ResidualVariance:\n",
    "    def __init__(self, mode):\n",
    "        self.mode = mode\n",
    "        \n",
    "    def apply(self, eff_obj):\n",
    "        if self.mode == 'identity':\n",
    "            return np.identity(eff_obj.R)\n",
    "    \n",
    "class UnivariateMixture:\n",
    "    '''Simulated distributions of Stephens 2017 (ASH paper)'''\n",
    "    def __init__(self, dim):\n",
    "        self.size = dim\n",
    "        self.pi0 = 0\n",
    "        self.pis = []\n",
    "        self.mus = []\n",
    "        self.sigmas = []\n",
    "        self.coef = []\n",
    "        \n",
    "    def set_pi0(self, pi0):\n",
    "        self.pi0 = pi0\n",
    "        \n",
    "    def set_spiky(self):\n",
    "        self.pis = [0.4,0.2,0.2,0.2]\n",
    "        self.mus = [0,0,0,0]\n",
    "        self.sigmas = [0.25,0.5,1,2]\n",
    "    \n",
    "    def set_near_normal(self):\n",
    "        self.pis = [2/3,1/3]\n",
    "        self.mus = [0,0]\n",
    "        self.sigmas = [1,2]\n",
    "        \n",
    "    def set_flat_top(self):\n",
    "        self.pis = [1/7] * 7\n",
    "        self.mus = [-1.5, -1, -.5 , 0, .5, 1, 1.5]\n",
    "        self.sigmas = [0.5] * 7\n",
    "        \n",
    "    def set_skew(self):\n",
    "        self.pis = [1/4,1/4,1/3,1/6]\n",
    "        self.mus = [-2,-1,0,1]\n",
    "        self.sigmas = [2,1.5,1,1]\n",
    "        \n",
    "    def set_big_normal(self):\n",
    "        self.pis = [1]\n",
    "        self.mus = [0]\n",
    "        self.sigmas = [4]\n",
    "\n",
    "    def set_bimodal(self):\n",
    "        self.pis = [0.5, 0.5]\n",
    "        self.mus = [-2, 2]\n",
    "        self.sigmas = [1, 1]\n",
    "        \n",
    "    def get_effects(self):\n",
    "        '''\n",
    "        beta ~ \\pi_0\\delta_0 + \\sum \\pi_i N(mu_i, sigma_i)\n",
    "        '''\n",
    "        sigmas = np.diag(self.sigmas)\n",
    "        assert (len(self.pis), len(self.pis)) == sigmas.shape\n",
    "        masks = np.random.multinomial(1, self.pis, size = self.size)\n",
    "        mix = np.random.multivariate_normal(self.mus, sigmas, self.size)\n",
    "        self.coef = np.sum(mix * masks, axis = 1) * np.random.binomial(1, 1 - self.pi0, self.size)\n",
    "        \n",
    "    def swap_top_effects(self, given_index):\n",
    "        '''Set top effects to given indices\n",
    "        One can specify index, or use the \"top_index\"\n",
    "        generated by RegressionData.get_representative_features()\n",
    "        '''\n",
    "        given_index = np.array(given_index, dtype=int)\n",
    "        nb = np.zeros(len(self.coef))\n",
    "        beta = sorted(self.coef, key=abs, reverse=True)\n",
    "        for idx in given_infex:\n",
    "            nb[idx] = beta.pop(0)\n",
    "        random.shuffle(beta)\n",
    "        for idx in range(len(nb)):\n",
    "            if not idx in given_index:\n",
    "                nb[idx] = beta.pop(0)\n",
    "        assert len(beta) == 0\n",
    "        self.coef = np.array(nb)\n",
    "        \n",
    "    def sparsify_effects(self, num_non_zero):\n",
    "        '''\n",
    "        only keep top `num_non_zero` effects\n",
    "        '''\n",
    "        nb = np.zeros(len(self.coef))\n",
    "        big_beta_index = [i[0] for i in sorted(enumerate(self.coef), key = lambda x: np.absolute(x[1]), reverse = True)]\n",
    "        selected_index = big_beta_index[:min(len(big_beta_index), num_non_zero)]\n",
    "        for j in self.size:\n",
    "            if j not in selected_index:\n",
    "                self.coef[j] = 0\n",
    "                \n",
    "    def get_y(self, regression_data, sigma):\n",
    "        y = np.dot(regression_data.X, self.coef.T) + np.random.normal(0, sigma, regression_data.X.shape[0])\n",
    "        y.reshape(len(y), 1)\n",
    "        return y\n",
    "        \n",
    "    def __str__(self):\n",
    "        params = ' + '.join([\"{} N({}, {}^2)\".format(x,y,z) for x, y, z in zip(self.pis, self.mus, self.sigmas)])\n",
    "        return '{:.3f} \\delta_0 + {:.3f} [{}]'.format(self.pi0, 1 - self.pi0, params)\n",
    "    \n",
    "class MultivariateMixture:\n",
    "    '''FIXME: ideally implement Urbut 2017 simulated covs'''\n",
    "    def __init__(self, dim):\n",
    "        self.J, self.R = dim\n",
    "        self.pis = OrderedDict([('null', 0)])\n",
    "        self.Us = OrderedDict([('null', np.zeros((self.R, self.R)))])\n",
    "        self.mus = dict([('zeros', np.zeros(self.R))])\n",
    "        self.coef = []\n",
    "        self.grid = [0.1,0.5,1,2]\n",
    "        self._init_canonical()\n",
    "\n",
    "    def set_pi0(self, pi0):\n",
    "        self.pis['null'] = pi0\n",
    "        \n",
    "    def set_grid(self, grid):\n",
    "        self.grid = grid\n",
    "        \n",
    "    def _init_canonical(self):\n",
    "        '''\n",
    "        U is a dict of \n",
    "        - \"identity\" for the identity (effects are independent among conditions);\n",
    "        - \"singletons\" for the set of matrices with just one non-zero entry x_{jj} = 1 (j=1,...,R); (effect specific to condition j);\n",
    "        - \"equal_effects\" for the matrix of all 1s (effects are equal among conditions);\n",
    "        - \"simple_het\" for a set of matrices with 1s on the diagonal and all off-diagonal elements equal to pho; (effects are correlated among conditions).\n",
    "        '''\n",
    "        pho = [0.25, 0.5, 0.75]\n",
    "        self.Us['identity'] = np.identity(self.R)\n",
    "        for i in range(self.R):\n",
    "            self.Us[f'singleton_{i+1}'] = np.diagflat([1 if idx == i else 0 for idx in range(self.R)])\n",
    "        self.Us['equal_effects'] = np.ones((self.R, self.R))\n",
    "        for idx, item in enumerate(sorted(pho)):\n",
    "            self.Us[f'simple_het_{idx+1}'] = np.ones((self.R, self.R)) * item\n",
    "            np.fill_diagonal(self.Us[f'simple_het_{idx+1}'], 1)\n",
    "            \n",
    "    def set_shared(self):\n",
    "        '''\n",
    "        All weights are on equal effects\n",
    "        '''\n",
    "        self.pis['equal_effects'] = 1 - self.pis['null']\n",
    "        for k in self.Us:\n",
    "            if k not in self.pis:\n",
    "                self.pis[k] = 0\n",
    "                \n",
    "    def set_low_het(self):\n",
    "        '''\n",
    "        All weights are on small het effects\n",
    "        '''\n",
    "        self.pis['simple_het_1'] = 1 - self.pis['null']\n",
    "        for k in self.Us:\n",
    "            if k not in self.pis:\n",
    "                self.pis[k] = 0\n",
    "                \n",
    "    def set_indep(self):\n",
    "        '''\n",
    "        All weights are on identity effects\n",
    "        '''\n",
    "        self.pis['identity'] = 1 - self.pis['null']\n",
    "        for k in self.Us:\n",
    "            if k not in self.pis:\n",
    "                self.pis[k] = 0\n",
    "\n",
    "    def set_singleton(self, index):\n",
    "        '''\n",
    "        All weights evenly set to given index of singleton effects\n",
    "        '''\n",
    "        index = [int(x) for x in index if x <= self.R and x > 1]\n",
    "        weight = (1 - self.pis['null']) / len(index)\n",
    "        for item in index:\n",
    "            self.pis[f'singleton_{item}'] = weight\n",
    "        for k in self.Us:\n",
    "            if k not in self.pis:\n",
    "                self.pis[k] = 0        \n",
    "        \n",
    "    def apply_grid(self):\n",
    "        def product(x,y):\n",
    "            for item in y:\n",
    "                yield x*item\n",
    "        self.Us = dict(sum([[(f\"{p}_{i+1}\", g) for i, g in enumerate(product(self.Us[p], np.square(self.grid)))] for p in self.Us if p != 'null'], []) + \\\n",
    "                      [('null', self.Us['null'])])\n",
    "        nG = len(self.grid)\n",
    "        for k in list(self.pis.keys()):\n",
    "            if k == 'null':\n",
    "                continue\n",
    "            for g in range(nG):\n",
    "                self.pis[f'{k}_{g+1}'] = self.pis[k] / nG\n",
    "            del self.pis[k]\n",
    "            \n",
    "    def get_effects(self):\n",
    "        '''\n",
    "        Generate B under multivariate normal mixture\n",
    "        beta ~ \\pi_0\\delta_0 + \\sum \\pi_i N(0, U_i)\n",
    "        '''\n",
    "        self.coef = np.zeros((self.J, self.R))\n",
    "        for j in range(self.J):\n",
    "            # sample distribution\n",
    "            dist_index = np.random.multinomial(1, list(self.pis.values()), size = 1).tolist()[0].index(1)\n",
    "            name = list(self.pis.keys())[dist_index]\n",
    "            self.coef[j,:] = np.random.multivariate_normal(self.mus['zeros'], self.Us[name], 1)\n",
    "        \n",
    "    def sparsify_effects(self, num_non_zero):\n",
    "        '''\n",
    "        only keep top `num_non_zero` effects\n",
    "        '''\n",
    "        beta_max = np.amax(np.absolute(self.coef), axis = 1)\n",
    "        big_beta_index = [i[0] for i in sorted(enumerate(beta_max), key = lambda x: x[1], reverse = True)]\n",
    "        selected_index = big_beta_index[:min(len(big_beta_index), num_non_zero)]\n",
    "        for j in range(self.J):\n",
    "            if j not in selected_index:\n",
    "                self.coef[j,:] = self.mus['zeros']\n",
    "                \n",
    "    def swap_top_effects(self, given_index):\n",
    "        '''Set top effects to given indices\n",
    "        One can specify index, or use the \"top_index\"\n",
    "        generated by RegressionData.get_representative_features()\n",
    "        '''\n",
    "        given_index = np.array(given_index, dtype=int)\n",
    "        nb = np.zeros(self.coef.shape)\n",
    "        beta_max = np.amax(np.absolute(self.coef), axis = 1)\n",
    "        big_beta_index = [i[0] for i in sorted(enumerate(beta_max), key = lambda x: x[1], reverse = True)]\n",
    "        for idx in given_index:\n",
    "            nb[idx,:] = self.coef[big_beta_index.pop(0),:]\n",
    "        for idx in range(nb.shape[0]):\n",
    "            if not idx in given_index:\n",
    "                nb[idx,:] = self.coef[big_beta_index.pop(0),:]\n",
    "        self.coef = nb\n",
    "        \n",
    "    def get_y(self, regression_data, sigma_mat):\n",
    "        return regression_data.X @ self.coef + np.random.multivariate_normal(np.zeros(self.R), sigma_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `regression_simulator.py`\n",
    "\n",
    "Simulator workhorses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/regression_simulator.py\" target=\"_blank\">modules/regression_simulator.py</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/regression_simulator.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/regression_simulator.py\n",
    "def summarize_LD(X, ld_input, ld_plot):\n",
    "    data = RegressionData()\n",
    "    data.X = X\n",
    "    data.set_xcorr(ld_input)\n",
    "    data.plot_xcorr(ld_plot)\n",
    "    return data.get_representative_features()\n",
    "\n",
    "def simulate_main(data, c, plot_prefix):\n",
    "    '''\n",
    "    data: $data\n",
    "    top_idx: $top_eff\n",
    "    n_signal: 3\n",
    "    n_traits: 2\n",
    "    eff_mode: mash_low_het\n",
    "    swap_eff: raw(True)\n",
    "    keep_ld: raw(True)\n",
    "    tag: sim1\n",
    "    @ALIAS: conf = Dict(!data, !eff_mode)\n",
    "    $data: data\n",
    "    '''\n",
    "    reg = RegressionData()\n",
    "    reg.X = data['X']\n",
    "    if c['swap_eff'] and c['top_idx'] is None:\n",
    "        raise ValueError(f'\"top_idx\" variable is not set by an upstream module')\n",
    "    if eff_mode == 'mash_low_het':\n",
    "        if c['n_traits'] < 2:\n",
    "            raise ValueError(f'Cannot simulate {c[\"n_traits\"]} under mode {eff_mode}')\n",
    "        data['true_coef'] = mash_low_het(data, reg, c)\n",
    "    elif eff_mode == 'original':\n",
    "        data['true_coef'] = original_y(data, reg, c)\n",
    "    else:\n",
    "        raise ValueError(f'Mode {eff_mode} is not implemented.')\n",
    "    if c['center_data']:\n",
    "        reg.center_data()\n",
    "    data['X'] = reg.X\n",
    "    data['Y'] = reg.Y\n",
    "    if data['true_coef'] is not None:\n",
    "        for j in range(data['true_coef'].shape[1]):\n",
    "            plot_file = f'{plot_prefix}.{j+1}.pdf'\n",
    "            reg.plot_property_vector(data['true_coef'][:,j], \n",
    "                                 [np.absolute(x)>0 for x in data['true_coef'][:,j]], \n",
    "                                 xz_cutoff = None, out = plot_file,\n",
    "                                conf = {'title': f'Response {j+1}', \n",
    "                                        'ylabel': 'effect size', 'zlabel': ''})\n",
    "    return data\n",
    "        \n",
    "def original_y(data, reg, c):\n",
    "    reg.Y = np.vstack(data['Y'].values()).T\n",
    "    return None\n",
    "    \n",
    "def mash_low_het(data, reg, c):\n",
    "    if not c['keep_ld']:\n",
    "        reg.permuate_X_columns()\n",
    "        data['X'] = reg.X\n",
    "    eff = MultivariateMixture((data['X'].shape[1], c['n_traits']))\n",
    "    eff.set_low_het()\n",
    "    eff.apply_grid()\n",
    "    eff.get_effects()\n",
    "    if c['swap_eff']:\n",
    "        eff.swap_top_effects(c['top_idx'])\n",
    "    eff.sparsify_effects(c['n_signal'])\n",
    "    reg.Y = eff.get_y(reg, ResidualVariance(c['residual_mode']).apply(eff))\n",
    "    return eff.coef"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFE771"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.9.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
