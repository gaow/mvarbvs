{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype of VEM in M&M ASH model\n",
    "This is the VEM step of M&M ASH model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\bs}[1]{\\boldsymbol{#1}}$\n",
    "$\\DeclareMathOperator*{\\diag}{diag}$\n",
    "$\\DeclareMathOperator*{\\cov}{cov}$\n",
    "$\\DeclareMathOperator*{\\rank}{rank}$\n",
    "$\\DeclareMathOperator*{\\var}{var}$\n",
    "$\\DeclareMathOperator*{\\tr}{tr}$\n",
    "$\\DeclareMathOperator*{\\veco}{vec}$\n",
    "$\\DeclareMathOperator*{\\uniform}{\\mathcal{U}niform}$\n",
    "$\\DeclareMathOperator*{\\argmin}{arg\\ min}$\n",
    "$\\DeclareMathOperator*{\\argmax}{arg\\ max}$\n",
    "$\\DeclareMathOperator*{\\N}{N}$\n",
    "$\\DeclareMathOperator*{\\gm}{Gamma}$\n",
    "$\\DeclareMathOperator*{\\dif}{d}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M&M ASH model\n",
    "\n",
    "We assume the following multivariate, multiple regression model with $N$ samples, $J$ effects and $R$ conditions (and **without covariates, for the time being**)\n",
    "\\begin{align}\n",
    "\\bs{Y}_{N\\times R} = \\bs{X}_{N \\times J}\\bs{B}_{J \\times R} + \\bs{E}_{N \\times R},\n",
    "\\end{align}\n",
    "where\n",
    "\\begin{align}\n",
    "\\bs{E} &\\sim \\N_{N \\times R}(\\bs{0}, \\bs{I}_N, \\bs{\\Lambda}^{-1}),\\\\\n",
    "\\bs{\\Lambda} &= \\diag(\\lambda_1,\\ldots,\\lambda_R).\n",
    "\\end{align}\n",
    "\n",
    "We assume true effects $\\bs{b}_j$ (rows of $\\bs{B}$) are iid with prior distribution of mixtures of multivariate normals\n",
    "\n",
    "$$p(\\bs{b}_j) = \\sum_{t = 0}^T\\pi_t\\N_R(\\bs{b}_j | \\bs{0}, \\bs{V}_t),$$\n",
    "\n",
    "Where the $\\bs{V}_t$'s are $R \\times R$ covariance matrices and the $\\pi_t$'s are their weights.\n",
    "\n",
    "We place Gamma prior on $\\bs{\\Lambda}$\n",
    "\n",
    "$$\\lambda_r \\overset{iid}{\\sim} \\gm(\\alpha, \\beta),$$\n",
    "\n",
    "and set $\\alpha = \\beta = 0$ so that it is equivalent to estimating $\\bs{\\Lambda}$ via maximum likelihood.\n",
    "\n",
    "We can augment the prior of $\\bs{b}_j$ by indicator vector $\\bs{\\gamma}_j \\in \\mathbb{R}^T$ for membership of $\\bs{b}_j$ into one of the $T$ mixture groups. The densities involved are\n",
    "\n",
    "\\begin{align}\n",
    "p(\\bs{Y},\\bs{B},\\bs{\\Gamma},\\bs{\\Lambda}) &= p(\\bs{Y}|\\bs{B}, \\bs{\\Lambda})p(\\bs{B}|\\bs{\\Gamma})p(\\bs{\\Gamma})p(\\bs{\\Lambda}), \\\\\n",
    "p(\\bs{Y}|\\bs{B}, \\bs{\\Lambda}) &= N_{N \\times R}(\\bs{X}\\bs{B}, \\bs{I}_N, \\bs{\\Lambda}^{-1}), \\\\\n",
    "p(\\lambda_r|\\alpha,\\beta) &= \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\lambda_r^{\\alpha - 1}\\exp\\{-\\beta\\lambda_r\\}, \\\\\n",
    "p(\\bs{b}_j|\\bs{\\gamma}_j) &= \\prod_{t = 0}^T\\left[\\N(\\bs{b}_j|\\bs{0},\\bs{V}_t)\\right]^{\\gamma_{jt}},\\\\\n",
    "p(\\bs{\\gamma}_j) &= \\prod_{t = 0}^{T} \\pi_t^{\\gamma_{jt}}.\n",
    "\\end{align}\n",
    "\n",
    "**We assume $V_t$'s and their corresponding $\\pi_t$'s are known. In practice we use `mashr` to estimate these quantities and provide them to M&M.**\n",
    "\n",
    "### Variational approximation to densities\n",
    "\n",
    "For the posterior of $\\bs{B}$ we seek an independent variational approximation based on\n",
    "\n",
    "\\begin{align}\n",
    "q(\\bs{B}, \\bs{\\Gamma}, \\bs{\\Lambda}) = q(\\bs{\\Lambda})\\prod_{j = 1}^{J}q(\\bs{b}_j,\\bs{\\gamma}_j),\n",
    "\\end{align}\n",
    "\n",
    "so that we can maximize over $q$ the following lower bound of the marginal log-likelihood\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(\\bs{Y}) \\geq \\mathcal{L}(q) = \\int q(\\bs{B}, \\bs{\\Gamma}, \\bs{\\Lambda}) \\log\\left\\{\\frac{p(\\bs{Y},\\bs{B},\\bs{\\Gamma},\\bs{\\Lambda})}{q(\\bs{B}, \\bs{\\Gamma}, \\bs{\\Lambda})}\\right\\}\\dif\\bs{B}\\dif\\bs{\\Gamma}\\dif\\bs{\\Lambda},\n",
    "\\end{align}\n",
    "\n",
    "Gao & Wei have previously developed [a version that assumes $\\Lambda = I_R$](https://github.com/gaow/mvarbvs/blob/master/writeup/identity_cov/mnmash.pdf). This version generalized it to a diagonal matrix with Gamma priors. [David has developed a version](https://www.overleaf.com/11985539jvwgjhrqnrry#/45465793/) that assumes a diagonal plus low rank structure -- the model of that version is a bit different from shown here, and will be prototyped later after this version works.\n",
    "\n",
    "### Core updates\n",
    "\n",
    "The complete derivation of updates are documented elsewhere (in the two PDF write-ups whose links are shown above). Here I document core updates to guide implementation of the algorithm.\n",
    "\n",
    "Let $E[\\bs{R}_{-j}] := \\bs{Y} - \\bs{X}\\bs{\\mu}_{\\bs{B}} + \\bs{x}_j\\bs{\\mu}_{\\bs{B}[j, ]}^{\\intercal}$, then\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\bs{\\xi}_j &= E\\left[\\bs{R}_{-j}\\right]^{\\intercal}\\bs{x}_j\\|\\bs{x}_j\\|^{-2}, \\\\\n",
    "\\bs{\\Sigma}_{jt} &= \\left(\\bs{V}_t^{-1} + \\|\\bs{x}_j\\|^2\\bs{\\Lambda}\\right)^{-1}, \\\\\n",
    "\\bs{\\mu}_{jt} &= \\bs{\\Sigma}_{jt}\\bs{\\Lambda}E\\left[\\bs{R}_{-k}\\right]^{\\intercal}\\bs{x}_j, \\\\\n",
    "\\gamma_{jt} &= \\frac{\\pi_t\\N(\\bs{\\xi}_j|\\bs{0}, \\bs{V}_t + \\bs{\\Lambda}^{-1}\\|\\bs{x}_j\\|^{-2})}{\\sum_{t = 0}^T\\pi_t\\N(\\bs{\\xi}_j|\\bs{0}, \\bs{V}_t + \\bs{\\Lambda}^{-1}\\|\\bs{x}_j\\|^{-2})},\\\\\n",
    "\\bs{\\mu}_{\\bs{B}[j, ]}  &= \\sum_{t = 0}^T \\gamma_{jt}\\bs{\\mu}_{jt}\n",
    "\\end{align}\n",
    "\n",
    "We update until the lower bound $\\mathcal{L}(q)$ converges.\n",
    "\n",
    "## Initialization\n",
    "\n",
    "* We fit `mashr` with effects learned from univariate analysis to obtain $\\pi_t$ and $V_t$\n",
    "  * For the first round the effects are \"LD-polluted\"\n",
    "* Use multivariate LASSO to get the ordering of $X$ for input. Similar approach has been previousely used with `varbvs`.\n",
    "* We \"stack\" expression data under multiple conditions and impute missing data with mean imputation or `softImpute` for a completed $Y$ matrix.\n",
    "  * This version of the model does not impute missing data in $Y$ in its variational updates although this will be added in next version.\n",
    "* We regress out covariates beforehand\n",
    "  * Same approach taken by Guan & Stephens 2011 yet not Carbonetto & Stephens 2012\n",
    "  * In next version we will preprocess covariates by \"stacking\" them together and perform a low-rank decomposition / imputation. For example for 50 tissues there will be a blocked matrix with a total of over 1000 PEER factors when stacked together, with non-random missing data. We will perform a low rank approximation to hopefully only keep < 50 PEER. We will then control for covariates in the M&M model.\n",
    "  \n",
    "**In this notebook we use a test data set of 2 tissues: Thyroid and Lung. As a first pass we also fix $V_t$ as one identity matrix, and $\\pi_t$ to 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "R",
    "scrolled": true,
    "tags": [
     "report_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 2\n",
      " $ Y:'data.frame':\t698 obs. of  2 variables:\n",
      "  ..$ Thyroid: num [1:698] 0.163 0.436 -0.212 0.327 -0.698 ...\n",
      "  ..$ Lung   : num [1:698] 0.77011 0.77799 -0.65361 0.00672 -0.36792 ...\n",
      " $ X: num [1:698, 1:7492] 1 0 0 0 0 1 1 0 1 1 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : chr [1:698] \"GTEX-111CU\" \"GTEX-111FC\" \"GTEX-111VG\" \"GTEX-111YS\" ...\n",
      "  .. ..$ : chr [1:7492] \"chr1_170185243_G_A_b38\" \"chr1_170185272_T_C_b38\" \"chr1_170185405_C_A_b38\" \"chr1_170185417_G_A_b38\" ...\n"
     ]
    }
   ],
   "source": [
    "dat = readRDS('/home/gaow/Documents/GTExV8/Thyroid.Lung.FMO2.filled.rds')\n",
    "str(dat)\n",
    "attach(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: feather\n"
     ]
    }
   ],
   "source": [
    "%get X Y --from R\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "Y = Y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16348104,  0.77010917],\n",
       "       [ 0.43588995,  0.77798736],\n",
       "       [-0.21237311, -0.65361193],\n",
       "       ..., \n",
       "       [ 0.62036618, -0.0035004 ],\n",
       "       [ 0.00279156, -0.05439095],\n",
       "       [-0.14650835,  0.29935286]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate LASSO \n",
    "For initialization of effects. Here I use implementation via `sklearn`. It is quite slow to compute a proper LASSO path, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "model = linear_model.Lasso()\n",
    "reg_path = model.path(X, Y, l1_ratio = 1, n_alphas = 20, eps = 1E-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(model.coef_[0], model.coef_[1], cmap=\"viridis\")\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "max(model.coef_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MASH priors and weights\n",
    "As initialization we take univariate analysis summary statistics $\\hat{\\bs{B}}$ and $\\bs{S}$ for fitting with `mashr`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VEM implementation\n",
    "It is not working yet. Still trying to figure out what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell",
     "report_output"
    ]
   },
   "outputs": [],
   "source": [
    "class MNMASH:\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y        \n",
    "        self.B = np.zeros((X.shape[1], Y.shape[1]))\n",
    "        # self.V = np.ones((2, Y.shape[1], Y.shape[1]))\n",
    "        self.V = np.array([np.identity(2)]) * 1\n",
    "        self.pi = np.random.uniform(0,1,self.V.shape[0])\n",
    "        self.pi = self.pi / sum(self.pi)\n",
    "        self.Lambda = np.identity(Y.shape[1])\n",
    "        self.tol = 1E-4\n",
    "        self.debug = 1\n",
    "        self.maxiter = 1\n",
    "        # initialize intermediate variables\n",
    "        self.R = np.ones((self.X.shape[1], self.Y.shape[0], self.Y.shape[1])) * np.nan\n",
    "        self.E = np.ones((self.Y.shape[1], self.X.shape[1])) * np.nan\n",
    "        self.Rx = np.ones((self.Y.shape[1], self.X.shape[1])) * np.nan\n",
    "        self.wdE = np.ones((self.X.shape[1], self.V.shape[0])) * np.nan\n",
    "        self.Sigma = {tt: np.ones((self.X.shape[1], self.Y.shape[1], self.Y.shape[1])) * np.nan for tt in range(self.V.shape[0])}\n",
    "        self.Mu = np.ones((self.X.shape[1], self.Y.shape[1], self.V.shape[0])) * np.nan\n",
    "        self.gamma = np.ones((self.X.shape[1], self.V.shape[0])) * np.nan\n",
    "        # X is N by K matrix, X_norm is 1 by K vector of L2 norm of column k's\n",
    "        self.X_norm = np.linalg.norm(self.X, ord = 2, axis = 0)\n",
    "        if self.debug:\n",
    "            self.X_std = self.X / self.X_norm\n",
    "            np.testing.assert_array_almost_equal(np.sum(np.square(self.X_std), axis = 0), np.ones(self.X.shape[1]))\n",
    "        self.X_norm = np.square(self.X_norm)\n",
    "        self.X_std = self.X / self.X_norm\n",
    "        self.R_all = None\n",
    "        self.H = None\n",
    "        self.Delta = None\n",
    "        self.update_lambda = True\n",
    "\n",
    "    def update(self):\n",
    "        '''\n",
    "        Core update\n",
    "        '''\n",
    "        iLambda = np.linalg.inv(self.Lambda)\n",
    "        # B is M by K matrix\n",
    "        self.R_all = self.Y - self.X @ self.B\n",
    "        # K is number of effects\n",
    "        for kk in range(self.X.shape[1]):\n",
    "            # R[kk] is N x M, where M is number of conditions\n",
    "            self.R[kk,:,:] = self.R_all + np.outer(self.X[:,kk], (self.B[kk,:].T))\n",
    "            # E[kk] is M x 1\n",
    "            self.E[:,kk] = (self.R[kk,:,:].T @ self.X_std[:,kk]).ravel()\n",
    "            # Rx[kk] is M x 1\n",
    "            self.Rx[:,kk] = (self.R[kk,:,:].T @ self.X[:,kk]).ravel()\n",
    "            for tt in range(self.V.shape[0]):\n",
    "                self.wdE[kk,tt] = multivariate_normal.pdf(self.E[:,kk], np.zeros(self.Y.shape[1]), \\\n",
    "                                                          self.V[tt] + iLambda / self.X_norm[kk]) * self.pi[tt]\n",
    "            wdE_sum = sum(self.wdE[kk,:])\n",
    "            for tt in range(self.V.shape[0]):\n",
    "                # Can be made faster via low-rank approximation\n",
    "                self.Sigma[tt][kk,:,:] = np.linalg.inv(np.identity(self.Y.shape[1]) + self.V[tt] * self.X_norm[kk] @ self.Lambda) @ self.V[tt]\n",
    "                self.Mu[kk,:,tt] = self.Sigma[tt][kk,:,:] @ self.Lambda @ self.Rx[:,kk]\n",
    "                self.gamma[kk,tt] = self.wdE[kk,tt] / wdE_sum\n",
    "                #if self.gamma[kk,tt] != self.gamma[kk,tt]:\n",
    "                #    self.gamma[kk,tt] = 0\n",
    "            # dot product for weighted sums\n",
    "            self.B[kk,:] = self.Mu[kk,:,:] @ self.gamma[kk,:]\n",
    "        if self.update_lambda:\n",
    "            # Recalculate h, a M by M matrix\n",
    "            self.H = np.diag(np.sum([np.sum([self.gamma[kk,tt] * ((self.Mu[kk,:,tt] - self.B[kk,:]) ** 2 + np.diag(self.Sigma[tt][kk,:,:])) for tt in range(self.V.shape[0])], axis = 0) for kk in range(self.X.shape[1])], axis = 0))\n",
    "            # Update Lambda\n",
    "            self.Delta = np.diag(self.R_all.T @ self.R_all) + self.H\n",
    "            self.Lambda = np.diag(self.X.shape[0] / np.diag(self.Delta))\n",
    "\n",
    "    def vem(self):\n",
    "        '''\n",
    "        Variational EM\n",
    "        '''\n",
    "        cnt = 0\n",
    "        while cnt < self.maxiter:\n",
    "            self.update()\n",
    "            cnt += 1\n",
    "\n",
    "    def summary(self):\n",
    "        self.prt('E')\n",
    "        self.prt('Rx')\n",
    "        self.prt('R')\n",
    "        self.prt('wdE')\n",
    "        self.prt('Mu')\n",
    "        self.prt('gamma')\n",
    "        self.prt('Lambda')\n",
    "        self.prt('B')\n",
    "        self.prt('H')\n",
    "        self.prt('Delta')\n",
    "        print('Sigma[0][0] @ R[0].T @ X[:,0] = \\n{}\\n'.format(self.Sigma[0][0] @ self.R[0].T @ self.X[:,0]))\n",
    "        print('X @ B = \\n{}\\n'.format(self.X @ self.B))\n",
    "        print('Y - X @ B = \\n{}\\n'.format(self.Y - self.X @ self.B))\n",
    "\n",
    "\n",
    "    def prt(self, variable):\n",
    "        print(variable, '=', repr(eval(f'self.{variable}')))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "res = MNMASH(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking core updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "First iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "res.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "kernel": "Python3",
    "scrolled": false,
    "tags": [
     "report_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E = array([[-0.02094472, -0.06122512, -0.04164898, ...,  0.0372279 ,\n",
      "        -0.00669449,  0.04083855],\n",
      "       [-0.02124238, -0.05018941, -0.06105233, ..., -0.00273088,\n",
      "         0.01641117,  0.00058457]])\n",
      "\n",
      "\n",
      "Rx = array([[-5.37396148, -3.67350731, -4.12385519, ...,  3.61241949,\n",
      "        -3.382703  ,  4.00364293],\n",
      "       [-5.45033424, -3.01136475, -6.04506932, ..., -0.26499216,\n",
      "         8.29251397,  0.05730889]])\n",
      "\n",
      "\n",
      "R = array([[[ 0.16348104,  0.77010917],\n",
      "        [ 0.43588995,  0.77798736],\n",
      "        [-0.21237311, -0.65361193],\n",
      "        ..., \n",
      "        [ 0.62036618, -0.0035004 ],\n",
      "        [ 0.00279156, -0.05439095],\n",
      "        [-0.14650835,  0.29935286]],\n",
      "\n",
      "       [[ 0.16348104,  0.77010917],\n",
      "        [ 0.43588995,  0.77798736],\n",
      "        [-0.21237311, -0.65361193],\n",
      "        ..., \n",
      "        [ 0.62036618, -0.0035004 ],\n",
      "        [ 0.00279156, -0.05439095],\n",
      "        [-0.14650835,  0.29935286]],\n",
      "\n",
      "       [[ 0.16348104,  0.77010917],\n",
      "        [ 0.43588995,  0.77798736],\n",
      "        [-0.21237311, -0.65361193],\n",
      "        ..., \n",
      "        [ 0.62036618, -0.0035004 ],\n",
      "        [ 0.00279156, -0.05439095],\n",
      "        [-0.14650835,  0.29935286]],\n",
      "\n",
      "       ..., \n",
      "       [[ 0.16348104,  0.77010917],\n",
      "        [ 0.43588995,  0.77798736],\n",
      "        [-0.21237311, -0.65361193],\n",
      "        ..., \n",
      "        [ 0.62036618, -0.0035004 ],\n",
      "        [ 0.00279156, -0.05439095],\n",
      "        [-0.14650835,  0.29935286]],\n",
      "\n",
      "       [[ 0.16348104,  0.77010917],\n",
      "        [ 0.43588995,  0.77798736],\n",
      "        [-0.21237311, -0.65361193],\n",
      "        ..., \n",
      "        [ 0.62036618, -0.0035004 ],\n",
      "        [ 0.00279156, -0.05439095],\n",
      "        [-0.14650835,  0.29935286]],\n",
      "\n",
      "       [[ 0.16348104,  0.77010917],\n",
      "        [ 0.43588995,  0.77798736],\n",
      "        [-0.21237311, -0.65361193],\n",
      "        ..., \n",
      "        [ 0.62036618, -0.0035004 ],\n",
      "        [ 0.00279156, -0.05439095],\n",
      "        [-0.14650835,  0.29935286]]])\n",
      "\n",
      "\n",
      "wdE = array([[ 0.1584668 ],\n",
      "       [ 0.15606406],\n",
      "       [ 0.1571382 ],\n",
      "       ..., \n",
      "       [ 0.1574229 ],\n",
      "       [ 0.15881569],\n",
      "       [ 0.15741787]])\n",
      "\n",
      "\n",
      "Mu = array([[[-0.02086341],\n",
      "        [-0.02115991]],\n",
      "\n",
      "       [[-0.06022143],\n",
      "        [-0.04936664]],\n",
      "\n",
      "       [[-0.04123255],\n",
      "        [-0.06044189]],\n",
      "\n",
      "       ..., \n",
      "       [[ 0.03684816],\n",
      "        [-0.00270303]],\n",
      "\n",
      "       [[-0.00668126],\n",
      "        [ 0.01637876]],\n",
      "\n",
      "       [[ 0.04042619],\n",
      "        [ 0.00057867]]])\n",
      "\n",
      "\n",
      "gamma = array([[ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       ..., \n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.]])\n",
      "\n",
      "\n",
      "Lambda = array([[ 2.35504843,  0.        ],\n",
      "       [ 0.        ,  3.80523012]])\n",
      "\n",
      "\n",
      "B = array([[-0.02086341, -0.02115991],\n",
      "       [-0.06022143, -0.04936664],\n",
      "       [-0.04123255, -0.06044189],\n",
      "       ..., \n",
      "       [ 0.03684816, -0.00270303],\n",
      "       [-0.00668126,  0.01637876],\n",
      "       [ 0.04042619,  0.00057867]])\n",
      "\n",
      "\n",
      "H = array([[ 106.11214038,    0.        ],\n",
      "       [   0.        ,  106.11214038]])\n",
      "\n",
      "\n",
      "Delta = array([[ 296.38456316,   77.31960452],\n",
      "       [ 190.27242279,  183.43174489]])\n",
      "\n",
      "\n",
      "Sigma[0][0] @ R[0].T @ X[:,0] = \n",
      "[-0.02086341 -0.02115991]\n",
      "\n",
      "X @ B = \n",
      "[[  5.03179042 -16.76070089]\n",
      " [ 12.96616759  -4.96282766]\n",
      " [-35.31251009 -30.96808951]\n",
      " ..., \n",
      " [  8.03660223 -33.55848241]\n",
      " [ 15.47081903 -16.17904361]\n",
      " [-13.49400516 -23.54020699]]\n",
      "\n",
      "Y - X @ B = \n",
      "[[ -4.86830939  17.53081006]\n",
      " [-12.53027764   5.74081502]\n",
      " [ 35.10013698  30.31447758]\n",
      " ..., \n",
      " [ -7.41623605  33.55498201]\n",
      " [-15.46802748  16.12465266]\n",
      " [ 13.34749681  23.83955985]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Second iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaow/Public/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "res.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "kernel": "Python3",
    "scrolled": false,
    "tags": [
     "report_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E = array([[ -0.41189173,   0.29964363,   2.06530046, ...,  -1.55582062,\n",
      "         -1.22096704,  -1.85730112],\n",
      "       [ 21.82290883,  23.37554433,  20.920637  , ...,  22.19810052,\n",
      "         15.73781539,  21.95128224]])\n",
      "\n",
      "\n",
      "Rx = array([[ -105.68247929,    17.97861755,   204.49481699, ...,\n",
      "         -150.96948701,  -616.95091084,  -182.08212114],\n",
      "       [ 5599.28482416,  1402.5326597 ,  2071.44767636, ...,\n",
      "         2153.99886232,  7952.26995702,  2152.01292885]])\n",
      "\n",
      "\n",
      "R = array([[[ -4.8891728 ,  17.50965015],\n",
      "        [-12.53027764,   5.74081502],\n",
      "        [ 35.10013698,  30.31447758],\n",
      "        ..., \n",
      "        [ -7.41623605,  33.55498201],\n",
      "        [-15.46802748,  16.12465266],\n",
      "        [ 13.34749681,  23.83955985]],\n",
      "\n",
      "       [[ -4.86830939,  17.53081006],\n",
      "        [-12.53027764,   5.74081502],\n",
      "        [ 35.03991555,  30.26511094],\n",
      "        ..., \n",
      "        [ -7.41623605,  33.55498201],\n",
      "        [-15.46802748,  16.12465266],\n",
      "        [ 13.34749681,  23.83955985]],\n",
      "\n",
      "       [[ -4.86830939,  17.53081006],\n",
      "        [-12.53027764,   5.74081502],\n",
      "        [ 35.10013698,  30.31447758],\n",
      "        ..., \n",
      "        [ -7.41623605,  33.55498201],\n",
      "        [-15.46802748,  16.12465266],\n",
      "        [ 13.34749681,  23.83955985]],\n",
      "\n",
      "       ..., \n",
      "       [[ -4.86830939,  17.53081006],\n",
      "        [-12.53027764,   5.74081502],\n",
      "        [ 35.10013698,  30.31447758],\n",
      "        ..., \n",
      "        [ -7.41623605,  33.55498201],\n",
      "        [-15.46802748,  16.12465266],\n",
      "        [ 13.34749681,  23.83955985]],\n",
      "\n",
      "       [[ -4.87499065,  17.54718882],\n",
      "        [-12.5369589 ,   5.75719377],\n",
      "        [ 35.09345572,  30.33085633],\n",
      "        ..., \n",
      "        [ -7.41623605,  33.55498201],\n",
      "        [-15.47470874,  16.14103142],\n",
      "        [ 13.34081555,  23.85593861]],\n",
      "\n",
      "       [[ -4.86830939,  17.53081006],\n",
      "        [-12.53027764,   5.74081502],\n",
      "        [ 35.10013698,  30.31447758],\n",
      "        ..., \n",
      "        [ -7.41623605,  33.55498201],\n",
      "        [-15.46802748,  16.12465266],\n",
      "        [ 13.34749681,  23.83955985]]])\n",
      "\n",
      "\n",
      "wdE = array([[  7.18142331e-105],\n",
      "       [  1.10831333e-119],\n",
      "       [  3.09114003e-097],\n",
      "       ..., \n",
      "       [  9.23467053e-109],\n",
      "       [  1.32820085e-055],\n",
      "       [  1.25861721e-106]])\n",
      "\n",
      "\n",
      "Mu = array([[[ -0.4112112 ],\n",
      "        [ 21.80057994]],\n",
      "\n",
      "       [[  0.29753795],\n",
      "        [ 23.2736074 ]],\n",
      "\n",
      "       [[  2.05648133],\n",
      "        [ 20.86525817]],\n",
      "\n",
      "       ..., \n",
      "       [[ -1.54904212],\n",
      "        [ 22.1381448 ]],\n",
      "\n",
      "       [[ -1.21994188],\n",
      "        [ 15.72963468]],\n",
      "\n",
      "       [[ -1.84929135],\n",
      "        [ 21.89259667]]])\n",
      "\n",
      "\n",
      "gamma = array([[ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       ..., \n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.]])\n",
      "\n",
      "\n",
      "Lambda = array([[ nan,   0.],\n",
      "       [  0.,  nan]])\n",
      "\n",
      "\n",
      "B = array([[ -0.4112112 ,  21.80057994],\n",
      "       [  0.29753795,  23.2736074 ],\n",
      "       [  2.05648133,  20.86525817],\n",
      "       ..., \n",
      "       [ -1.54904212,  22.1381448 ],\n",
      "       [ -1.21994188,  15.72963468],\n",
      "       [ -1.84929135,  21.89259667]])\n",
      "\n",
      "\n",
      "H = array([[ nan,   0.],\n",
      "       [  0.,  nan]])\n",
      "\n",
      "\n",
      "Delta = array([[             nan,  468225.13784254],\n",
      "       [ 249377.18134286,              nan]])\n",
      "\n",
      "\n",
      "Sigma[0][0] @ R[0].T @ X[:,0] = \n",
      "[-0.17460838  5.72910948]\n",
      "\n",
      "X @ B = \n",
      "[[ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " ..., \n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]]\n",
      "\n",
      "Y - X @ B = \n",
      "[[ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " ..., \n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(res.wdE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(res.gamma)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "Python3",
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFE771"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": "655px",
    "style": "side"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
